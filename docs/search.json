[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R ile İstatistiğe Giriş ve Veri Dönüşümü",
    "section": "",
    "text": "Önsöz\nDevlet yardımları, ekonomik ve sosyal kalkınmayı desteklemek amacıyla yürütülen önemli araçlardır. Ancak bu yardımların etkinliğinin değerlendirilmesi, kaynakların verimli kullanımı ve doğru politikaların oluşturulması açısından kritik bir öneme sahiptir. Etki değerlendirme yöntemleri, bu süreçte bilimsel bir temel sağlayarak karar alma mekanizmalarına rehberlik eder.\nEtki değerlendirme süreçlerinin güvenilir sonuçlar verebilmesi, kullanılan yöntemlerin sağlamlığı kadar, bu süreçlerde kullanılan verilerin niteliğiyle de doğrudan ilişkilidir. R programlama dili, analiz ve modelleme çalışmalarında sağladığı esneklik ve güç ile etki değerlendirme yöntemlerinin uygulanmasında kritik bir rol oynamaktadır. Bu çalışmada, devlet yardımlarının etki değerlendirme süreçlerinde kullanılabilecek yöntemlere teorik ve uygulamalı bir temel oluşturulması amaçlanmıştır.\nEtki değerlendirme süreçlerinde doğru ve anlamlı sonuçlara ulaşmak, yalnızca kullanılan yöntemlerin etkinliği ile değil, aynı zamanda güvenilir ve tutarlı verilere dayanılarak gerçekleştirilen analizlerle mümkündür. Bu nedenle, istatistiksel analiz ve veri dönüşüm süreçleri, çalışmanın odak noktalarından biri olarak ele alınmıştır. Bu süreçler, devlet yardımlarının etkilerinin doğru bir şekilde ölçülmesinin ve daha etkili politikaların geliştirilmesinin temelini oluşturmaktadır. Bu çalışmanın, Başkanlığımız ve diğer bakanlık ve kurumlarda yürütülen faaliyetler için yardımcı bir rehber olabileceği değerlendirilmektedir.\nÇalışma, R programı ile uyum içinde çalışan Quarto platformu kullanılarak hazırlanmıştır. Bu platformun sunduğu dinamik ve modüler yapı, kitabın etkili bir şekilde yapılandırılmasına olanak sağlamıştır. Kitap, Quarto’nun kitap formatı özelliğiyle derlenerek, hem kolay okunabilir bir kaynak hem de uygulamalı bir rehber olarak tasarlanmıştır.\nÇalışmanın, ülkemizin kalkınma hedeflerine katkı sağlaması ve bu alanda çalışan uzmanlara yardımcı olmasını dileriz.\nStrateji ve Bütçe Başkanlığı Devlet Yardımları Genel Müdürlüğü",
    "crumbs": [
      "Önsöz"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Giriş",
    "section": "",
    "text": "Bu çalışma, devlet yardımlarının etkilerinin ölçülmesinde kullanılan istatistiksel analiz ve veri dönüşüm süreçlerine odaklanmaktadır. Çalışma, temel istatistiksel kavramlardan başlayarak, R programlama dili kullanılarak gerçekleştirilen veri manipülasyonu ve analitik yöntemlere kadar geniş bir yelpazeyi kapsamaktadır.\nÇalışmanın ilk bölümü, istatistiksel analizlerde temel teşkil eden kavramların açıklanmasıyla başlamaktadır. Bu kapsamda, veri tipleri ele alınarak sayısal (nicel) ve kategorik (nitel) verilerin sınıflandırılmasına ve bu sınıfların alt gruplarına (örneğin, sürekli, kesikli, nominal, ordinal) değinilmiştir. Her bir veri tipi, özellikleri ve kullanım alanları açısından örneklerle desteklenmiştir. Bu açıklamalar, analiz süreçlerinde verilerin doğru şekilde sınıflandırılması ve uygun yöntemlerin seçilmesi açısından önem taşımaktadır.\nMerkezi eğilim ölçüleri (ortalama, medyan ve mod) ve yayılım ölçüleri (aralık, varyans, standart sapma, çeyrekler açıklığı), veri kümesinin genel özelliklerini ve dağılımını anlamak için kullanılan temel araçlar olarak ele alınmıştır. Bu ölçülerin avantajları ve sınırlamaları açıklanmış, farklı veri yapılarında nasıl kullanılabilecekleri örneklerle gösterilmiştir. Dağılım türleri ve merkezi limit teoremi gibi istatistikte sıkça kullanılan kavramlara da yer verilmiş, bu kavramların istatistiksel analiz süreçlerinde taşıdığı önem vurgulanmıştır.\nÇalışmanın ikinci bölümü, veri manipülasyonu ve dönüşüm tekniklerine odaklanmaktadır. Veri çerçeveleri üzerinde yapılan seçim, sıralama, filtreleme, dönüştürme ve özetleme gibi işlemler, R programlama dili kullanılarak uygulamalı örneklerle ele alınmıştır. Özellikle dplyr paketi ile veri manipülasyonu süreçleri sade bir şekilde anlatılmış ve kullanılan yöntemlerin adımları açıklanmıştır. Bu yöntemler, veri analizi sürecinin başlangıcında sıkça karşılaşılan zorluklara çözüm sunmayı amaçlamaktadır.\nVeri temizleme işlemleri kapsamında eksik verilerle çalışmaya yönelik detaylı bir anlatı sunulmaktadır. Eksik verilerin tespiti, analiz sürecindeki etkileri ve bu durumların yönetimi için kullanılan yöntemler, teorik açıklamalar ve R programlama diliyle gerçekleştirilen uygulamalarla desteklenmiştir. Eksik veri oranlarının hesaplanması, bu verilerin görselleştirilmesi ve eksik değerlerin doldurulmasına yönelik çeşitli yaklaşımlar kitapta yer bulmuştur. Özellikle MICE ve dlookr gibi R paketlerinin bu alandaki işlevselliği, uygulamalı örneklerle açıklanmıştır. Eksik verilerin uygun yöntemlerle işlenmesi, analiz sonuçlarının doğruluğunu artırmak ve bu verilerin veri setindeki diğer bilgilerle uyumlu hale gelmesini sağlamak açısından önem taşımaktadır.\nKitabın bu iki bölümü, okuyucunun hem istatistiksel analiz hem de veri manipülasyonu konularında sağlam bir altyapı kazanmasını sağlamayı hedeflemektedir. Teorik bilgiler ve uygulamalı örneklerin bir arada sunulması ile veri analizi süreçlerinde karşılaşabilecek zorluklara çözüm üretilebilmesi amaçlanmıştır.",
    "crumbs": [
      "Giriş"
    ]
  },
  {
    "objectID": "veri_tipleri.html",
    "href": "veri_tipleri.html",
    "title": "\n1  İstatistikte Veri Tipleri\n",
    "section": "",
    "text": "1.1 Sayısal (Nicel) Veriler\nSayısal veriler, sayılarla ifade edilen ve genellikle miktar veya ölçüm sonucu olan verilerdir. Nicel veriler, sürekli veya kesikli olmak üzere iki alt gruba ayrılır.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>İstatistikte Veri Tipleri</span>"
    ]
  },
  {
    "objectID": "veri_tipleri.html#sayısal-nicel-veriler",
    "href": "veri_tipleri.html#sayısal-nicel-veriler",
    "title": "\n1  İstatistikte Veri Tipleri\n",
    "section": "",
    "text": "1.1.1 Sürekli (Measured)\n\n\nTanım: Belirli bir aralıkta herhangi bir değer alabilen, ölçümle elde edilen verilerdir. Bu tür veriler genellikle ölçü aletleriyle elde edilir (metre, kilogram, saat vb.).\n\nÖzellikler:\n\nSonsuz sayıda değer alabilir.\nGenellikle ondalıklı değerler içerir.\n\n\n\nÖrnekler:\n\nBir kişinin boyu: 175.4 cm\nBir suyun sıcaklığı: 23.7°C\nBir koşucunun 100 metreyi tamamlama süresi: 10.53 saniye\n\n\n\n1.1.2 Kesikli (Counted)\n\n\nTanım: Sayılabilir ve yalnızca tam sayı değerleri alabilen verilerdir. Bu tür veriler genellikle bir şeyin sayısını ifade eder.\n\nÖzellikler:\n\nSayılar tam sayıdır; ondalıklı değer almaz.\n\n\n\nÖrnekler:\n\nBir sınıfta bulunan öğrenci sayısı: 25\nBir mağazada satılan ürün adedi: 120\nBir kişinin aylık kitap okuma sayısı: 3",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>İstatistikte Veri Tipleri</span>"
    ]
  },
  {
    "objectID": "veri_tipleri.html#kategorik-nitel-veriler",
    "href": "veri_tipleri.html#kategorik-nitel-veriler",
    "title": "\n1  İstatistikte Veri Tipleri\n",
    "section": "\n1.2 Kategorik (Nitel) Veriler",
    "text": "1.2 Kategorik (Nitel) Veriler\nKategorik veriler, sayısal olmayan ve sınıflar veya gruplar halinde sınıflandırılan verilerdir. Kategorik veriler nominal veya ordinal olarak ikiye ayrılır.\n\n1.2.1 Nominal (Sırasız)\n\n\nTanım: Belirli bir sıralama içermeyen, yalnızca kategorileri veya sınıfları ifade eden verilerdir.\n\nÖzellikler:\n\nKategoriler arasında bir sıralama yoktur.\nGenellikle metinsel olarak ifade edilir.\n\n\n\nÖrnekler:\n\nCinsiyet: Erkek, Kadın\nKan grubu: A, B, AB, 0\nGöz rengi: Kahverengi, Mavi, Yeşil\n\n\n\n1.2.2 Ordinal (Sıralı)\n\n\nTanım: Kategoriler arasında belirli bir sıralama olan verilerdir. Ancak bu sıralama arasındaki farklar eşit veya kesin değildir.\n\nÖzellikler:\n\nSıralama içerir; ancak farkların büyüklüğü ölçülemez.\n\n\n\nÖrnekler:\n\nEğitim düzeyi: İlkokul, Ortaokul, Lise, Üniversite\nMüşteri memnuniyeti: Çok memnun, Memnun, Nötr, Memnun Değil\nYarış sıralaması: 1., 2., 3.\n\n\n\n\n\n\n\n\n\nVeri Tiplerinin Seçimi ve Önemi\n\n\n\n\n\nSayısal Veriler: İstatistiksel analizlerde genellikle aritmetik işlemlere uygundur. Örneğin, bir grup insanın boy ortalamasını hesaplamak.\n\nKategorik Veriler: Genellikle gruplama ve sınıflandırma için kullanılır. Örneğin, farklı kan gruplarının bir popülasyondaki dağılımını analiz etmek.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>İstatistikte Veri Tipleri</span>"
    ]
  },
  {
    "objectID": "veri_tipleri.html#özet-tablo",
    "href": "veri_tipleri.html#özet-tablo",
    "title": "\n1  İstatistikte Veri Tipleri\n",
    "section": "\n1.3 Özet Tablo",
    "text": "1.3 Özet Tablo\n\n\n\n\n\n\n\nVeri Tipi\nTanım\nÖrnekler\n\n\n\nSürekli\nÖlçülen, belirli bir aralıkta değer alır\nBoy: 175.4 cm, Sıcaklık: 23.7°C\n\n\nKesikli\nSayılan, yalnızca tam sayı değer alır\nÖğrenci sayısı: 25, Ürün adedi: 120\n\n\nNominal\nSırasız kategoriler\nCinsiyet: Erkek, Kadın; Göz rengi: Mavi, Yeşil\n\n\nOrdinal\nSıralı kategoriler\nEğitim düzeyi: Lise, Üniversite; Yarış sıralaması: 1., 2.\n\n\n\nVeri türlerinin anlaşılması, doğru istatistiksel analiz yöntemlerini seçmek ve sonuçları daha iyi yorumlamak için önemlidir.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>İstatistikte Veri Tipleri</span>"
    ]
  },
  {
    "objectID": "veri_tipleri.html#veri-tipleri",
    "href": "veri_tipleri.html#veri-tipleri",
    "title": "\n1  İstatistikte Veri Tipleri\n",
    "section": "\n2.1 Veri Tipleri",
    "text": "2.1 Veri Tipleri\nR’daki veri tipleri, bir değişkenin bellekte nasıl saklandığını ve ne tür işlemler yapılabileceğini belirleyen temel yapı taşlarıdır. Bu veri tiplerini anlamak, R’da verilerle etkin bir şekilde çalışmanın anahtarıdır. Veri tipleri, hangi tür veriyi nasıl sakladığımızı ve bu veriyle ne tür işlemler yapabileceğimizi belirler. Aşağıda, R’da kullanılan temel veri tiplerini ve kullanım alanlarını bulabilirsiniz:\n\n2.1.1 Numeric (Sayısal)\n\n\nTanım: Ondalıklı veya tam sayıları ifade eder. Bu tip, en yaygın kullanılan veri türüdür.\n\nÖzellikler:\n\nHem tam sayılar hem de ondalıklı sayılar bu kategoridedir.\nVarsayılan olarak, sayılar numeric olarak tanımlanır.\n\n\n\n\n# Sayısal bir tam sayı tanımlama\nsayi &lt;- 42\n\n# Ondalıklı bir sayı tanımlama\nondalikli &lt;- 3.14\n\n# Değişkenlerin sınıflarını kontrol etme\nclass(sayi)        # \"numeric\"\n\n[1] \"numeric\"\n\nclass(ondalikli)   # \"numeric\"\n\n[1] \"numeric\"\n\n\n\n\nKullanım Alanı: Matematiksel işlemler, istatistiksel hesaplamalar ve ölçüm verileri.\n\n2.1.2 Integer (Tamsayı)\n\nTanım: Tam sayıları temsil eder. Numeric tipine benzer, ancak yalnızca tam sayı değerleri içerir.\nÖzellikler: Tamsayı olarak bir değer belirtmek için L eklenir (örneğin, 5L).\n\n\n# Tamsayı bir değişken tanımlama\ntamsayi &lt;- 100L\n\n# Değişkenin sınıfını kontrol etme\nclass(tamsayi)  # \"integer\"\n\n[1] \"integer\"\n\n\n\n\nKullanım Alanı: İndeksleme, sayaçlar veya tam sayı gerektiren işlemler.\n\n2.1.3 Character (Karakter)\n\n\nTanım: Metinsel verileri temsil eder. Kelimeler, cümleler veya herhangi bir metin bilgisi için kullanılır.\n\nÖzellikler: Değerler çift tırnak (\") veya tek tırnak (') ile tanımlanır.\n\n\n# Metin türünde bir değişken tanımlama\nmetin &lt;- \"Merhaba R\"\n\n# Değişkenin sınıfını kontrol etme\nclass(metin)  # \"character\"\n\n[1] \"character\"\n\n\n\n\nKullanım Alanı: İsimler, açıklamalar, kategorik veriler veya etiketler.\n\n2.1.4 Logical (Mantıksal)\n\n\nTanım: Doğru (TRUE) veya yanlış (FALSE) durumlarını ifade eder.\n\nÖzellikler: Mantıksal veri tipleri, genellikle koşullu ifadelerde kullanılır.\n\n\n# Mantıksal değişkenler tanımlama\ndogru_mu &lt;- TRUE\nyanlis_mi &lt;- FALSE\n\n# Değişkenin sınıfını kontrol etme\nclass(dogru_mu)  # \"logical\"\n\n[1] \"logical\"\n\n\n\n\nKullanım Alanı: Koşullar, filtreleme ve kontrol akışları.\n\n2.1.5 Complex (Karmaşık)\n\n\nTanım: Karmaşık sayılar, reel ve sanal bileşenleri içeren sayılardır.\n\nÖzellikler: Karmaşık sayıların biçimi: a + bi (örneğin, 2 + 3i).\n\n\n# Karmaşık sayı tanımlama\nkarmasik &lt;- 1 + 2i\n\n# Değişkenin sınıfını kontrol etme\nclass(karmasik)  # \"complex\"\n\n[1] \"complex\"\n\n\n\n\nKullanım Alanı: Matematikte, özellikle ileri düzey hesaplamalarda.\n\n2.1.6 Factor (Faktör)\n\n\nTanım: Faktörler, kategorik verilerin saklanması için kullanılır. Bu tip, sınıflandırma ve seviyelendirme için idealdir.\n\nÖzellikler:\n\nFaktörler, seviyeler (levels) adı verilen kategorileri içerir.\nBellek kullanımı açısından verimlidir.\n\n\n\n\n# Faktör türünde bir değişken tanımlama\ncinsiyet &lt;- factor(c(\"Erkek\", \"Kadın\", \"Kadın\"))\n\n# Değişkenin sınıfını kontrol etme\nclass(cinsiyet)      # \"factor\"\n\n[1] \"factor\"\n\n# Faktör seviyelerini görüntüleme\nlevels(cinsiyet)     # \"Erkek\" \"Kadın\"\n\n[1] \"Erkek\" \"Kadın\"\n\n\n\n\nKullanım Alanı: Anket yanıtları, kategorik değişkenler ve gruplama.\n\n\n\n\n\n\n\nVeri Tiplerini Bilmek Neden Önemlidir?\n\n\n\n\n\nBellek Yönetimi: Doğru veri tipini kullanmak, bellek verimliliği sağlar.\n\nDoğru Hesaplamalar: Veri tipi yanlış seçilirse, beklenmeyen sonuçlar veya hata mesajları alınabilir.\n\nDönüşüm: Veri tiplerini bilmek, gerekli dönüşümleri yaparak (örneğin, sayısaldan karaktere) veriyle daha esnek çalışmayı mümkün kılar.\n\nÖrnek Dönüşüm:\n\n# Numeric bir değişken tanımlama\nsayi &lt;- 123\n\n# Numeric'ten karaktere dönüşüm\nkarakter &lt;- as.character(sayi)\n\n# Dönüştürülen değişkenin sınıfını kontrol etme\nclass(karakter)  # \"character\"\n\n[1] \"character\"\n\n\nVeri tiplerini anlamak, R’da verileri işlemek için temel bir adımdır ve verilerle daha etkili bir şekilde çalışmanızı sağlar.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>İstatistikte Veri Tipleri</span>"
    ]
  },
  {
    "objectID": "veri_tipleri.html#veri-yapıları",
    "href": "veri_tipleri.html#veri-yapıları",
    "title": "\n1  İstatistikte Veri Tipleri\n",
    "section": "\n2.2 Veri Yapıları",
    "text": "2.2 Veri Yapıları\nR’daki veri yapıları, verilerin nasıl organize edildiğini ve işlendiğini belirler. Farklı boyut ve türdeki veri kümelerini temsil etmek için çeşitli veri yapıları kullanılır. Aşağıda, R’da kullanılan temel veri yapıları ve bu yapıların nasıl kullanılabileceği açıklanmıştır:\n\n2.2.1 Vector (Vektör)\n\n\nTanım: Homojen bir veri yapısıdır; yalnızca bir tür veri içerir (örneğin, tümü sayısal veya tümü karakter).\n\nÖzellikler: Bir vektör, c() fonksiyonu ile oluşturulur.\n\n\n# Sayısal bir vektör tanımlama\nsayisal_vektor &lt;- c(1, 2, 3, 4, 5)\n\n# Karakter bir vektör tanımlama\nkarakter_vektor &lt;- c(\"Ali\", \"Asya\", \"Mehmet\")\n\n# Vektörlerin sınıfını kontrol etme\nclass(sayisal_vektor)    # \"numeric\"\n\n[1] \"numeric\"\n\nclass(karakter_vektor)   # \"character\"\n\n[1] \"character\"\n\n\n\n\nKullanım Alanı: Basit veri listeleri, bir boyutlu veriler.\n\n2.2.2 Matrix (Matris)\n\n\nTanım: İki boyutlu ve homojen bir veri yapısıdır; yalnızca bir tür veri içerir.\n\nÖzellikler: Matris, matrix() fonksiyonu ile oluşturulur.\n\n\n# Bir matris tanımlama\nmatris &lt;- matrix(1:6, nrow = 2, ncol = 3)\n\n# Matrisi ekrana yazdırma\nprint(matris)\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n# Matrisin sınıfını kontrol etme\nclass(matris)  # \"matrix\"\n\n[1] \"matrix\" \"array\" \n\n\n\n\nKullanım Alanı: Matematiksel hesaplamalar ve matris işlemleri.\n\n2.2.3 Array (Dizi)\n\n\nTanım: Çok boyutlu ve homojen bir veri yapısıdır.\n\nÖzellikler: Bir dizi, array() fonksiyonu ile oluşturulur.\n\n\n# Bir dizi (array) tanımlama\ndizi &lt;- array(1:12, dim = c(2, 3, 2))\n\n# Diziyi ekrana yazdırma\nprint(dizi)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n\n\n\nKullanım Alanı: Daha yüksek boyutlu verilerle çalışmak.\n\n2.2.4 Data Frame (Veri Çerçevesi)\n\n\nTanım: Heterojen bir veri yapısıdır; farklı türde veriler içerebilir (örneğin, sayısal ve karakter birlikte).\n\nÖzellikler: Bir veri çerçevesi, data.frame() fonksiyonu ile oluşturulur.\n\n\n# Bir veri çerçevesi (data frame) tanımlama\nveri_cercevesi &lt;- data.frame(\n    ID = c(1, 2, 3),              # Kimlik numarası sütunu\n    Ad = c(\"Ahmet\", \"Asya\", \"Mehmet\"), # İsim sütunu\n    Yas = c(25, 30, 22)           # Yaş sütunu\n)\n\n# Veri çerçevesini ekrana yazdırma\nprint(veri_cercevesi)\n\n  ID     Ad Yas\n1  1  Ahmet  25\n2  2   Asya  30\n3  3 Mehmet  22\n\n\n\n\nKullanım Alanı: Tablo formatında veriler.\n\n\n\n\n\n\n\nNeden data.frame() yerine tibble() tercih edilebilir?\n\n\n\n\n\nDaha kullanıcı dostudur: Tibble, büyük veri setlerinde sadece ilk birkaç satırı göstererek konsol çıktısını okunabilir hale getirir.\n\nModern veri analizi için optimize edilmiştir: tidyverse ekosistemiyle tam uyumlu çalışır ve pipeline (%&gt;%) kullanımıyla veri manipülasyonunu kolaylaştırır.\n\nVarsayılan davranışları daha sezgiseldir: Karakter vektörlerini factor’a dönüştürmez, sütun isimlerinde esneklik sunar ve veri işleme sürecinde sık yapılan hataları önler.\n\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(tidyverse)\n\n# Bir tibble tanımlama\ntb &lt;- tibble(\n    isim = c(\"Ahmet\", \"Asya\", \"Mehmet\"),  # İsim sütunu (character)\n    yas = c(25, 30, 22),                  # Yaş sütunu (numeric)\n    evli = c(TRUE, FALSE, FALSE)          # Evli durumu sütunu (logical)\n)\n\n# Tibble'ı ekrana yazdırma\nprint(tb)\n\n# A tibble: 3 × 3\n  isim     yas evli \n  &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt;\n1 Ahmet     25 TRUE \n2 Asya      30 FALSE\n3 Mehmet    22 FALSE\n\n\n\n\n\n\n\n\n\n\nVeri Yapılarının Seçimi\n\n\n\nVeri yapılarının doğru seçimi, veri analizi ve modelleme işlemlerini daha verimli hale getirir.\n\n\n\n2.2.5 List (Liste)\n\n\nTanım: Heterojen bir veri yapısıdır; herhangi bir veri türünü içerebilir.\n\nÖzellikler: Bir liste, list() fonksiyonu ile oluşturulur.\nÖrnekler:\n\n\n# Bir liste tanımlama\nliste &lt;- list(\n    isim = \"Ayşe\",              # Karakter eleman\n    yas = 30,                   # Sayısal eleman\n    evli = TRUE,                # Mantıksal eleman\n    sayilar = c(1, 2, 3)        # Vektör eleman\n)\n\n# Listeyi ekrana yazdırma\nprint(liste)\n\n$isim\n[1] \"Ayşe\"\n\n$yas\n[1] 30\n\n$evli\n[1] TRUE\n\n$sayilar\n[1] 1 2 3\n\n\n\n\nKullanım Alanı: Birden fazla veri türünü aynı yapıda saklamak.\n\n\n\n\n\n\n\nVeri Yapılarının Seçimi\n\n\n\n\n\nBoyut ve Tür: Verinin boyutu (tek boyutlu, iki boyutlu, çok boyutlu) ve türü (homojen, heterojen) veri yapısını seçerken belirleyicidir.\n\nHafıza Kullanımı: Daha büyük veri yapıları için belleği etkili kullanmak önemlidir.\n\nUygulama: Veri yapıları, analiz türüne göre seçilir. Örneğin:\n\nBasit veriler için vektör.\nTablo formatı için veri çerçevesi.\nİleri düzey hesaplamalar için matris veya diziler.\n\n\n\nVeri yapılarının doğru seçimi, veri analizi ve modelleme işlemlerini daha verimli hale getirir.\n\n\nReferanslar\nhttps://www.w3schools.com/r/r_variables.asp https://www.modernstatisticswithr.com/\nhttps://openintro-ims.netlify.app/exploratory-data-analysis\nhttps://trevorfrench.github.io/R-for-Data-Analysis/p1c3-data-types.html\nhttps://www.w3schools.com/r/r_data_types.asp\nhttps://app.datacamp.com/learn/courses/introduction-to-statistics-in-r",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>İstatistikte Veri Tipleri</span>"
    ]
  },
  {
    "objectID": "ozet_istatistikler.html",
    "href": "ozet_istatistikler.html",
    "title": "\n2  Merkezi Eğilim ve Yayılım Ölçüleri\n",
    "section": "",
    "text": "2.1 Merkezi Eğilim Ölçüleri\nMerkezi eğilim ölçüleri, bir veri kümesindeki “merkezi değeri” tanımlamak için kullanılır. Temel merkezi eğilim ölçüleri ortalama, medyan ve moddur.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Merkezi Eğilim ve Yayılım Ölçüleri</span>"
    ]
  },
  {
    "objectID": "ozet_istatistikler.html#merkezi-eğilim-ölçüleri",
    "href": "ozet_istatistikler.html#merkezi-eğilim-ölçüleri",
    "title": "\n2  Merkezi Eğilim ve Yayılım Ölçüleri\n",
    "section": "",
    "text": "2.1.1 Ortalama\n\n\nTanım: Bir veri kümesindeki tüm değerlerin toplamının, veri sayısına bölünmesiyle elde edilen değerdir. mean() fonksyonu ile hesaplanır.\n\n\n# Bir vektör tanımlama\nveri &lt;- c(12, 15, 20, 25, 30, 35, 40, 50)\n\n# Vektörün ortalamasını hesaplama\nortalama &lt;- mean(veri)\n\n# Ortalamayı ekrana yazdırma\nprint(ortalama)\n\n[1] 28.375\n\n\n\n\n\n\n\n\nAykırı değerler, ortalamayı büyük ölçüde etkileyebilir\n\n\n\nAykırı değerler, bir veri kümesindeki diğer verilere kıyasla çok büyük veya çok küçük olan sıra dışı değerlerdir. Bu değerler, veri kümesinin genel eğilimine uymadığı için ortalamayı önemli ölçüde etkileyebilir.\nNeden Ortalamayı Etkiler? Ortalama, tüm değerlerin toplamının veri sayısına bölünmesiyle hesaplanır. Bu nedenle, aşırı büyük veya küçük bir değer toplam üzerinde büyük bir ağırlık oluşturabilir ve ortalamayı bu uç değere doğru kaydırabilir.\n\n# Aykırı değer içermeyen bir veri kümesi\nveri_normal &lt;- c(10, 15, 20, 25, 30)\nortalama_normal &lt;- mean(veri_normal)\nprint(ortalama_normal) # Çıktı: 20\n\n[1] 20\n\n# Aykırı değer içeren bir veri kümesi\nveri_aykiri &lt;- c(10, 15, 20, 25, 1000) # 1000 bir aykırı değerdir\nortalama_aykiri &lt;- mean(veri_aykiri)\nprint(ortalama_aykiri) # Çıktı: 214\n\n[1] 214\n\n\n\n\n\n2.1.2 Medyan (Ortanca)\n\n\nTanım: Bir veri kümesindeki sıralanmış verilerin ortanca değeridir. Eğer veri sayısı tek ise ortanca değeri, çift ise ortanca iki değerin ortalamasıdır. median() fonksyonu ile hesaplanır.\n\n\n# Bir veri kümesi tanımlama\nveri &lt;- c(3, 5, 7, 9, 11, 13)\n\n# Verinin medyanını hesaplama\nmedyan &lt;- median(veri)\n\n# Medyanı ekrana yazdırma\nprint(medyan)\n\n[1] 8\n\n\n\n\n\n\n\n\nMedyanın Avantajı: Aykırı Değerlerden Etkilenmeme\n\n\n\nMedyan, veri kümesindeki sıralanmış değerlerin ortanca noktasını temsil ettiği için, çok büyük ya da çok küçük uç değerler (aykırı değerler) medyanı etkilemez. Bu, medyanı özellikle aykırı değerlere sahip veri setlerinde güvenilir bir merkezi eğilim ölçüsü haline getirir.\nNeden Etkilenmez? Medyan, sadece sıralanmış verilerin ortanca noktasını kullanır. Veri kümesindeki en küçük veya en büyük değer, sıralamayı değiştirse bile ortanca değeri değiştirmez.\n\n# Aykırı değer içermeyen bir veri kümesi\nveri_normal &lt;- c(10, 15, 20, 25, 30)\nmedyan_normal &lt;- median(veri_normal)\nprint(medyan_normal) # Çıktı: 20\n\n[1] 20\n\n# Aykırı değer içeren bir veri kümesi\nveri_aykiri &lt;- c(10, 15, 20, 25, 1000)\nmedyan_aykiri &lt;- median(veri_aykiri)\nprint(medyan_aykiri) # Çıktı: 20\n\n[1] 20\n\n\nMedyan, hem aykırı değer olmayan hem de aykırı değer içeren veri setlerinde aynı sonucu vermiştir. Bu, medyanın aykırı değerlere karşı dayanıklı olduğunu gösterir.\n\n\nMedyan, özellikle uç değerlerin bulunduğu durumlarda daha güvenilir bir merkezi eğilim ölçüsü sağlar. Örneğin, gelir dağılımı gibi büyük uç değerlere sahip veri kümelerinde medyan, genellikle ortalamadan daha anlamlı bir ölçü olur.\n\n2.1.3 Mod\n\nTanım: Bir veri kümesinde en sık görülen değerdir. Mod, özellikle kategorik verilerde veya sayısal verilerde tekrarlanan değerleri anlamak için kullanılır.\n\nÖzellikler:\n\nTekrarlanan bir değer yoksa mod yoktur.\nBirden fazla değerin aynı sıklıkla görülmesi durumunda, veri kümesi “çok modlu” (multi-modal) olarak adlandırılır.\n\n\n\n\n# Gerekli kütüphanenin yüklenmesi\n# install.packages(\"modeest\") # Eğer yüklenmemişse, bu satırı çalıştırın\nlibrary(modeest)\n\n# Bir veri kümesi tanımlama\nveri &lt;- c(1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6)\n\n# Verinin modunu hesaplama (en sık görülen değer)\nmod &lt;- mfv(veri)\n\n# Modu ekrana yazdırma\nprint(mod) # En sık görülen değer: 4\n\n[1] 4\n\n\nKategorik Veri için Mod\nMod, kategorik verilerde en sık görülen kategoriyi belirlemek için de kullanılabilir.\n\n# Gerekli kütüphanenin yüklenmesi\n# install.packages(\"modeest\") # Eğer yüklenmemişse bu satırı çalıştırın\nlibrary(modeest)\n\n# Bir kategorik veri kümesi tanımlama\nkategorik_veri &lt;- c(\"Kırmızı\", \"Mavi\", \"Kırmızı\", \"Yeşil\", \"Mavi\", \"Mavi\")\n\n# Kategorik verinin modunu hesaplama (en sık görülen kategori)\nmod_kategorik &lt;- mfv(kategorik_veri)\n\n# Modu ekrana yazdırma\nprint(mod_kategorik) # En sık görülen kategori: \"Mavi\"\n\n[1] \"Mavi\"\n\n\n\n\n\n\n\n\nMod Uygulama Alanı ve Açıklamalar\n\n\n\nUygulama Alanı: Mod, özellikle kategorik verilerde en sık görülen grubu veya sınıfı anlamak için yararlıdır. Sayısal verilerde de merkezi eğilimi gösterir, ancak tüm veri setini tam olarak temsil etmeyebilir.\nEksiklikler: Mod her zaman var olmayabilir (tekrarlanan bir değer yoksa). Çok modlu veri setlerinde tek bir merkezi eğilim ölçüsü sağlamak zordur.\n\n\nMod, veri setindeki tekrarlanan veya en yaygın değeri anlamak için kullanışlı bir araçtır. Ancak veri setinin niteliğine bağlı olarak diğer merkezi eğilim ölçüleri (örneğin, ortalama veya medyan) ile birlikte değerlendirilmesi daha kapsamlı bir analiz sağlar.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Merkezi Eğilim ve Yayılım Ölçüleri</span>"
    ]
  },
  {
    "objectID": "ozet_istatistikler.html#yayılım-ölçüleri",
    "href": "ozet_istatistikler.html#yayılım-ölçüleri",
    "title": "\n2  Merkezi Eğilim ve Yayılım Ölçüleri\n",
    "section": "\n2.2 Yayılım Ölçüleri",
    "text": "2.2 Yayılım Ölçüleri\nYayılım ölçüleri, veri kümesindeki değerlerin çeşitliliğini veya veri setinin ne kadar yayıldığını ölçmek için kullanılır.\n\n2.2.1 Aralık\n\n\nTanım: Bir veri kümesindeki en büyük değer ile en küçük değer arasındaki farktır. Aralık, veri setindeki yayılımın en temel ölçüsüdür.\n\n\n# Bir veri kümesi tanımlama\nveri &lt;- c(4, 7, 10, 15)\n\n# Verinin aralığını hesaplama\naralik &lt;- max(veri) - min(veri)\n\n# Aralığı ekrana yazdırma\nprint(aralik) # Çıktı: 11\n\n[1] 11\n\n\n\n\n\n\n\n\nAykırı Değerlerin Etkisi\n\n\n\nAralık, yalnızca iki değere (en büyük ve en küçük) bağlıdır. Veri kümesindeki diğer değerleri dikkate almaz. Aykırı değerler varsa yayılımı olduğundan fazla gösterebilir. Dolayısıyla Aykırı değerler (veri kümesindeki diğer değerlere göre çok büyük veya çok küçük olan değerler), aralığı büyük ölçüde etkileyebilir.\n\n\n\n2.2.2 Varyans\n\nTanım: Verilerin ortalamadan ne kadar uzaklaştığını ölçen bir yayılım ölçüsüdür. Her bir veri noktasının ortalamadan farkının karesi alınarak bu farkların ortalaması hesaplanır. Karesi alındığı için varyans, tüm sapmaları pozitif hale getirir ve yayılımın büyüklüğünü anlamamızı sağlar. var() fonksyonu ile hesaplanır.\nPopülasyon varyansı: \\(\\sigma^2 = \\frac{\\sum{(x_i - \\mu)^2}}{N}\\)\nÖrneklem varyansı: \\(s^2 = \\frac{\\sum{(x_i - \\bar{x})^2}}{n-1}\\)\n\n\n# Bir veri kümesi tanımlama\nveri &lt;- c(2, 4, 6)\n\n# Verinin ortalamasını hesaplama\nortalama &lt;- mean(veri)\nprint(ortalama) # Çıktı: 4\n\n[1] 4\n\n# Verinin varyansını hesaplama\nvaryans &lt;- var(veri)\nprint(varyans) # Çıktı: 4\n\n[1] 4\n\n\nHesaplama Adımları\n\nOrtalama: \\(\\bar{x} = \\frac{(2 + 4 + 6)}{3} = 4\\)\n\nOrtalamadan sapmalar: \\((2 - 4), (4 - 4), (6 - 4) = -2, 0, 2\\)\n\nSapmaların kareleri: \\((-2)^2, (0)^2, (2)^2 = 4, 0, 4)\\)\n\nVaryans: \\(\\frac{(4 + 0 + 4)}{3 - 1} = \\frac{8}{2} = 4\\)\n\n\n\n# Daha geniş bir veri kümesi tanımlama\nveri_genis &lt;- c(5, 10, 15, 20, 25)\n\n# Verinin ortalamasını hesaplama\nortalama_genis &lt;- mean(veri_genis)\nprint(ortalama_genis) # Çıktı: 15\n\n[1] 15\n\n# Verinin varyansını hesaplama\nvaryans_genis &lt;- var(veri_genis)\nprint(varyans_genis) # Çıktı: 62.5\n\n[1] 62.5\n\n\nHesaplama Adımları\n\nOrtalama: \\(\\bar{x} = \\frac{(5 + 10 + 15 + 20 + 25)}{5} = 15\\)\n\nOrtalamadan sapmalar: \\((-10,\\ -5,\\ 0,\\ 5,\\ 10)\\)\n\nSapmaların kareleri: \\((100,\\ 25,\\ 0,\\ 25,\\ 100)\\)\n\nVaryans: \\(\\frac{(100 + 25 + 0 + 25 + 100)}{5 - 1} = \\frac{250}{4} = 62.5\\)\n\n\n\n\n\n\n\n\nDikkat Edilmesi Gereken Hususlar\n\n\n\n\nBirimin Kare Farklılığı:\n\n\nVaryansın birimi, orijinal veri biriminin karesidir. Örneğin, veri “cm” birimindeyse, varyans “cm²” biriminde olur.\nBu nedenle, varyansın yorumu bazen zor olabilir. Standart sapma, birimi orijinal veri birimiyle aynı olduğu için daha sık tercih edilir.\n\n\nVaryansın Yorumlanması:\n\n\nVaryans büyüdükçe, verilerin ortalamadan daha fazla sapma gösterdiği anlamına gelir.\nKüçük bir varyans, verilerin ortalamaya yakın olduğunu ifade eder.\n\nVaryans, veri kümesindeki yayılımı anlamak için güçlü bir araçtır. Ancak birimi farklı olduğu için doğrudan yorumlamak yerine genellikle standart sapma ile birlikte değerlendirilir. Daha büyük veri kümelerinde varyans, verilerdeki farklılıkları daha doğru bir şekilde yansıtır.\n\n\n\n2.2.3 Standart Sapma\n\nTanım: Standart sapma, veri değerlerinin ortalamadan ne kadar saptığını gösteren bir yayılım ölçüsüdür. Varyansın karekökü olarak hesaplanır ve birimi, veri birimiyle aynıdır. Bu özelliği, standart sapmayı yorumlamayı daha kolay hale getirir. sd() fonksyonu ile hesaplanır.\nPopülasyon Standart Sapması: \\(\\sigma = \\sqrt{\\frac{\\sum{(x_i - \\mu)^2}}{N}}\\)\nÖrneklem Standart Sapması: \\(s = \\sqrt{\\frac{\\sum{(x_i - \\overline{x})^2}}{n-1}}\\)\n\n\n# Bir veri kümesi tanımlama\nveri &lt;- c(2, 4, 6)\n\n# Verinin standart sapmasını hesaplama\nstd_sapma &lt;- sd(veri)\n\n# Standart sapmayı ekrana yazdırma\nprint(std_sapma) # Çıktı: 2\n\n[1] 2\n\n\nHesaplama Adımları:\n\n\nOrtalama: \\(\\overline{x} = \\frac{(2 + 4 + 6)}{3} = 4\\)\n\n\nSapmalar: \\((2 - 4), (4 - 4), (6 - 4) = -2, 0, 2)\\)\n\n\nSapmaların Kareleri: \\((-2)^2, (0)^2, (2)^2 = 4, 0, 4\\)\n\n\nVaryans: \\(\\frac{(4 + 0 + 4)}{3 - 1} = \\frac{8}{2} = 4\\)\n\n\nStandart Sapma: \\(\\sqrt{4} = 2\\)\n\n\n\n\n\n\n\n\nVeri Yapılarının Seçimi\n\n\n\n\nBirimin Korunması:\n\n\nStandart sapmanın birimi, orijinal veri birimiyle aynıdır. Örneğin, veri “metre” ise, standart sapma da “metre” birimindedir.\nBu özellik, standart sapmayı varyanstan daha kolay yorumlanabilir hale getirir.\n\n\nVeri Dağılımını Anlama:\n\n\nStandart sapma küçükse, veri değerleri ortalamaya yakın demektir.\nStandart sapma büyükse, veri değerleri ortalamadan uzaklaşır, yani yayılım artar.\n\n\n\n\n\n\n\n\n\nAykırı değerler ve standart sapma\n\n\n\n\nStandart sapma, aykırı değerlerden etkilenir. Eğer veri setinde uç noktalar varsa, standart sapma olduğundan daha büyük görünebilir.\nAykırı değerlerin etkisini azaltmak için çeyrekler açıklığı (IQR) gibi diğer yayılım ölçüleriyle birlikte kullanılabilir.\n\n\n\nStandart sapma, verilerin yayılımını ve dağılımını anlamak için güçlü bir araçtır. Yorumlanması kolaydır ve birimi koruduğu için veri analizi sırasında sıkça tercih edilir. Ancak, aykırı değerlere duyarlılığı nedeniyle dikkatli bir şekilde değerlendirilmelidir.\n\n2.2.4 Çeyrekler Açıklığı (Interquartile Range (IQR))\n\n\nTanım: Çeyrekler açıklığı, verilerin dağılımını anlamak için kullanılan bir yayılım ölçüsüdür. Veriler, sıralandıktan sonra dört eşit parçaya bölünür ve çeyrekler açıklığı, üçüncü çeyrek (Q3) ile birinci çeyrek (Q1) arasındaki fark olarak hesaplanır. Bu ölçü, veri setindeki orta yüzde 50’lik dilimdeki yayılımı gösterir ve aykırı değerlere karşı daha dayanıklıdır.\n\nÇeyrekler açıklığı (IQR) şu şekilde hesaplanır: \\(IQR = Q3 - Q1\\)\nBurada \\(Q1\\): Birinci çeyrek, verilerin en küçük %25’lik kısmının üst sınırıdır. \\(Q3\\): Üçüncü çeyrek ise, verilerin en küçük %75’lik kısmının üst sınırıdır.\n\n# Daha büyük bir veri kümesi tanımlama\nveri_genis &lt;- c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n\n# Çeyreklerin hesaplanması\nq1_genis &lt;- quantile(veri_genis, 0.25) # Birinci çeyrek (Q1)\nq3_genis &lt;- quantile(veri_genis, 0.75) # Üçüncü çeyrek (Q3)\n\n# Çeyrekler açıklığı\ncayrekler_acikligi_genis &lt;- q3_genis - q1_genis\n\n# Çeyrekler açıklığını ekrana yazdırma\nprint(cayrekler_acikligi_genis) # Çıktı: 50\n\n75% \n 45 \n\n\nAçıklama: 1. Veri kümesi: \\((10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\\)\n2. Birinci çeyrek (Q1): \\((35)\\) 3. Üçüncü çeyrek (Q3): \\((85)\\) 4. Çeyrekler açıklığı: \\(Q3 - Q1 = 85 - 35 = 50\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÇeyrekler açıklığı\n\n\n\nAykırı Değerlere Dayanıklılık: Çeyrekler açıklığı, yalnızca orta yüzde 50’lik dilimi dikkate alır. Bu nedenle, aykırı değerlerden etkilenmez.\nDağılımın Anlaşılması: Veri setinin yoğunluğu ve yayılımı hakkında bilgi verir.\n\n\n\n\n\n\n\n\nÇeyrekler açıklığı\n\n\n\nÇeyrekler açıklığı, yalnızca veri setinin orta kısmını dikkate alır. Eğer veri setinin tümüne dair yayılım bilgisi gerekiyorsa, standart sapma gibi ölçülerle birlikte kullanılması daha yararlı olur.\n\n\nÇeyrekler açıklığı, aykırı değerlere dayanıklı bir yayılım ölçüsüdür ve özellikle veri setinin merkezi yayılımını anlamak için güçlü bir araçtır. Veri setindeki yoğunluğu ve merkezi eğilimi analiz etmek için sıkça kullanılır.\nÖzet\nMerkezi eğilim ölçüleri (ortalama, medyan, mod), verilerin merkezi bir noktada nasıl toplandığını anlamaya yardımcı olurken, yayılım ölçüleri (aralık, varyans, standart sapma, çeyrekler açıklığı), verilerin çeşitliliğini ve dağılımını anlamayı sağlar. Aykırı değerler, analiz sonuçlarını etkileyebileceği için dikkatli bir şekilde değerlendirilmelidir.\nReferanslar\nhttps://www.modernstatisticswithr.com/modchapter.html\nhttps://app.datacamp.com/learn/courses/introduction-to-statistics-in-r",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Merkezi Eğilim ve Yayılım Ölçüleri</span>"
    ]
  },
  {
    "objectID": "dagilim.html",
    "href": "dagilim.html",
    "title": "\n3  Dağılım Türleri ve Merkezi Limit Teoremi\n",
    "section": "",
    "text": "3.1 Ayrık Olasılık Dağılımları (Discrete Probability Distributions)\nAyrık olasılık dağılımları, yalnızca belirli ve sayılabilir değerler üzerinde tanımlanan olasılık dağılımlarıdır. Bu, değerlerin kesintili olduğu ve arada başka olasılıkların bulunmadığı anlamına gelir. Örneğin, bir zarın atılması durumunda sonuçlar yalnızca {1, 2, 3, 4, 5, 6} şeklindedir. Bir zarın 3.5 gibi bir sonuç göstermesi mümkün değildir, çünkü bu değer ayrık olasılıkların tanımı dışındadır.\nBu tür dağılımlar, bir olayın belirli bir sayıda gerçekleşme olasılığını modellemek ve tahmin etmek için kullanılır. Ayrık olasılık dağılımları, genellikle bir olayın “kaç kez” veya “hangi durumda” gerçekleştiğini anlamak için kullanılır.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dağılım Türleri ve Merkezi Limit Teoremi</span>"
    ]
  },
  {
    "objectID": "dagilim.html#ayrık-olasılık-dağılımları-discrete-probability-distributions",
    "href": "dagilim.html#ayrık-olasılık-dağılımları-discrete-probability-distributions",
    "title": "\n3  Dağılım Türleri ve Merkezi Limit Teoremi\n",
    "section": "",
    "text": "3.1.1 Binom Dağılımı (Binomial Distribution)\nBinom dağılımı, belirli bir sayıda bağımsız denemede bir olayın kaç kez başarılı olduğunu modellemek için kullanılır. Örneğin, 10 kez madeni para atıldığında, yazının kaç kez geleceğini tahmin etmek binom dağılımıyla modellenebilir.\nBinom dağılımı, her bir denemenin birbirinden bağımsız olduğu ve her birinde başarı veya başarısızlık gibi iki olası sonuç bulunduğu durumları ifade eder. Başarı olasılığı sabittir ve her bir deneme sonucu diğerlerinden bağımsızdır. Bu nedenle, belirli bir deneme sayısı için başarı sayısının olasılıklarını modellemek için oldukça kullanışlıdır.\n\n# dbinom() fonksiyonu ile olasılık hesaplama\n\ndbinom( # dbinom() fonksiyonu\n  x = 3, # x: Başarı sayısı\n  size = 10, # size: Toplam deneme sayısı\n  prob = 0.5# prob: Her bir denemede başarı olasılığı\n)\n\n[1] 0.1171875\n\n# 10 bağımsız denemede, başarı olasılığı 0.5 olan bir olayın tam 3 kez \n# gerçekleşme olasılığını hesaplar.\n\n\n\n\n\n\n\nset.seed() Fonksiyonu\n\n\n\nset.seed() fonksiyonu, rastgele sayı üretim süreçlerinde kullanılan bir kontrol mekanizmasıdır ve R’de rastgelelik ile çalışırken sonuçların yeniden üretilebilir olmasını sağlar.\nRastgelelik ve Sorunlar: Rastgele sayı üretimi aslında “sözde rastgele sayı üretimi” (pseudo-random number generation) olarak çalışır. Bu işlem bir başlangıç noktasına (seed) dayanır. Eğer başlangıç noktası aynıysa, üretilen rastgele sayılar da aynı olur.\nEğer set.seed() kullanılmazsa: R her çalıştırıldığında farklı rastgele sayılar üretir. Bu durum, analizlerin yeniden üretilebilirliğini zorlaştırır.\n\n# Rastgele sayılar üretme\nrunif(5)  \n\n[1] 0.1489761 0.9894432 0.6275486 0.6397097 0.5953498\n\n# 0 ile 1 arasında 5 rastgele sayı üretir. Her çalışmada sayılar da değişir.\n\nEğer set.seed() kullanılırsa: Kod her çalıştırıldığında aynı başlangıç noktası kullanılır ve aynı rastgele sayılar üretilir. Bu, kodun tutarlı ve yeniden üretilebilir olmasını sağlar.\n\n# Rastgelelik için sabit bir başlangıç noktası belirleme\nset.seed(123)\n# set.seed() kullanıldığında, rastgele sayı üretimi kontrol altına alınır.\n\n# 0 ile 1 arasında 5 rastgele sayı üretme\nrunif(5)  # Kod her çalıştırıldığında aynı sayılar üretilir. Değişmez.\n\n[1] 0.2875775 0.7883051 0.4089769 0.8830174 0.9404673\n\n\n\nset.seed(123) ile runif(5) kodu çalıştırıldığında, aynı yazılım ortamı ve aynı R sürümünde çalışan dünyadaki tüm bilgisayarlarda aynı sonucu verir.\n\n\n\n\n3.1.2 Poisson Dağılımı (Poisson Distribution)\nPoisson dağılımı, belirli bir zaman aralığında veya belirli bir alanda bir olayın kaç kez gerçekleştiğini modellemek için kullanılır. Örneğin, bir çağrı merkezine bir saatte gelen çağrıların sayısını tahmin etmek Poisson dağılımı ile modellenebilir.\nPoisson dağılımı, olayların sabit bir ortalama hızla meydana geldiği durumları ifade eder. Bu olaylar birbirinden bağımsızdır ve herhangi bir zaman veya alanda iki olayın aynı anda gerçekleşme olasılığı yok denecek kadar azdır. Özellikle nadir olayların sayısını modellemek için oldukça kullanışlıdır.\n\n# Poisson dağılımında belirli bir olayın gerçekleşme olasılığını hesaplama\n\n# dpois() fonksiyonu\ndpois( # dpois() fonksiyonu\n  x = 3, # x: Olay sayısı (kaç kez gerçekleştiği)\n  lambda = 5 # lambda: Ortalama olay sayısı (beklenen değer)\n)\n\n[1] 0.1403739\n\n# Ortalama 5 olay gerçekleşen bir durumda, 3 olayın gerçekleşme olasılığı\n\n\n3.1.3 Geometrik Dağılım (Geometric Distribution)\nGeometrik dağılım, bir denemede başarıdan önceki başarısızlıkların sayısını modellemek için kullanılır. Örneğin, bir zar atışında ilk kez 6 gelene kadar kaç başarısızlık (6 dışında başka bir sayı) yaşandığını tahmin etmek bu dağılım ile modellenebilir.\nGeometrik dağılım, bir olayın başarıyla sonuçlanana kadar tekrarlanmasını ifade eder. Başarıya ulaşma olasılığı, denemeler ilerledikçe giderek azalır. Teorik olarak olasılıklar sonsuza kadar devam eder; yani başarının hiçbir zaman gerçekleşmeme olasılığı sıfır değildir, ancak bu olasılık çok küçüktür. Bu nedenle geometrik dağılım, nadir olayların kaç deneme sonra gerçekleşebileceğini modellemek için oldukça kullanışlıdır.\n\n# Geometrik dağılımda olasılık hesaplama\ndgeom(x = 3, # x: Başarıdan önceki başarısızlık sayısı\n      prob = 0.2 # prob: Her bir denemede başarı olasılığı\n      )\n\n[1] 0.1024\n\n# Başarı olasılığı 0.2 olan bir deneyde, \n# ilk başarıdan önce tam 3 başarısızlık gerçekleşme olasılığını hesaplar.\n\n\n3.1.4 Hipergeometrik Dağılım (Hypergeometric Distribution)\nHipergeometrik dağılım, belirli bir özelliğe sahip nesnelerin bir örneklemde kaç kez seçileceğini modellemek için kullanılır. Örneğin, bir torbada 10 beyaz ve 5 siyah bilye varsa, rastgele seçilen 5 bilye içindeki beyaz bilye sayısını tahmin etmek için kullanılır.\nHipergeometrik dağılım, belirli bir popülasyondan yapılan örneklemin, geri koymadan seçilmesi durumunda belirli bir özelliğe sahip nesnelerin sayısını modellemek için kullanılır. Bu dağılımda, seçim yapıldıkça popülasyondaki nesnelerin oranı değiştiği için her seçimin olasılığı bağımsız değildir. Bu, örneklemler arası bağımlılığın olduğu durumları modellemek için oldukça kullanışlıdır.\n\n# Hipergeometrik dağılımda olasılık hesaplama\n\ndhyper( # dhyper() fonksiyonu\n  x = 3, # x: Örneklemde istenen özelliğe sahip nesne sayısı\n  m = 10, # m: Popülasyondaki istenen özelliğe sahip nesne sayısı\n  n = 5, # n: Popülasyondaki diğer nesne sayısı\n  k = 5 # k: Örneklem büyüklüğü\n)\n\n[1] 0.3996004\n\n# Popülasyonda 10 beyaz, 5 siyah bilye bulunan bir torbadan, rastgele \n# seçilen 5 bilyede tam 3 beyaz bilye bulunma olasılığını hesaplar.",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dağılım Türleri ve Merkezi Limit Teoremi</span>"
    ]
  },
  {
    "objectID": "dagilim.html#sürekli-olasılık-dağılımları-continuous-probability-distributions",
    "href": "dagilim.html#sürekli-olasılık-dağılımları-continuous-probability-distributions",
    "title": "\n3  Dağılım Türleri ve Merkezi Limit Teoremi\n",
    "section": "\n3.2 Sürekli Olasılık Dağılımları (Continuous Probability Distributions)",
    "text": "3.2 Sürekli Olasılık Dağılımları (Continuous Probability Distributions)\nSürekli Olasılık Dağılımları (Continuous Probability Distributions) Sürekli olasılık dağılımları, bir aralıktaki değerler üzerinde tanımlanan olasılık dağılımlarıdır. Bu, değerlerin kesintisiz olduğu ve belirli bir değer yerine bir aralık için olasılık hesaplandığı anlamına gelir. Örneğin, bir kişinin boyu 170 cm olabilir, ancak 170.1 cm veya 170.25 cm gibi sonsuz sayıda ara değer de mümkündür. Bu nedenle, sürekli dağılımlarda belirli bir değerin olasılığı sıfırdır, ancak bir aralık içerisindeki olasılık hesaplanabilir.\nBu tür dağılımlar, bir olayın belirli bir aralıktaki değerlerde gerçekleşme olasılığını modellemek ve tahmin etmek için kullanılır. Sürekli olasılık dağılımları, genellikle bir değişkenin “hangi aralıkta” ya da “ne kadar” gerçekleştiğini anlamak için kullanılır. Normal dağılım, üstel dağılım ve tekdüze dağılım gibi modeller sürekli olasılık dağılımlarına örnektir.\n\n3.2.1 Normal Dağılım (Normal Distribution)\nNormal dağılım, doğal olayların çoğunu modellemek için kullanılan çan şeklinde bir sürekli olasılık dağılımıdır. Örneğin, bir sınıftaki öğrencilerin boylarının ortalamalarının etrafında simetrik bir şekilde dağıldığını gözlemlemek, normal dağılımın bir örneğidir. (Çan Eğrisi)\nNormal dağılım, sürekli bir veri setinin ortalama etrafında yoğunlaşması ve uçlara doğru gidildikçe olasılıkların azalması durumunu modellemek için kullanılır. Normal dağılım simetriktir ve ortalama, medyan ve mod aynı noktada bulunur. Doğadaki birçok olayın normal dağılıma uyduğu gözlemlenmiştir ve bu nedenle istatistikte sıkça kullanılır.\n\n# Normal dağılımda olasılık yoğunluğunu hesaplama\ndnorm( # dnorm() fonksiyonu\n  x = 0,# x: Değerler\n  mean = 0, # mean: Ortalama\n  sd = 1 # sd: Standart sapma\n  )\n\n[1] 0.3989423\n\n# Ortalama 0 ve standart sapma 1 olan bir normal dağılımda, \n# tam olarak 0 değerinin olasılık yoğunluğunu hesaplar.\n\nNormal Dağılım Grafik Görünümü\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormal Dağılım Neden Önemli\n\n\n\nNormal dağılım, istatistik biliminde temel bir yere sahiptir, çünkü birçok doğal olay ve sosyal fenomen normal dağılım özellikleri sergilemektedir. Özellikle parametrik testler (örneğin, t-testi ve ANOVA) ve regresyon analizleri, verilerin normal dağılıma uygun olduğu varsayımı üzerine inşa edilmiştir. Normal dağılımın bu denli önemli olmasının temel nedenlerinden biri, Merkezi Limit Teoremi’dir.\nEtki değerlendirme yöntemlerinde, özellikle yarı deneysel yaklaşımlar (farkların farkı, eğilim skoru eşleştirme, regresyon süreksizliği gibi), analizlerin güvenilirliği ve geçerliliği büyük ölçüde normal dağılım varsayımına bağlıdır. Normal dağılım, hata terimlerinin ve sonuç değişkenlerinin istatistiksel gücünü ve analiz sonuçlarının doğruluğunu artırır. Parametrik testlerin (örneğin, t-testi, ANOVA) veya regresyon modellerinin etkin bir şekilde kullanılabilmesi için bu varsayım kritik bir öneme sahiptir. Normal dağılım sağlanmadığında, analiz sonuçları yanıltıcı olabilir ve etkilerin doğru tahmini güçleşir. Bu nedenle, yarı deneysel yöntemler uygulanmadan önce verilerin dağılımını kontrol etmek ve gerekirse gerekli dönüşümleri uygulamak, güvenilir ve anlamlı sonuçlar elde etmek için vazgeçilmez bir adımdır.\n\n\n\n\n\n\n\n\nMerkezi Limit Teoremi\n\n\n\nMerkezi Limit Teoremi, bağımsız ve aynı dağılıma sahip rastgele değişkenlerin aritmetik ortalamasının, örneklem büyüklüğü yeterince büyük olduğunda yaklaşık olarak normal dağılım göstereceğini ifade eder. Bu teorem, rastgele değişkenlerin varyansının sonlu olması durumunda geçerlidir ve örneklem büyüklüğü arttıkça, toplam veya ortalamanın dağılımının normal bir şekil alacağını belirtir. Merkezi Limit Teoremi, başlangıçta normal dağılıma uymayan verilerin bile, büyük örneklem boyutlarında ortalamalarının normal dağılıma yakınsama eğiliminde olduğunu söyler. Bu, istatistiksel analizlerde normal dağılımın neden bu kadar sık kullanıldığını açıklayan temel bir kavramdır.\n\n\n\n3.2.2 Standart Normal Dağılım\nStandart normal dağılım, ortalaması 0 ve standart sapması 1 olan özel bir normal dağılım türüdür. Normal dağılımların standartlaştırılmış hali olarak da düşünülebilir. Bu dağılımda, herhangi bir veri noktasının z-skoru, o noktanın ortalamadan kaç standart sapma uzaklıkta olduğunu gösterir.\nStandart normal dağılım, eğrisinin toplam alanı 1 olacak şekilde çan şeklindedir ve ortalama etrafında simetriktir. Eğrinin en yüksek noktası, ortalama olan 0 değerindedir ve değerler uçlara doğru gittikçe olasılık yoğunluğu azalır. Tüm normal dağılımlar, bu dağılıma dönüştürülebilir, böylece farklı birimlerdeki veriler karşılaştırılabilir ve analiz edilebilir hale gelir.\nBu dağılım, istatistikte sıklıkla kullanılır çünkü normal dağılım ile ilgili tüm olasılık hesaplamalarını kolaylaştırır. Örneğin, z-skoru kullanılarak bir veri noktasının hangi yüzdelik dilimde olduğu veya bir değerin olasılığı standart normal dağılım tabloları yardımıyla hesaplanabilir. Standart normal dağılım, istatistiksel analizlerde merkezi bir role sahiptir ve parametrik testler gibi birçok yöntemin temelini oluşturur.\n\n\n\n\n\n\nZ-Skoru\n\n\n\nZ-skoru, bir veri noktasının popülasyon ortalamasından kaç standart sapma uzaklıkta olduğunu gösteren bir ölçüdür. Z-skoru şu formülle hesaplanır:\n\\(Z = \\frac{X - \\mu}{\\sigma}\\)​\n\n\\(X\\): Veri noktası,\n\\(\\mu\\): Popülasyon ortalaması,\n\\(\\sigma\\) : Popülasyon standart sapmasıdır.\n\nZ-skoru, verilerin standartlaştırılmasını sağlar ve farklı dağılımların karşılaştırılmasına olanak tanır. Örneğin, \\(Z = 2\\) bir veri noktasının ortalamadan 2 standart sapma uzaklıkta olduğunu ifade eder.\n\n\n\n3.2.3 t-Dağılımı (t-Distribution)\nt-Dağılımı, örnekleme dağılımlarında kullanılan ve küçük örneklem boyutlarında popülasyon varyansının bilinmediği durumlar için tasarlanmış bir sürekli olasılık dağılımıdır. William Sealy Gosset tarafından geliştirilmiş ve başlangıçta Student’s t-distribution olarak adlandırılmıştır. t-dağılımı, normal dağılıma benzer bir yapıya sahiptir ancak daha geniş kuyruklara sahiptir. Bu, küçük örneklemlerle çalışırken uç değerlerin daha yüksek bir olasılıkla gerçekleştiği anlamına gelir.\nMatematiksel Açıklama\nBir örneklemden elde edilen ortalama ile popülasyon ortalamasının standart hata üzerinden farkını ölçmek için kullanılır.\n\n\n\n\n\n\nStandart Hata - Standart Error (SE)\n\n\n\nStandart hata, bir örneklem istatistiğinin (örneğin, ortalama) örnekleme dağılımındaki değişkenliğini özetleyen bir ölçüttür. Standart hata, örneklemin standart sapması (\\(s\\)) ve örneklem büyüklüğü ($n$) kullanılarak tahmin edilir ve şu formülle hesaplanır: \\(SE = \\frac{s}{\\sqrt{n}}\\)​\nStandart hata, örneklem büyüklüğü arttıkça azalır. Bu, daha büyük örneklemlerle tahminlerin daha kesin hale geldiği anlamına gelir. Bu ilişki, genellikle “n’in karekökü kuralı” olarak adlandırılır; standart hatayı yarıya indirmek için örneklem büyüklüğünün dört katına çıkarılması gerekir. Standart hata kavramı, Merkezi Limit Teoremi ile ilişkilidir, çünkü bu teorem, yeterince büyük bir örneklemde, örneklem istatistiklerinin yaklaşık olarak normal dağılım göstereceğini ifade eder.\nKarıştırmayın: Standard Sapma vs. Standart Hata\nStandart sapma ve standart hata farklı kavramlardır ve genellikle birbirine karıştırılır. Standart sapma, bireysel veri noktalarının yayılımını, yani veri setindeki değişkenliği ölçer. Öte yandan, standart hata, bir örneklemden hesaplanan bir istatistiğin (örneğin, örneklem ortalaması) farklı örneklemler arasında nasıl değiştiğini ölçer. Kısaca:\n\n\nStandart Sapma (SD): Tek bir veri setinin yayılımını ölçer.\n\nStandart Hata (SE): Örneklem ortalamalarının dağılımını ölçer.\n\nBu nedenle, standart hata bir tahminin hassasiyetini değerlendirirken kullanılırken, standart sapma, verilerin çeşitliliği hakkında bilgi sağlar.\n\n\nt-dağılımının temel formülü:\n\\(t = \\frac{\\bar{X}-\\mu}{\\frac{s}{\\sqrt{n}}}\\)​\nBurada:\n\n\n\\(\\bar{X}\\): Örneklem ortalaması,\n\n\\(\\mu\\): Popülasyon ortalaması,\n\n\\(s\\): Örneklem standart sapması,\n\n\\(n\\): Örneklem büyüklüğüdür.\n\nt- Dağılımının Özellikleri\n\n\nSimetrik ve Çan Şeklindedir: t-dağılımı, normal dağılım gibi çan şeklinde ve simetriktir.\n\nSerbestlik Derecesine (df - degrees of freedom) Bağlıdır: t-dağılımı, örneklem büyüklüğü azaldıkça daha geniş kuyruklara sahiptir. Serbestlik derecesi arttıkça (örneklem büyüdükçe), t-dağılımı normal dağılıma yaklaşır.\n\n\n\n\n\n\n\nSerbestlik Derecesi - Degrees of Freedom (df)\n\n\n\nSerbestlik derecesi, bir istatistiksel hesaplamada serbestçe değişebilen bağımsız veri noktalarının sayısını ifade eder. Bir parametrenin tahmininde kullanılan bağımsız veri sayısından, bu tahminde kullanılan ara hesaplamalar (örneğin, ortalama gibi) çıkarılarak hesaplanır. Örneğin, bir örneklemde varyans hesaplanırken, ortalama sabit bir değer olduğu için serbestlik derecesi \\(N−1\\) olarak belirlenir. Serbestlik derecesi, özellikle t-dağılımı ve ki-kare dağılımı gibi istatistiksel testlerde, dağılımın şekli ve genişliği üzerinde önemli bir etkiye sahiptir. Matematiksel olarak, serbestlik derecesi, bir rastgele vektörün kaç bileşeni bilindiğinde tam olarak belirlenebileceğini ifade eder.\n\n\n\n\nPopülasyon Standart Sapması Bilinmediğinde Kullanılır: Normal dağılım yerine t-dağılımı, popülasyon standart sapmasının bilinmediği ve küçük örneklem boyutlarıyla çalışıldığı durumlarda kullanılır.\n\nGeniş Kuyruklar: t-dağılımı, uç değerlerin daha yüksek bir olasılıkla gerçekleştiğini varsayar.\n\nKullanım Alanları\n\n\nt-Testleri: Küçük örneklemlerde iki grup arasındaki farkın anlamlılığını test etmek için kullanılır.\n\n\n\n\n\n\n\nt-Testleri\n\n\n\nt-testi, iki grup arasındaki ortalamaların istatistiksel olarak anlamlı bir fark gösterip göstermediğini belirlemek için kullanılan bir istatistiksel testtir. Küçük örneklemlerle çalışırken veya popülasyon varyansı bilinmediğinde kullanılır. t-testi, grup ortalamalarının farkını standart hata ile karşılaştırarak bir t-istatistiği hesaplar ve bu istatistiğin t-dağılımına göre anlamlılığını değerlendirir. Eğer t-istatistiği belirli bir eşik değerini (örneğin, \\(p&lt;0.05\\)) aşarsa, gruplar arasında anlamlı bir fark olduğu sonucuna varılır.\n\n\n\n# Örnek veri seti oluşturma\nset.seed(123)  # Rastgelelik kontrolü\ngroup1 &lt;- rnorm(15, mean = 100, sd = 10)  # Grup 1 için rastgele değerler\ngroup2 &lt;- rnorm(15, mean = 110, sd = 10)  # Grup 2 için rastgele değerler\n\n# Grupları görüntüleme\nprint(group1)\n\n [1]  94.39524  97.69823 115.58708 100.70508 101.29288 117.15065 104.60916\n [8]  87.34939  93.13147  95.54338 112.24082 103.59814 104.00771 101.10683\n[15]  94.44159\n\nprint(group2)\n\n [1] 127.86913 114.97850  90.33383 117.01356 105.27209  99.32176 107.82025\n [8]  99.73996 102.71109 103.74961  93.13307 118.37787 111.53373  98.61863\n[15] 122.53815\n\n# Bağımsız iki örneklem t-testi\nt_test_result &lt;- t.test(group1, group2, var.equal = TRUE) \n#t.test() Fonksiyonu: İki grubun ortalamalarının eşit olup olmadığını test eder.\n\n# Test sonuçlarını görüntüleme\nprint(t_test_result)\n\n\n    Two Sample t-test\n\ndata:  group1 and group2\nt = -1.685, df = 28, p-value = 0.1031\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -13.316499   1.296023\nsample estimates:\nmean of x mean of y \n 101.5238  107.5341 \n\n\n\nt-testi Sonuçlarının Anlamı:\n\n\nt = -1.685: t-istatistiği, iki grup arasındaki farkın standart hata cinsinden ne kadar büyük olduğunu gösterir. Negatif değer, Grup 1’in ortalamasının Grup 2’nin ortalamasından daha düşük olduğunu ifade eder, ancak bu fark istatistiksel olarak anlamlı olmayabilir.\n\ndf = 28: Serbestlik derecesi (degrees of freedom), veri setinin büyüklüğüne ve kullanılan modelin özelliklerine bağlıdır. Burada serbestlik derecesi 28’dir.\n\np-value = 0.1031: p-değeri, gruplar arasındaki farkın şansa bağlı olarak oluşma olasılığını ifade eder. Burada p=0.1031p = 0.1031p=0.1031, genellikle kabul edilen \\(\\alpha = 0.05\\) anlamlılık seviyesinden büyüktür. Bu, iki grup arasında istatistiksel olarak anlamlı bir fark olmadığını gösterir.\n\n95 percent confidence interval: [-13.316499, 1.296023]: Bu güven aralığı, iki grup arasındaki gerçek ortalama farkın hangi aralıkta olabileceğini ifade eder. Güven aralığı 0’ı içerdiği için (örneğin, -13.32 ile 1.30 arasında), iki grup arasında anlamlı bir fark olduğu söylenemez.\n\nmean of x = 101.5238, mean of y = 107.5341: Grup 1’in (x) ortalaması 101.52, Grup 2’nin (y) ortalaması 107.53’tür. Grup 2’nin ortalaması daha yüksek, ancak bu fark istatistiksel olarak anlamlı değildir.\n\n\n\nt-Dağılımının Regresyon Analizindeki Rolü:\n\n\n\nKatsayıların Anlamlılığını Test Etmek: Regresyon analizinde, bağımsız değişkenlerin katsayılarının istatistiksel olarak anlamlı olup olmadığını değerlendirmek için t-testi kullanılır. t-testi, katsayı tahmininin standart hatası ile katsayının değerini karşılaştırarak bir t-istatistiği hesaplar: \\(t = \\frac{\\hat{\\beta} - \\beta_0}{SE(\\hat{\\beta})}\\). Bu t-istatistiği, t-dağılımına göre p-değeri hesaplamada kullanılır.\n\n\n\n\n\n\n\np-değeri\n\n\n\np-değeri, bir istatistiksel test sonucunda, gözlenen verilerin veya daha uç sonuçların, test edilen dağılım altında tesadüfen ortaya çıkma olasılığını ifade eder.\nYukarıdaki bağlamda, t-istatistiği, t-dağılımında hesaplanır ve p-değeri bu istatistiğin t-dağılımında daha uç değerlere düşme olasılığını temsil eder. Bu, iki grup arasındaki farkın rastlantısal olma ihtimalini değerlendirmek için kullanılır. Küçük bir p-değeri (genellikle \\(p&lt;0.05\\)), farkın tesadüfi olmaktan çok anlamlı olabileceğini işaret eder.\n\n\n\n\nHata Terimlerinin Dağılımı: Regresyon analizinde, hata terimlerinin normal dağıldığı varsayılır. Ancak örneklem boyutu küçükse, katsayı tahminlerinin dağılımı normal değil, t-dağılımına uyar.\n\nKüçük Örneklemlerde Doğruluk: Eğer örneklem boyutu küçükse $n&lt;30$, katsayı tahminleri t-dağılımına göre değerlendirilir, çünkü küçük örneklemlerde t-dağılımı daha geniş kuyruklara sahiptir ve bu da uç değerleri daha iyi hesaba katar.\n\n\n\nÖrneklem Dağılımı: Küçük örneklem boyutları için ortalamaların dağılımını modellemek amacıyla t-dağılımı kullanılır.\n\n3.2.4 Üstel Dağılım (Exponential Distribution)\nÜstel dağılım, olaylar arasındaki bekleme sürelerini modellemek için kullanılan bir sürekli olasılık dağılımıdır. Örneğin, bir ATM’ye gelen müşteriler arasındaki işlem süreleri, üstel dağılımın tipik bir örneğidir.\nÜstel dağılım, bir olayın sabit bir hızla meydana geldiği durumlarda, olaylar arasındaki sürelerin dağılımını modellemek için kullanılır. Bu dağılım, sıfırdan başlar ve asimetrik bir şekilde sağa doğru uzanır. Olasılıklar, değerler arttıkça azalır, bu nedenle kısa sürelerde olay gerçekleşme olasılığı daha yüksektir. Üstel dağılım, genellikle bir olayın gerçekleşme hızını veya bekleme sürelerini analiz etmek için kullanılır.\n\n# Üstel dağılımda olasılık yoğunluğunu hesaplama\ndexp( \n  x = 2, # x: Değerler (süre)\n  rate = 1 # rate: Oran (olayın gerçekleşme hızı)\n  )\n\n[1] 0.1353353\n\n# Olayın gerçekleşme hızının 1 olduğu bir üstel dağılımda,\n# 2 birimlik bir sürede olayın gerçekleşme olasılığını hesaplar.\n\nÜstel Dağılım Grafik Görünümü\n\n\n\n\n\n\n\n\n\n3.2.5 Tekdüze Dağılım (Uniform Distribution)\nTekdüze dağılım, belirli bir aralıkta tüm değerlerin eşit olasılıkla meydana geldiği bir sürekli olasılık dağılımıdır. Örneğin, 1 ile 100 arasında rastgele bir sayı seçildiğinde her sayının eşit olasılıkla seçilebileceği bir durum, tekdüze dağılımın bir örneğidir.\nTekdüze dağılım, belirli bir alt ve üst sınır arasında sürekli bir veri setinin her değerinin eşit olasılıkla seçilme durumunu modellemek için kullanılır. Bu dağılımın olasılık yoğunluğu, verilen aralığın dışındaki tüm değerler için sıfırdır. Tekdüze dağılım, rastgele olayların eşit olasılıkla gerçekleştiği durumları analiz etmek için sıklıkla kullanılır.\n\n# Tekdüze dağılımda olasılık yoğunluğunu hesaplama\ndunif(\n  x = 0.5, # x: Değerler\n  min = 0, # min: Alt sınır\n  max = 1 # max: Üst sınır\n  )\n\n[1] 1\n\n# 0 ile 1 arasında bir tekdüze dağılımda,\n# 0.5 değerinin olasılık yoğunluğunu hesaplar.\n\nUniform Dağılım Grafik Görünümü\n\n\n\n\n\n\n\n\n\n3.2.6 Gamma Dağılımı (Gamma Distribution)\nGamma dağılımı, sürekli bir değişkenin pozitif değerler üzerinde nasıl dağıldığını modellemek için kullanılır. Örneğin, bir çağrı merkezinde müşteriler arasındaki bekleme sürelerinin toplamını analiz etmek, gamma dağılımının bir örneğidir.\nGamma dağılımı, belirli bir olayın toplam süresini veya bir olayın gerçekleşmesi için gereken süreyi modellemek için uygundur. Şekil ve ölçek parametrelerine bağlı olarak, dağılımın formu değişebilir. Bu dağılım, sağa çarpık olabilir ve sıfırdan başlayarak pozitif değerlere doğru genişler. Gamma dağılımı, bekleme süreleri, toplam zamanlama ve sigorta risk analizi gibi alanlarda yaygın olarak kullanılır.\n\n# Gamma dağılımında olasılık yoğunluğunu hesaplama\ndgamma(\n  x = 2, # x: Değerler (süre)\n  shape = 2, # shape: Şekil parametresi\n  scale = 1 # scale: Ölçek parametresi\n  )\n\n[1] 0.2706706\n\n# Şekil parametresi 2 ve ölçek parametresi 1 olan bir gamma dağılımında,\n# 2 değerinin olasılık yoğunluğunu hesaplar.\n\nGamma Dağılım Grafik Görünümü\n\n\n\n\n\n\n\n\nReferanslar\nhttps://bookdown.org/pbaumgartner/swr-harris/04-probability-distributions.html\nhttps://app.datacamp.com/learn/courses/introduction-to-statistics-in-r\nhttps://github.com/gedeck/practical-statistics-for-data-scientists/blob/master/R/code/Chapter%202%20-%20Data%20and%20sampling%20distributions.R",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dağılım Türleri ve Merkezi Limit Teoremi</span>"
    ]
  },
  {
    "objectID": "hipotez.html",
    "href": "hipotez.html",
    "title": "\n4  Güven Aralıkları ve Hipotez Testleri\n",
    "section": "",
    "text": "4.1 Güven Aralığı (Confidence Interval - CI)\nGüven aralığı, istatistikte bir anakütle parametresi için bir aralık kestirimi olup, çıkarımsal istatistikte önemli bir araçtır. Tek bir noktadan tahmin yerine, parametrenin belirli bir olasılıkla içinde bulunabileceği alt ve üst sınırlarla tanımlanan bir aralık sunar. Güven aralıkları, tahminin ne kadar güvenilir olduğunu ifade eder ve bu güvenilirlik, seçilen güven düzeyiyle (%90, %95 veya %99 gibi) belirtilir. Yüksek bir güven düzeyi seçildiğinde güven aralığı genişler, bu da parametreyi kapsama olasılığını artırır. Güven aralıkları genellikle, tahmin yönteminin normal dağılım gibi belirli varsayımları karşılaması durumunda hesaplanır. Çıkarımsal istatistikte, anakütle parametreleri hakkında daha anlamlı ve güvenilir sonuçlara ulaşmayı sağlar ve hipotez testleriyle birlikte kullanıldığında analizlerin istatistiksel gücünü artırır.\nGüven Aralıklarının Hesaplanması\nR’de güven aralıklarını hesaplamak oldukça basittir. Temel R paketinde doğrudan güven aralığı hesaplayan bir fonksiyon bulunmasa da, z.test() ve t.test() fonksiyonlarını kullanarak ortalamalar için güven aralıklarını hesaplayabiliriz (bu yöntemler oranlar için kullanılamaz).",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Güven Aralıkları ve Hipotez Testleri</span>"
    ]
  },
  {
    "objectID": "hipotez.html#güven-aralığı-confidence-interval---ci",
    "href": "hipotez.html#güven-aralığı-confidence-interval---ci",
    "title": "\n4  Güven Aralıkları ve Hipotez Testleri\n",
    "section": "",
    "text": "4.1.1 Popülasyon Standart Sapmasını Biliniyorsa: z.test() Fonksiyonu\nEğer popülasyon standart sapmasını biliyorsak, z.test() fonksiyonunu (BSDA paketinden) kullanabiliriz. Bu fonksiyona popülasyon standart sapmasını (sigma.x) ve güven düzeyini (conf.level) sağlamamız gerekir. Örnek bir kullanım aşağıda verilmiştir:\n\n# Gerekli paketin yüklenmesi\n# install.packages(\"BSDA\") \nlibrary(\"BSDA\") \n\n# z.test fonksiyonu ile güven aralığı hesaplama\nz_test1 &lt;- z.test(\n  choc.ankara,       # Analiz edilecek veri seti\n  sigma.x = 2,       # Popülasyonun bilinen standart sapması\n  conf.level = 0.95  # Güven düzeyi (%95)\n)\n\n# Güven aralığını döndürme\nz_test1$conf.int\n\n[1] 39.94773 40.02613\nattr(,\"conf.level\")\n[1] 0.95\n\n# Hesaplanan güven aralığını döndürür. Bu, belirlenen %95 güven düzeyi ile \n# çikolata barlarının ağırlık ortalaması için tahmin edilen aralıktır.\n\n\nBu sonuç, çikolata barlarının ağırlık ortalamasının %95 güven düzeyiyle 39.94773 gram ile 40.02613 gram arasında olduğunu göstermektedir. Başka bir deyişle, elimizdeki verilere dayanarak, gerçek ortalama ağırlığın bu aralıkta yer alması oldukça olasıdır. Ancak, bu güven aralığı %100 kesinlik sunmaz; %5’lik bir hata payı mevcuttur.\nGüven düzeyi %95 olarak belirlenmiştir. Bu da, benzer şekilde birçok örneklem üzerinden analiz yapılsa, bu örneklemlerin %95’inin gerçek ortalamayı belirtilen aralıkta içerme olasılığını ifade eder. Dolayısıyla, çikolata barlarının üretim sürecinin genel olarak tutarlı ve standartlara uygun olduğunu söyleyebiliriz. Üretimdeki varyasyonun düşük olması, kalite kontrol süreçlerinin etkili bir şekilde işlediğini göstermektedir.\n\n\n\n\n\n\n\nNeden “%95” Güven Aralığı\n\n\n\nGüven aralıklarını hesaplarken %95 güven düzeyinin önemi, istatistikte bir denge noktası olarak kabul edilmesinden kaynaklanır. %95 güven düzeyi, bir tahminin güvenilirliğini makul bir kesinlik düzeyinde ifade ederken, aynı zamanda hata payını (%5) da kontrol edilebilir seviyede tutar. Bunun birkaç temel nedeni vardır:\n\n\nPratik Denge: %95 güven düzeyi, güvenilirlik ve belirsizlik arasında dengeli bir nokta sağlar. Daha yüksek bir güven düzeyi (%99) aralığı genişletir, bu da sonuçları daha az hassas hale getirebilir. Daha düşük bir güven düzeyi (%90) ise daha dar aralık sağlar ancak güvenilirlik azalır. %95, bu ikisi arasında ideal bir denge olarak kabul edilir.\n\nGeleneksel Kabul: İstatistiksel analizde %95 güven düzeyi, literatürde ve uygulamada yaygın olarak kabul edilmiş bir standarttır. Bu standartlaşma, farklı çalışmalar arasında karşılaştırma yapmayı kolaylaştırır.\n\nHata Payı (%5): %95 güven düzeyi, tahmin edilen aralığın gerçek parametreyi kapsama olasılığının %95 olduğunu, yani yalnızca %5 hata payı olduğunu ifade eder. Bu hata payı, birçok durumda bilimsel kabul için yeterince düşük bulunur.\n\nNormatif Kullanım: Pek çok disiplin ve uygulamada (örneğin, biyoloji, sosyal bilimler, ekonomi) %95 güven düzeyi yaygın olarak kullanılır ve bu düzeyin ötesinde bir anlam çıkarma genellikle “istatistiksel olarak anlamlı” kabul edilir.\n\nZ Değeri: %95 güven düzeyi, standart normal dağılımda \\(z = \\pm 1.96\\) sınırına karşılık gelir. Bu, istatistiksel analizlerde kolaylıkla hesaplanabilen ve yorumlanabilen bir değerdir.\n\nSonuç olarak, %95 güven aralığı, tek bir tahminin doğruluğunu ifade etmez. Bunun yerine, birçok örneklem alınarak yapılan hesaplamalarda, bu aralıkların çoğunluğunun (%95) gerçek değeri kapsayacağını garanti eder.\n\n\n\n4.1.2 Popülasyon Standart Sapmasını Bilinmiyorsa: t.test() Fonksiyonu\nPratikte çoğu zaman popülasyon standart sapmasını bilmediğimiz durumlarla karşılaşırız. Bu durumda t.test() fonksiyonunu kullanabiliriz. Burada yalnızca güven düzeyini (conf.level) belirteriz ve fonksiyon, standart hatayı kullanarak güven aralığını oluşturur.\n\n# T-testi ile güven aralığı hesaplama\nt_test1 &lt;- t.test(\n  choc.ankara,       # Analiz edilecek veri seti\n  conf.level = 0.95  # Güven düzeyi (%95)\n)\n\n# Hesaplanan güven aralığını döndürme\nt_test1$conf.int\n\n[1] 39.94724 40.02661\nattr(,\"conf.level\")\n[1] 0.95",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Güven Aralıkları ve Hipotez Testleri</span>"
    ]
  },
  {
    "objectID": "hipotez.html#hipotez-testleri-hypothesis-tests",
    "href": "hipotez.html#hipotez-testleri-hypothesis-tests",
    "title": "\n4  Güven Aralıkları ve Hipotez Testleri\n",
    "section": "\n4.2 Hipotez Testleri (Hypothesis Tests)",
    "text": "4.2 Hipotez Testleri (Hypothesis Tests)\nHipotez testleri, istatistiksel analizlerde belirli bir iddianın doğruluğunu değerlendirmek için kullanılan yöntemlerdir. Hipotez testi, bir null hipoteze (yokluk hipotezi) karşı kanıtların gücünü değerlendirmek için kullanılan bir istatistiksel yöntemdir. Null hipotez, popülasyonda herhangi bir fark, ilişki veya etkinin olmadığını varsayar. Bu yöntem, null hipotezin doğru olduğunu kabul ederek, örneklem verilerinde gözlemlenen veya daha uç sonuçların olasılığını hesaplar. Bu olasılık, p-değeri ile ifade edilir.\nEğer p-değeri yeterince küçükse (örneğin, genellikle \\(p&lt;0.05\\)), null hipotez reddedilir ve alternatif hipotezin doğru olabileceği sonucuna varılır. Ancak, null hipotez asla “kabul edilmez” veya “kanıtlanmaz.” Sadece mevcut verilerle reddedilemeyecek kadar güçlü olduğu düşünülür.\nBu süreç, bir ceza davasına benzetilebilir: Sanık suçsuz kabul edilir (null hipotez reddedilmez) ancak suçluluğu yeterince güçlü kanıtlarla gösterildiğinde (istatistiksel olarak anlamlı sonuçlar) sanık suçlu ilan edilir (null hipotez reddedilir).\nBu yöntemlerde iki ana hipotez tanımlanır:\n\n\nNull hipotez (\\(H_0\\)): Varsayılan durum ya da iddia (örneğin, iki grup arasında fark yoktur).\n\nAlternatif hipotez (\\(H_1\\)): Test edilmek istenen yeni iddia (örneğin, iki grup arasında fark vardır).\n\nVeriler toplandıktan sonra, bu hipotezler istatistiksel araçlarla değerlendirilir. Hipotez testinin sonucunda elde edilen p-değeri, \\(H_0\\)’ın doğru olduğu varsayımı altında gözlemlenen sonuçların olasılığını ifade eder. Eğer p-değeri, önceden belirlenmiş anlamlılık düzeyinden (örneğin, \\(\\alpha\\) = 0.05) küçükse, null hipotez reddedilir ve alternatif hipotezin doğru olabileceği kabul edilir.\nAdım 1. Araştırma Sorusu Belirlenir\nBir palet çikolata barımız olduğunu ve bunların Ankara Çikolatacısı’na ait olup olmadığından emin olmadığımızı varsayalım. Bu çikolata barlarının ağırlıkları, bu barların Ankara Çikolatacısı’na ait olma olasılığı hakkında bize ne söyleyebilir?\n\n# Rastgelelik için sabit bir başlangıç noktası belirleme\nset.seed(20)\n\n# Normal dağılımdan rastgele veri üretme\nchoc.palet &lt;- rnorm(\n  20,       # Üretilecek rastgele sayıların toplam miktarı\n  mean = 42, # Normal dağılımın ortalama değeri\n  sd = 2     # Normal dağılımın standart sapması\n)\n\n# Veri özet istatistiklerini görüntüleme\nsummary(choc.palet)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  36.22   40.81   41.41   41.62   42.87   45.57 \n\n\nAraştırma sorusu: “Bu çikolata barlarının ağırlıkları, onların Ankara Çikolatacısı’na ait olduğunu gösteriyor mu?”\nAdım 2. Null Hipotezi (\\(H_0\\)), ve Alternatif Hipotez (\\(H_1\\)) Belirlenir\nAraştırma sorusuna dayanarak, null ve alternatif hipotezler oluşturulur. Örneğin, Adım 1’deki araştırma sorusunu cevaplamak için, iki grup arasında bir karşılaştırma yapmamız gerekir: Ankara Çikolataları’ndan olduğu varsayılan çikolata barlarının ağırlıkları ve diğer çikolata barlarının ağırlıkları. Bu durumda, her iki grubun popülasyon ortalamalarını sırasıyla \\(\\mu_1\\) ve \\(\\mu_2\\) olarak ifade edilir.\n\n\n\n\n\n\nYunan Alfabesi ve istatistik Sembolleri\n\n\n\nYunan alfabesindeki \\(\\mu\\) (mu) harfi istatistikte popülasyon ortalamasını bembolize etmektedir. Buna benzer olarak, \\(\\sigma\\) (sigma), \\(\\alpha\\) (alfa) gibi semboller de kullanılmaktadır. Sembollerle alakalı daha fazla bilgi edinmek için: https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/\n\n\nNull hipotez \\(H_0\\), genellikle “etki yok” ya da “fark yok” ifadesini içeren bir parametre durumu olmalıdır. Bu örnekte, null hipotez şu şekilde ifade edilir:\n\\(H_0\\): \\(\\mu_1 = \\mu_2\\) ya da \\(\\mu_1 - \\mu_2 = 0\\)\n\nBu, çikolata barlarının ağırlıklarının Ankara Çikolataları’nın ortalama ağırlığı olan (\\(\\mu_1 = 40\\)) 40 gramdan farklı olmadığını varsayar.\n\nAlternatif hipotez (\\(H_1\\)), genellikle doğru olduğunu düşündüğümüz ya da test etmek istediğimiz iddiayı ifade eder. Bu durumda, alternatif hipotez şu şekilde olabilir:\n\\(H_1\\): \\(\\mu_1 \\neq \\mu_2\\) ya da \\(\\mu_1 - \\mu_2 \\neq 0\\)\n\nBu, çikolata barlarının ağırlıklarının Ankara Çikolataları’nın ortalama ağırlığından (\\(\\mu_1 = 40\\)) farklı olduğunu ifade eder.\n\nAdım 3. Test İstatistiği ve p-değeri Hesaplanır\n\n4.2.1 Ortalamalar için Hipotez Testleri (Hypothesis Tests for Means)\n\n4.2.1.1 Standart Sapma Biliniyorsa (Known Standard Deviation)\nBir palet çikolata üzerinde, bu çikolataların Ankara Çikolataları’na ait olup olmadığını test etmek isteniyor. Bu amaçla, popülasyon standart sapmasının bilindiği durumda kullanılan z-testi yöntemi kullanılır. Test sırasında şu hipotezler tanımlanır:\n\nNull hipotez (\\(H_0\\)): Çikolata paletinde yer alan çikolataların ağırlık ortalaması Ankara Çikolataları’nın ortalaması olan 40 gramdır (\\(\\mu_1 = \\mu_2 = 40\\)).\nAlternatif hipotez (\\(H_1\\)): Çikolata paletinde yer alan çikolataların ağırlık ortalaması 40 gramdan farklıdır (\\(\\mu_1 \\neq \\mu_2 \\neq 40\\)).\n\nPopülasyon standart sapmasının \\(\\sigma = 2\\) olduğu bilindiğinden (adım 1.’de choc.palet veri setinde standart sapma 2 (sd = 2) olarak belirlenmişti.), bu değer z-testi sırasında kullanılacaktır. Ayrıca, güven düzeyini \\(1 - \\alpha = 0.95\\) (yani %95) olarak belirledik. Testi gerçekleştirmek için BSDA paketindeki z.test() fonksiyonunu kullanılır. Test sonucunda elde edilen p-değeri, null hipotezin doğru olduğu varsayımı altında gözlemlenen verilerin veya daha uç sonuçların olasılığını gösterecektir.\nEğer hesaplanan p-değeri, belirlenen anlamlılık düzeyinden (\\(1 - \\alpha = 0.95\\), yani yüzde 95 güven aralığı) küçükse, null hipotezi reddedilir. Bu durumda, çikolataların Ankara Çikolataları’na ait olmadığı sonucuna varabilir. Eğer p-değeri büyükse, null hipotezi reddedemeyiz ve çikolataların ağırlıklarının Ankara Çikolataları’na ait olduğu varsayımını destekleyen bir sonuç elde edilmiş olur.\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(BSDA)\n\n# Z-testi ile hipotez testi\nz_test2 &lt;- z.test(\n  x = choc.palet,     # Test edilecek veri: Çikolata barlarının ağırlıkları\n  mu = 40,            # Null hipotezdeki popülasyon ortalaması: 40 gram\n  sigma.x = 2,        # Popülasyon standart sapması: 2 gram\n  conf.level = 0.95   # Güven düzeyi: %95\n)\n\n# Hesaplanan p-değerini görüntüleme\nz_test2$p.value\n\n[1] 0.0002807644\n\n\n\nTest sonucunda elde edilen p-değeri = 0.0002807644, genellikle kabul edilen anlamlılık düzeyi olan \\(\\alpha = 0.05\\)’ten (hatta \\(\\alpha = 0.01\\)’den) oldukça küçüktür. Bu, gözlemlenen verilerin null hipotez (\\(H_0 = \\mu_2 = 40\\)) doğru olduğu varsayımı altında ortaya çıkma olasılığının son derece düşük olduğunu göstermektedir. Bu nedenle, null hipotez reddedilmektedir.\nBu sonuca göre, çikolata paletindeki çikolataların ağırlık ortalamasının Ankara Çikolataları’nın standart ağırlık ortalaması olan 40 gramdan anlamlı derecede farklı olduğu söylenebilir. Dolayısıyla, bu çikolataların Anakara Çikolataları’na ait olmadığını gözlemlenen farkın tesadüfen oluşma olasılığının çok düşük olduğunu ifade etmektedir.\nSonuç olarak bu test sonuçlarına dayanarak, çikolata paletindeki çikolataların Ankara Çikolataları’na ait olmadığı yönünde güçlü bir kanıya varılabilir.\n\n\n4.2.1.2 Standart Sapma Bilinmiyorsa (Unknown Standard Deviation)\nBir palet çikolata üzerinde, bu çikolataların Ankara Çikolataları’na ait olup olmadığını test etmek isteniyor. Ancak bu durumda, popülasyon standart sapmasının bilinmediği varsayılmaktadır. Standart sapmanın bilinmediği durumlarda, t-testi yöntemi kullanılır ve bu yöntem R’ın temel fonksiyonlarından olan t.test() ile kolaylıkla uygulanabilir. Bu yöntem, aşağıdaki formül ile tanımlanan dağılıma dayanır:\n\\(\\frac{\\bar{X} - \\mu}{\\frac{s_x}{\\sqrt{n}}} \\sim t_{n-1}\\)\nBurada \\(t_{n-1}\\) , \\(n-1\\) serbestlik derecesine sahip Student’s t-dağılımını ifade eder. Testi gerçekleştirmek için yalnızca güven düzeyini belirtmek yeterlidir. Örneğin, güven düzeyi \\(1 - \\alpha = 0.95\\) olarak belirlenebilir. Bu durumda, çikolata paletindeki çikolataların Ankara Çikolataları’na ait olup olmadığı, popülasyon standart sapması bilinmeden değerlendirilmiş olur.\n\n# T-testi ile hipotez testi\nt_test2 &lt;- t.test(\n  x = choc.palet,     # Test edilecek veri: Çikolata paleti ağırlıkları\n  mu = 40,            # Null hipotezdeki popülasyon ortalaması: 40 gram\n  conf.level = 0.95   # Güven düzeyi: %95\n)\n\n# Hesaplanan p-değerini görüntüleme\nt_test2$p.value\n\n[1] 0.003109143\n\n\n\nTest sonucunda elde edilen p-değeri = 0.0031, genellikle kabul edilen anlamlılık düzeyi olan \\(\\alpha = 0.05\\)’ten küçük bir değerdir. Bu durum, null hipotezin (\\(H_0 = \\mu_2 = 40\\)) doğru olduğu varsayımı altında, gözlemlenen verilerin veya daha uç sonuçların ortaya çıkma olasılığının oldukça düşük olduğunu göstermektedir. Bu nedenle, null hipotez reddedilmektedir.\nBu sonuca göre, çikolata paletindeki çikolataların ağırlık ortalamasının Ankara Çikolataları’nın standart ağırlık ortalaması olan 40 gramdan anlamlı derecede farklı olduğu söylenebilir. Elde edilen düşük p-değeri, bu farkın istatistiksel olarak güçlü bir anlamlılık taşıdığını ve gözlemlenen sonucun rastgele oluşma ihtimalinin oldukça düşük olduğunu ifade etmektedir.\nSonuç olarak, çikolata paletindeki çikolataların Ankara Çikolataları’na ait olmadığı yönünde güçlü bir bulgu elde edilmiştir. Bu çikolataların başka bir üreticiye ait olabileceği değerlendirilmektedir.\n\n\n4.2.2 İki Örneklem Testleri (two-sample Tests)\n\n4.2.2.1 Birleştirilmemiş İki Örneklem t-testi (Unpooled Two-sample t-test)\nİki farklı çikolata partisini karşılaştırarak, bunların aynı fabrikadan gelip gelmediklerini test etmek istiyoruz. İlk parti 40, ikinci parti 45 paket çikolatadan oluşmaktadır. Popülasyon ortalamaları (\\(\\mu_1\\) ve \\(\\mu_2\\)) ve standart sapmaları bilinmediğinden, bu partiler arasındaki farkı değerlendirmek için birleştirilmemiş iki örneklem t-testi uygulanır.\nHipotezler:\n\nNull hipotez (\\(H_0\\)): İki partinin ortalamaları arasında fark yoktur (\\(\\mu_1 = \\mu_2 = 40\\)).\nAlternatif hipotez (\\(H_1\\)): İki partinin ortalamaları arasında fark vardır (\\(\\mu_1 \\neq \\mu_2 \\neq 40\\)).\n\nÖrneklem verilerini, ortalamaları sırasıyla 45 ve 47 olan normal dağılımlardan üreteceğiz. Ancak, bu bilgilerin bilinmediğini varsayacağız. Ayrıca, örneklem aldığımız dağılımların popülasyon standart sapmalarının 2 olduğu bilinse de, test sırasında bu bilginin de mevcut olmadığını kabul edeceğiz. Gerçek popülasyon ortalamalarını \\(\\mu_1\\) ve \\(\\mu_2\\) ile ifade edeceğiz.\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(tidyverse)\n\n# Tekrarlanabilirlik için rastgelelik sabitleniyor\nset.seed(123)\n\n# Verilerin simülasyonu\nparti1 &lt;- rnorm(40, mean = 45, sd = 2) # Birinci partinin ağırlıkları\nparti2 &lt;- rnorm(45, mean = 47, sd = 2) # İkinci partinin ağırlıkları\n\n# Veri çerçevesi oluşturma\nParti &lt;- c(rep(\"1\", 40), rep(\"2\", 45)) # Partileri temsil eden faktör değişken\nCikolata &lt;- c(parti1, parti2)          # Birleştirilmiş çikolata ağırlıkları\ntablo &lt;- tibble(Parti, Cikolata)\n\n# Boxplot ile görselleştirme\nggplot(tablo, aes(x = Parti, y = Cikolata)) +\n  geom_boxplot() +\n  labs(\n    title = \"Cikolata Partilerinin Agirlik Dagilimi\",\n    x = \"Parti\",\n    y = \"Agirlik\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n# Birleştirilmemiş iki örneklem T-testi\nt_test3 &lt;- t.test(\n  parti1,              # Birinci örneklem verisi\n  parti2               # İkinci örneklem verisi\n)\n\n# Test sonuçlarını görüntüleme\nt_test3\n\n\n    Welch Two Sample t-test\n\ndata:  parti1 and parti2\nt = -4.8753, df = 82.135, p-value = 5.227e-06\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.699807 -1.135072\nsample estimates:\nmean of x mean of y \n 45.09037  47.00781 \n\n\n\nElde edilen p-değeri = 5.227e-06, genellikle kabul edilen anlamlılık düzeyi olan \\(\\alpha = 0.05\\)’ten ve hatta \\(\\alpha = 0.01\\)’den bile çok küçüktür. Bu durum, iki çikolata partisinin ağırlık ortalamalarının aynı olduğu null hipotezin (\\(H_0\\)) doğru olma olasılığının son derece düşük olduğunu göstermektedir. Bu nedenle, null hipotez reddedilmektedir.\nBu sonuca göre, iki çikolata partisi arasında ağırlık ortalamaları açısından anlamlı bir fark olduğu ve partilerin muhtemelen farklı fabrikalardan geldiği söylenebilir.\n\n\n\n\n\n\n\ne-” nedir?\n\n\n\n“e-” ifadesi, bilimsel gösterimde kullanılan bir kısaltmadır ve “10 üzeri” anlamına gelir. Örneğin, 5.227e-06 ifadesi, \\(5.227 \\times 10^{-6}\\) yani 0.000005227 anlamına gelir. Bu gösterim, çok küçük veya çok büyük sayıları kolayca ifade etmek için kullanılır.\n\n\nBu sefer de \\(H_0: \\mu_1 = \\mu_2\\) yerine \\(H_1:\\mu_1 \\leq \\mu_2\\) hipotezi test edilsin.\n\n# Tek yönlü T-testi\nt_test4 &lt;- t.test(\n  parti1,                # Birinci örneklem verisi\n  parti2,                # İkinci örneklem verisi\n  alternative = \"less\")\n# Tek yönlü test: Birinci partinin ortalamasının, ikinci partinin ortalamasına \n# eşit veya daha küçük olduğunu test eder\n\n# Test sonuçlarını görüntüleme\nt_test4\n\n\n    Welch Two Sample t-test\n\ndata:  parti1 and parti2\nt = -4.8753, df = 82.135, p-value = 2.614e-06\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n      -Inf -1.263149\nsample estimates:\nmean of x mean of y \n 45.09037  47.00781 \n\n\n\nP-değeri = 2.614e-06 olduğu için null hipotez reddedilir. Birinci partinin ağırlık ortalamasının, ikinci partininkinden anlamlı derecede daha küçük olduğu sonucuna varılır (\\(\\mu_1 \\leq \\mu_2\\)).\n\nBu testte, tek yönlü bir hipotez testi uygulandığı için null hipotezin reddedildiği sonucuna varılmıştır. Tek yönlü testler, pratikte daha yaygındır çünkü veri setleri arasındaki ilişkinin daha odaklı bir açıklamasını sağlar. Örneğin, devlet yardımı alan firmaların ihracat performanslarını değerlendirdiğimizi düşünelim. Burada, yardımların ihracatı artırıp artırmadığıyla ilgileniyoruz, yani tek yönlü bir alternatif hipotez (\\(H_1 :ihracat performansı artar\\)) kullanırız. Yardımların sadece ihracatı değiştirdiğini, ancak artıp artmadığını bilmediğimiz bir durumda ise iki yönlü bir alternatif hipotez (\\(H_1:ihracat performansı farklıdır\\)} tercih edilir. Ancak genelde bu tür analizlerde asıl odak, ihracatın artması üzerindedir, bu yüzden tek yönlü test daha uygun olur.\n\n4.2.2.2 Birleştirilmiş İki Örneklem t-testi (Pooled Two-sample t-test)\nEğer örneklemlerin aynı standart sapmaya sahip dağılımlardan geldiğini biliyorsanız, birleştirilmiş iki örneklem t-testi (pooled t-test) uygulanabilir. Bu test, iki grup arasında ortalamalar açısından fark olup olmadığını değerlendirmek için kullanılır ve grup varyanslarının eşit olduğu varsayılır. R’de bu test, t.test fonksiyonunda var.equal = TRUE argümanı ile belirtilir.\n\n# Birleştirilmiş iki örneklem T-testi\nt_test_pooled &lt;- t.test(\n  parti1,           # Birinci parti verisi\n  parti2,           # İkinci parti verisi\n  var.equal = TRUE  # Varyansların eşit olduğu varsayımı\n)\n\n# Test sonuçlarını görüntüleme\nt_test_pooled\n\n\n    Two Sample t-test\n\ndata:  parti1 and parti2\nt = -4.8705, df = 83, p-value = 5.254e-06\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.700462 -1.134417\nsample estimates:\nmean of x mean of y \n 45.09037  47.00781 \n\n\n\n\n\nt-istatistiği (\\(t=−4.8705\\)):\n\nT-testi sonucunda hesaplanan t-değeri, iki grup arasındaki ortalama farkın standart hata cinsinden ne kadar uzakta olduğunu gösterir. Burada elde edilen negatif değer, birinci grubun ortalamasının ikinci grubunkinden daha düşük olduğunu işaret eder.\n\n\n\nSerbestlik Derecesi (\\(df=83\\)):\n\nTestte kullanılan serbestlik derecesi, veri setlerinin boyutlarına ve test türüne bağlıdır. Burada, iki grubun toplam gözlem sayısından (40 + 45) varyans hesaplamaları için kullanılan parametreler çıkarılarak \\(df=83\\) elde edilmiştir.\n\n\n\nP-değeri :\n\nElde edilen p-değeri = 5.254e-06, kabul edilen anlamlılık düzeyi (\\(\\alpha=0.05\\)) ve hatta daha düşük bir düzey olan (\\(\\alpha=0.05\\)) ile karşılaştırıldığında oldukça küçüktür. Bu, null hipotezin (\\(H_0\\): iki grup ortalaması arasında fark yoktur) reddedilmesine neden olur.\nSonuç: İki grup arasında ortalamalar açısından istatistiksel olarak anlamlı bir fark vardır.\n\n\n\nGüven Aralığı:\n\n%95 güven düzeyi ile, iki grup arasındaki ortalama farkın popülasyonda −2.7-2.7−2.7 ile −1.13-1.13−1.13 arasında olduğu tahmin edilmektedir.\nNegatif aralık, birinci grubun ortalamasının ikinci grubunkinden daha düşük olduğunu teyit eder.\n\n\n\nÖrneklem Ortalamaları\n\nBirinci grup (x): Ortalama ağırlık 45.09.\nİkinci grup (y): Ortalama ağırlık 47.01.\nBu fark, test sonuçlarında da anlamlı bulunmuştur.\n\n\n\n\n4.2.3 Sonuç:\n\nBu test, iki çikolata partisi arasındaki ağırlık ortalamalarının anlamlı derecede farklı olduğunu göstermektedir. Elde edilen negatif değerler, birinci partinin ortalamasının ikinci partininkinden daha düşük olduğunu desteklemektedir. İstatistiksel olarak anlamlı bu fark, partilerin muhtemelen farklı fabrikalardan geldiğini düşündürmektedir.\n\nReferans\nhttps://rpubs.com/syedafzalali/R3\nhttps://uw-statistics.github.io/Stat311Tutorial/confidence-intervals.html\nhttps://uw-statistics.github.io/Stat311Tutorial/hypothesis-tests.html\nhttps://www.modernstatisticswithr.com/basicstatistics.html\nhttps://openintro-ims.netlify.app/foundations-of-inference\nhttps://bookdown.org/pbaumgartner/swr-harris/",
    "crumbs": [
      "Temel İstatistik",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Güven Aralıkları ve Hipotez Testleri</span>"
    ]
  },
  {
    "objectID": "veri_manipulasyonu.html",
    "href": "veri_manipulasyonu.html",
    "title": "\n5  Veri Manipülasyonu\n",
    "section": "",
    "text": "5.1 Temel Veri Manipülasyonu İşlemleri",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Veri Manipülasyonu</span>"
    ]
  },
  {
    "objectID": "veri_manipulasyonu.html#temel-veri-manipülasyonu-işlemleri",
    "href": "veri_manipulasyonu.html#temel-veri-manipülasyonu-işlemleri",
    "title": "\n5  Veri Manipülasyonu\n",
    "section": "",
    "text": "5.1.1 Sütun Seçimi: select()\n\nVeri analizi sırasında, genellikle yalnızca belirli sütunlarla çalışmak ya da analiz için gereksiz sütunları veri setinden çıkarmak gerekebilir. R dilinde, sütun seçimi ve yönetimi için en yaygın kullanılan araçlardan biri, dplyr paketinin sunduğu select() fonksiyonudur. Bu fonksiyon, kolay ve esnek bir şekilde sütunları seçmeyi, sıralamayı veya hariç tutmayı mümkün kılar.\nselect() fonksiyonunu kullanırken yalnızca sütun isimlerini belirterek seçim yapabilirsiniz. Ayrıca, sütun seçim işlemini kolaylaştırmak için çeşitli yardımcı fonksiyonlar da kullanılabilir. Bu yardımcı fonksiyonlar, sütun adlarını desenlere, pozisyonlara veya belirli kurallara göre seçmeyi sağlar.\n\nÖrnek Veri: starwars Veri Seti\n\nBu eğitimde, sütun seçimi işlemlerini öğrenirken, dplyr paketinde yer alan starwars veri setinin ilk 5 satırı ve ilk 6 sütunundan oluşan bir alt kümesini kullanacağız. Bu veri seti, sütun seçim işlemlerini göstermek için çeşitli veri türlerini ve isimlendirme desenlerini içeren harika bir örnek sağlar.\nAşağıdaki adımlarda, hem belirli sütunları seçme hem de sütunları hariç tutma işlemlerini nasıl gerçekleştireceğimizi öğrenirken yukarıda bahsedilen yardımcı fonksiyonları pratikte göreceğiz.\n\n# Gerekli paketin yüklenmesi\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n\n# Örnek veri seti oluşturma\ndf &lt;- starwars[1:5, 1:6] \n# starwars veri setinin ilk 5 satırını ve ilk 6 sütununu seçerek bir alt küme\n# oluşturur ve bunu df adlı bir nesneye atar.\n\n# Veri setini görüntüleme\ndf # Bundan sonra df veri seti kullanılacaktır.\n\n# A tibble: 5 × 6\n  name           height  mass hair_color skin_color  eye_color\n  &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;    \n1 Luke Skywalker    172    77 blond      fair        blue     \n2 C-3PO             167    75 &lt;NA&gt;       gold        yellow   \n3 R2-D2              96    32 &lt;NA&gt;       white, blue red      \n4 Darth Vader       202   136 none       white       yellow   \n5 Leia Organa       150    49 brown      light       brown    \n\n\n\nStarwars Veri Seti\nstarwars veri seti, Star Wars evrenindeki karakterlerin fiziksel özelliklerini ve kimlik bilgilerini içeren bir veri setidir. Bu veri seti, çeşitli değişkenlerle karakterlerin boy, kilo, saç rengi gibi fiziksel özelliklerini ve göz rengi gibi detaylarını sunar. Seçilen veri seti (ilk 5 satır ve ilk 6 sütun), aşağıdaki değişkenleri içerir:\n\n\nname: Karakterin adı.\n\nheight: Boy ölçümlerini içerir (santimetre).\n\nmass: Kilo ölçümlerini içerir (kilogram).\n\nhair_color: Saç rengini içerir.\n\nskin_color: Ten rengini içerir.\n\neye_color: Göz rengini içerir.\n\n\nselect() fonksiyonu, bir veri çerçevesinden belirli sütunları seçmek veya hariç tutmak için kullanılır. Sütun seçimi, hem sütun isimleri hem de sütunların konum/indeks bilgileri kullanılarak yapılabilir.\n\n\n\n\n\n\nR’da Köşeli Parantez\n\n\n\nR’de [ işareti, bir nesne içinden belirli elemanları seçmek için kullanılan bir alt kümeleme operatörüdür. Veri çerçeveleri, matrisler, vektörler ve listeler üzerinde alt kümeleme yapmak için kullanılır.\n\nVektörlerde Alt Kümeleme:\n\n\n# Bir vektör oluşturma\nv &lt;- c(10, 20, 30, 40)\n\n# Tek bir eleman seçme\nv[2]  # Sonuç: 20 (2. eleman)\n\n[1] 20\n\n# Birden fazla eleman seçme\nv[c(1, 3)]  # Sonuç: 10, 30 (1. ve 3. eleman)\n\n[1] 10 30\n\n\n\nVeri Çerçevelerinde Alt Kümeleme:\n\n\n# Bir örnek data frame oluşturma\ndf_ornek &lt;- data.frame(\n  a = 1:3, # Birinci sütun: 1, 2, 3\n  b = 4:6  # İkinci sütun: 4, 5, 6\n)\n\n# 1. satıra erişim\ndf_ornek[1, ]  # 1. satır\n\n  a b\n1 1 4\n\n# \"a\" sütununa erişim\ndf_ornek[, \"a\"]  # \"a\" sütunu\n\n[1] 1 2 3\n\n# İlk 2 satır ve \"a\", \"b\" sütunlarına erişim\ndf_ornek[1:2, c(\"a\", \"b\")]  # İlk 2 satır, \"a\" ve \"b\" sütunları\n\n  a b\n1 1 4\n2 2 5\n\n\n\n\n\n5.1.1.1 İsimle Seçim (By Name)\nBir veri seti üzerinde çalışırken, select fonksiyonu içinde seçmek istediğiniz sütunları belirtebilirsiniz. Sütun isimlerini tırnak işaretleriyle (\") veya tırnak işareti olmadan yazabilirsiniz. Tek bir sütun ya da birden fazla sütunu seçmeniz mümkündür.\n\nBelirli Sütunların Seçilmesi\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Star Wars veri setinden alt küme oluşturma\ndf &lt;- starwars[1:5, 1:6] \n\n# Belirli sütunların seçimi\ndf_2 &lt;- df %&gt;%\n  select(name, height) \n# Yalnızca \"name\" ve \"height\" sütunlarını seçer.\n\n# Yeni veri setini görüntüleme\ndf_2 \n\n# A tibble: 5 × 2\n  name           height\n  &lt;chr&gt;           &lt;int&gt;\n1 Luke Skywalker    172\n2 C-3PO             167\n3 R2-D2              96\n4 Darth Vader       202\n5 Leia Organa       150\n\n\n\n\n\n\n\n\nPipe Operatörü Nedir ve Nasıl Çalışır?\n\n\n\nPipe operatörü (%&gt;%), R programlama dilinde bir işlemin sonucunu otomatik olarak bir sonraki işleme girdi olarak aktarır. Bu operatör, özellikle veri manipülasyonu işlemlerini daha okunabilir, düzenli ve anlaşılır hale getirmek için kullanılır. Pipe, bir işlemden gelen veriyi diğerine “aktararak” adım adım bir işlem zinciri oluşturmayı sağlar.\nNeden Kullanılır?\n\n\nKod Okunabilirliğini Artırır: Pipe operatörüyle yazılmış kodda, işlemler sırasıyla ve kolayca takip edilebilir. Bu, özellikle uzun ve karmaşık veri işleme süreçlerinde büyük bir avantaj sağlar.\n\nAra Değişkenleri Ortadan Kaldırır: Pipe kullanımı, her işlem sonucu için ayrı bir değişken tanımlama ihtiyacını ortadan kaldırır, böylece kod daha sade hale gelir.\n\nAdım Adım İşlem Zinciri Kurar: Birden fazla işlemi arka arkaya uygulamak gerektiğinde pipe operatörü ile bu işlemler kolayca zincirlenir.\n\nNasıl Çalışır?\nPipe operatörü, bir nesneyi (örneğin bir veri çerçevesini) bir fonksiyonun girdisi olarak aktarır. Bu sayede kod, “bu işlemden gelen sonucu şu işleme aktar” şeklinde yazılır. Her işlem bir öncekinin sonucunu alır ve yeni bir işlem yapar.\nÖzetle, pipe operatörü veriyi işlemler arasında taşımak için kullanılır ve kod yazımını hem daha kısa hem de daha anlaşılır hale getirir.\n\n\n\nBelirli Sütun Aralığının Seçilmesi\n\nSütunlar arasında bir dizi seçmek için : operatörünü kullanabilirsiniz. Örneğin, height sütunundan başlayarak skin_color sütununa kadar (her iki sütun da dahil) olan sütunları seçmek isterseniz, şu şekilde yazabilirsiniz:\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6] \n\n# 'height' sütunundan 'skin_color' sütununa kadar olan sütunları seçme\ndf_2 &lt;- df %&gt;%\n  select(height:skin_color) \n# Bu ifade, df veri setinden \"height\" sütunundan başlayıp \"skin_color\" sütununa kadar\n# (her iki sütun dahil) olan sütunları seçer.\n\n# Seçilen sütunları görüntüleme\ndf_2 \n\n# A tibble: 5 × 4\n  height  mass hair_color skin_color \n   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      \n1    172    77 blond      fair       \n2    167    75 &lt;NA&gt;       gold       \n3     96    32 &lt;NA&gt;       white, blue\n4    202   136 none       white      \n5    150    49 brown      light      \n\n\n\n5.1.1.2 İndeks ile Seçim (By Index)\n\nBelirli Sütunların İndeks Numarası ile Seçilmesi\n\nSütunlar indeks (konum) numaralarına göre de seçilebilir. Bunun için select fonksiyonu içinde istenilen sütun numaralarını belirtmeniz yeterlidir. Aşağıdaki örnek, birinci, beşinci ve altıncı sütunları seçmektedir:\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6] \n\n# Belirli sütunları indeks numarasına göre seçme\ndf_2 &lt;- df %&gt;%\n  select(1, 5, 6) \n# Bu ifade, df veri setinden birinci, beşinci ve altıncı sütunları\n# indeks numaralarına göre seçer.\n\n# Seçilen sütunları görüntüleme\ndf_2\n\n# A tibble: 5 × 3\n  name           skin_color  eye_color\n  &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;    \n1 Luke Skywalker fair        blue     \n2 C-3PO          gold        yellow   \n3 R2-D2          white, blue red      \n4 Darth Vader    white       yellow   \n5 Leia Organa    light       brown    \n\n\n\n5.1.1.3 Sütunları Hariç Tutma (Drop Columns)\n\nBelirli Bir Sütunu Hariç Tutma\n\nselect fonksiyonu, belirli sütunları hariç tutmak (çıkarmak) için de kullanılabilir. Bunun için, sütun isimlerinin önüne - sembolünü eklemek yeterlidir. Aşağıdaki örnekte, mass sütunu hariç tüm sütunlar seçilmektedir:\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6] \n\n# Belirli bir sütunu hariç tutma\ndf_2 &lt;- df %&gt;%\n  select(-mass) \n# Bu ifade, df veri setinden \"mass\" sütununu hariç tutar \n# ve geri kalan tüm sütunları seçer.\n\n# Seçilen sütunları görüntüleme\ndf_2\n\n# A tibble: 5 × 5\n  name           height hair_color skin_color  eye_color\n  &lt;chr&gt;           &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;    \n1 Luke Skywalker    172 blond      fair        blue     \n2 C-3PO             167 &lt;NA&gt;       gold        yellow   \n3 R2-D2              96 &lt;NA&gt;       white, blue red      \n4 Darth Vader       202 none       white       yellow   \n5 Leia Organa       150 brown      light       brown    \n\n\n\nBirden Fazla Sütunu Hariç Tutma\n\nBirden fazla sütunu çıkarmak istediğiniz durumlarda, her sütun adının önüne - ekleyebilir ya da sütun adlarını içeren bir vektörün önüne - koyabilirsiniz.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6] \n\n# Birden fazla sütunu hariç tutma\ndf_2 &lt;- df %&gt;%\n  select(-height, -mass, -hair_color) \n# Alternatif olarak: select(-c(height, mass, hair_color))\n\n# Seçilen sütunları görüntüleme\ndf_2\n\n# A tibble: 5 × 3\n  name           skin_color  eye_color\n  &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;    \n1 Luke Skywalker fair        blue     \n2 C-3PO          gold        yellow   \n3 R2-D2          white, blue red      \n4 Darth Vader    white       yellow   \n5 Leia Organa    light       brown    \n\n\n\n5.1.1.4 Sütunları Seçmek veya Çıkarmak İçin Yardımcı Fonksiyonlar\n\nBelirli Bir Kelimeyi İçeren Sütunları Seçme\n\nBelirli desenlere veya koşullara dayalı olarak sütunları seçmek için çeşitli yardımcı fonksiyonlar bulunmaktadır. Bu fonksiyonlar şunları içerir:\n\n\ncontains: Belirli bir kelimeyi içeren sütunları seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# \"color\" kelimesini içeren sütunları seçme\ndf_contains_color &lt;- df %&gt;%\n  select(contains(\"color\")) # \"color\" kelimesini içeren sütunları seçer.\n\n# Sonucu görüntüleme\ndf_contains_color\n\n# A tibble: 5 × 3\n  hair_color skin_color  eye_color\n  &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;    \n1 blond      fair        blue     \n2 &lt;NA&gt;       gold        yellow   \n3 &lt;NA&gt;       white, blue red      \n4 none       white       yellow   \n5 brown      light       brown    \n\n\n\nBelirli Bir Metin ile Başlayan Sütunları Seçme\nstarts_with: Belirli bir metinle başlayan sütunları seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# \"h\" harfiyle başlayan sütunları seçme\ndf_starts_with_h &lt;- df %&gt;%\n  select(starts_with(\"h\")) # \"h\" harfiyle başlayan sütunları seçer.\n\n# Sonucu görüntüleme\ndf_starts_with_h\n\n# A tibble: 5 × 2\n  height hair_color\n   &lt;int&gt; &lt;chr&gt;     \n1    172 blond     \n2    167 &lt;NA&gt;      \n3     96 &lt;NA&gt;      \n4    202 none      \n5    150 brown     \n\n\n\nBelirli Bir Metin ile Biten Sütunları Seçme\nends_with: Belirli bir metinle biten sütunları seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# \"t\" harfiyle biten sütunları seçme\ndf_ends_with_t &lt;- df %&gt;%\n  select(ends_with(\"t\")) # \"t\" harfiyle biten sütunları seçer.\n\n# Sonucu görüntüleme\ndf_ends_with_t\n\n# A tibble: 5 × 1\n  height\n   &lt;int&gt;\n1    172\n2    167\n3     96\n4    202\n5    150\n\n\n\nSon Sütunu Seçme\nlast_col: Son sütunu seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# Son sütunu seçme\ndf_last_col &lt;- df %&gt;%\n  select(last_col()) # Veri setindeki son sütunu seçer.\n\n# Sonucu görüntüleme\ndf_last_col\n\n# A tibble: 5 × 1\n  eye_color\n  &lt;chr&gt;    \n1 blue     \n2 yellow   \n3 red      \n4 yellow   \n5 brown    \n\n\n\nBelirli Kelimeleri İçeren Sütunları Regex ile Seçme\nmatches: Regex desenine uyan sütunları seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# \"name\" veya \"mass\" kelimelerini içeren sütunları seçme\ndf_matches_name_mass &lt;- df %&gt;%\n  select(matches(\"name|mass\")) \n# \"name\" veya \"mass\" kelimelerini içeren sütunları regex (düzenli ifade) ile seçer.\n\n# Sonucu görüntüleme\ndf_matches_name_mass\n\n# A tibble: 5 × 2\n  name            mass\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Luke Skywalker    77\n2 C-3PO             75\n3 R2-D2             32\n4 Darth Vader      136\n5 Leia Organa       49\n\n\n\nNumara Aralığı ile Sütun Seçme\nnum_range: Numara aralığına göre sütun seçimi yapar.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6] \n\n# Numara aralığına göre sütun seçme\ndf_num_range &lt;- df %&gt;%\n  select(num_range(\"col\", 1:2)) \n# \"col1\", \"col2\" gibi sütun isimlerine uyan numara aralığını seçer.\n# Ancak bu veri setinde \"col1\" veya \"col2\" isimli sütunlar olmadığı için \n# sonuç boş olacaktır.\n\n# Sonucu görüntüleme\ndf_num_range\n\n# A tibble: 5 × 0\n\n\n\nTüm Sütunları Seçme\neverything: Veri setindeki tüm sütunları seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# Tüm sütunları seçme\ndf_everything &lt;- df %&gt;%\n  select(everything()) # Veri setindeki tüm sütunları seçer.\n\n# Sonucu görüntüleme\ndf_everything\n\n# A tibble: 5 × 6\n  name           height  mass hair_color skin_color  eye_color\n  &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;    \n1 Luke Skywalker    172    77 blond      fair        blue     \n2 C-3PO             167    75 &lt;NA&gt;       gold        yellow   \n3 R2-D2              96    32 &lt;NA&gt;       white, blue red      \n4 Darth Vader       202   136 none       white       yellow   \n5 Leia Organa       150    49 brown      light       brown    \n\n\n\nYalnızca Sayısal Sütunları Seçme\nwhere: Belirli bir koşulu sağlayan sütunları seçer.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6] \n\n# Yalnızca sayısal sütunları seçme\ndf_numeric_cols &lt;- df %&gt;%\n  select(where(is.numeric)) # Sadece sayısal veri tipine sahip sütunları seçer.\n\n# Sonucu görüntüleme\ndf_numeric_cols\n\n# A tibble: 5 × 2\n  height  mass\n   &lt;int&gt; &lt;dbl&gt;\n1    172    77\n2    167    75\n3     96    32\n4    202   136\n5    150    49\n\n\n\nSütunları Belirli Bir Sıralamayla Düzenleme\n\nselect() fonksiyonu yalnızca sütunları seçmek için değil, aynı zamanda sütunların sıralamasını değiştirmek için de kullanılabilir. Sütunları belirli bir düzene göre sıralamak istediğinizde, sütun isimlerini veya yardımcı fonksiyonları sırayla belirterek veri setinizin sütun yapısını yeniden düzenleyebilirsiniz.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri seti\ndf &lt;- starwars[1:5, 1:6]\n\n# Sütunları sıralama\ndf_sorted &lt;- df %&gt;%\n  select(\n    name,                       # İlk olarak 'name' sütunu\n    ends_with(\"_color\"),        # Sonra sonu \"_color\" ile biten sütunlar\n    everything()                # En son diğer tüm sütunlar\n  )\n\n# Sonucu görüntüleme\ndf_sorted\n\n# A tibble: 5 × 6\n  name           hair_color skin_color  eye_color height  mass\n  &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt;\n1 Luke Skywalker blond      fair        blue         172    77\n2 C-3PO          &lt;NA&gt;       gold        yellow       167    75\n3 R2-D2          &lt;NA&gt;       white, blue red           96    32\n4 Darth Vader    none       white       yellow       202   136\n5 Leia Organa    brown      light       brown        150    49\n\n\n\n5.1.2 Satır Filtreleme: filter\n\nfilter fonksiyonu, bir veri çerçevesindeki satırları belirli bir veya birden fazla koşula göre alt kümeye ayırmak için kullanılır. Bu fonksiyon, hem karşılaştırma hem de mantıksal operatörlerle esnek bir şekilde çalışarak, veri setinden yalnızca belirli kriterlere uyan satırları seçmeyi sağlar.\n\n*Örnek Veri: women Veri Seti**\n\nBu eğitimde, filtreleme işlemlerini öğrenirken R içinde yer alan women veri setini kullanacağız. Bu veri seti, kadınlara ait boy ve kilo ölçümlerini içeren iki sayısal sütundan oluşur. Boy ve kilo arasındaki ilişkileri incelemek ve koşullara göre filtreleme işlemlerini göstermek için ideal bir örnek teşkil eder.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri çerçevesi\ndf &lt;- as_tibble(women) \n# women veri setini tibble formatına çevirir ve df nesnesine atar.\n\n# Veri çerçevesini görüntüleme\nhead(df, 10) \n\n# A tibble: 10 × 2\n   height weight\n    &lt;dbl&gt;  &lt;dbl&gt;\n 1     58    115\n 2     59    117\n 3     60    120\n 4     61    123\n 5     62    126\n 6     63    129\n 7     64    132\n 8     65    135\n 9     66    139\n10     67    142\n\n\n\nWomen Veri Seti\nwomen veri seti, kadınlara ait boy ve kilo ölçümlerini içeren bir veri setidir. Bu veri seti, iki sayısal değişken ile kadınların fiziksel özelliklerini sunar.\n\n\nheight: Kadınların boy ölçümlerini içerir (inç cinsinden).\n\nweight: Kadınların kilo ölçümlerini içerir (pound cinsinden).\n\n\n\n5.1.2.1 Tek Bir Koşula Dayalı Satır Filtreleme\nfilter fonksiyonu, bir veri çerçevesindeki satırları belirli bir koşula göre alt kümeye ayırmak için kullanılır. Bu fonksiyon sayesinde, değerlerin belirli bir değere eşit olup olmadığını, daha büyük veya küçük olduğunu, ya da belirli bir aralıkta olup olmadığını kontrol ederek veri filtreleme işlemi yapılabilir.\n\nR’deki Karşılaştırma Operatörleri\n\nAşağıdaki tablo, R’deki karşılaştırma operatörlerini ve açıklamalarını içerir:\n\n\nKarşılaştırma Operatörü\nAçıklama\n\n\n\n&gt;\nDaha büyük\n\n\n&lt;\nDaha küçük\n\n\n&gt;=\nDaha büyük veya eşit\n\n\n&lt;=\nDaha küçük veya eşit\n\n\n==\nEşit\n\n\n!=\nEşit değil\n\n\n\n\n*Belirli Bir Koşula Göre Satırları Filtreleme**\n\nAşağıdaki örnekte, women veri setinden height sütununda değeri 68’den büyük olan satırları filtreliyoruz. Bu işlem, yalnızca boyu belirtilen değerden daha büyük olan kadınlara ait bilgileri seçmek için kullanılır.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# height sütununda 68'den büyük olan değerleri filtreleme\ndf_2 &lt;- df %&gt;%\n  filter(height &gt; 68) \n# height sütununda  68'den büyük olan değerlerin bulunduğu satırları seçer.\n\n# Filtrelenmiş veri çerçevesini görüntüleme\ndf_2\n\n# A tibble: 4 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     69    150\n2     70    154\n3     71    159\n4     72    164\n\n\n\nOrtalama Değere Göre Satırları Filtreleme\n\nfilter fonksiyonu, yalnızca sabit bir değere değil, aynı zamanda bir fonksiyonun çıktısına dayalı olarak da satırları filtreleyebilir. Örneğin, bir sütunun değerlerini, o sütunun ortalamasıyla karşılaştırarak filtreleme yapılabilir.\nAşağıdaki örnekte, height sütununda değeri sütunun ortalamasına eşit veya daha düşük olan satırlar filtrelenmektedir.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# height sütununda ortalamaya eşit veya daha düşük olan değerleri filtreleme\ndf_2 &lt;- df %&gt;%\n  filter(height &lt;= mean(height)) \n# height sütununda, değeri sütunun ortalamasına eşit veya daha düşük olan\n# satırları seçer.\n\n# Filtrelenmiş veri çerçevesini görüntüleme\ndf_2\n\n# A tibble: 8 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     58    115\n2     59    117\n3     60    120\n4     61    123\n5     62    126\n6     63    129\n7     64    132\n8     65    135\n\n\n\n5.1.2.2 Mantıksal Operatörler ve Fonksiyonlarla Satır Filtreleme\nfilter fonksiyonu, mantıksal operatörler veya TRUE ya da FALSE döndüren fonksiyonlarla birlikte kullanılarak daha karmaşık filtreleme işlemleri yapabilir. Aşağıdaki tabloda, R’de sık kullanılan mantıksal operatörler ve fonksiyonlar açıklanmaktadır:\n\n\nOperatör/Fonksiyon\nAçıklama\n\n\n\n!\nMantıksal değil (‘NOT’)\n\n\n%in%\nBelirtilen kümenin içinde\n\n\n!(x %in% y)\nBelirtilen kümenin içinde olmayanlar\n\n\nis.na()\nDeğer NA olanlar\n\n\n!is.na()\nDeğer NA olmayanlar\n\n\ngrepl()\nBelirtilen bir deseni içerenler\n\n\n!grepl()\nBelirtilen bir deseni içermeyenler\n\n\n\n\nBelirli Değerlere Göre Satırları Filtreleme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\ndf &lt;- as_tibble(women)\n\n# 'height' sütununda değeri 65, 70 veya 72 olan satırları seçme\ndf_2 &lt;- df %&gt;%\n  filter(height %in% c(65, 70, 72)) \n# height sütununda 65, 70 veya 72 olan satırları filtreler.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     65    135\n2     70    154\n3     72    164\n\n\n\nBelirli Değerlere Sahip Olmayan Satırları Filtreleme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\ndf &lt;- as_tibble(women) \n\n# 'height' değeri 65, 70 veya 72 olmayan satırları seçme\ndf_2 &lt;- df %&gt;%\n  filter(!(height %in% c(65, 70, 72))) \n# Bu ifade, height sütununda değeri 65, 70 veya 72 olmayan satırları seçer.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 12 × 2\n   height weight\n    &lt;dbl&gt;  &lt;dbl&gt;\n 1     58    115\n 2     59    117\n 3     60    120\n 4     61    123\n 5     62    126\n 6     63    129\n 7     64    132\n 8     66    139\n 9     67    142\n10     68    146\n11     69    150\n12     71    159\n\n\n\nBelirli Bir Rakamı veya Deseni İçeren Satırları Filtreleme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# height sütununda \"5\" rakamını içeren satırları filtreleme\ndf_2 &lt;- df %&gt;%\n  filter(grepl(\"5\", height)) \n# Bu ifade, height sütununda \"5\" rakamını içeren satırları seçer.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     58    115\n2     59    117\n3     65    135\n\n\n\n5.1.2.3 Birden Fazla Koşula Dayalı Satır Filtreleme\nBir veri çerçevesinde satırları filtrelerken birden fazla koşul kullanılabilir. Örneğin, belirli bir aralıkta bulunan değerleri seçmek veya tarih aralığında veri filtrelemek gibi işlemler yapılabilir. Bunun için mantıksal operatörler kullanılır.\n\n5.1.2.4 R’deki Mantıksal Operatörler ve Açıklamaları\n\n\n\n\n\n\nMantıksal Operatör\nAçıklama\n\n\n\n&\nEleman bazında mantıksal “VE” (AND)\n\n\n\n|\nEleman bazında mantıksal “VEYA” (OR)\n\n\n\nxor()\nEleman bazında kapsamlı mantıksal !(x | y)\n\n\n\n\n\nİki Koşulu Aynı Anda Sağlayan Satırları Filtreleme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# 'height' değeri 65'ten büyük VE 68'den küçük olan satırları filtreleme\ndf_2 &lt;- df %&gt;%\n  filter(height &gt; 65 & height &lt; 68) \n# Bu ifade, height sütununda değeri 65'ten büyük ve 68'den küçük olan \n# satırları seçer.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 2 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     66    139\n2     67    142\n\n\n\nÇoklu Koşul ile Satırları Filtreleme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# 'height' sütunu 65'ten büyük ve 'weight' sütunu 150'den küçük veya \n# eşit olan satırları filtreleme\ndf_2 &lt;- df %&gt;%\n  filter(height &gt; 65 & weight &lt;= 150) \n# Bu ifade, height sütunu 65'ten büyük ve weight sütunu 150'den küçük veya \n# eşit olan satırları seçer.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 4 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     66    139\n2     67    142\n3     68    146\n4     69    150\n\n\n\nMantıksal “VEYA” Koşulu ile Satırları Filtreleme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# 'height' sütunu 65'ten büyük VEYA 'weight' sütunu 150'den büyük veya \n# eşit olan satırları filtreleme\ndf_2 &lt;- df %&gt;%\n  filter(height &gt; 65 | weight &gt;= 150) \n# Bu ifade, height sütunu 65'ten büyük VEYA weight sütunu 150'den büyük veya \n# eşit olan satırları seçer.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 7 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     66    139\n2     67    142\n3     68    146\n4     69    150\n5     70    154\n6     71    159\n7     72    164\n\n\n\n5.1.2.5 Satır Numarasına Göre Filtreleme: slice\n\nfilter fonksiyonuna benzer bir işlev de slice fonksiyonudur. Bu fonksiyon, satırları indekslerine/pozisyonlarına göre filtrelemeye olanak tanır. Girdi olarak bir sıra veya indekslerin bulunduğu bir vektör (tam sayı değerleri) alır. Kullanımı aşağıda gösterilmiştir.\n\nBelirli Satırları Seçme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women)\n\n# İlk 3 satırı seçme\ndf_2 &lt;- df %&gt;%\n  slice(1:3) # Bu ifade, df veri setinin ilk 3 satırını seçer.\n\n# Filtrelenmiş veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     58    115\n2     59    117\n3     60    120\n\n\n\nİlk N Satırı Seçme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women)\n\n# İlk 3 satırı seçme\ndf_slice_head &lt;- df %&gt;%\n  slice_head(n = 3) # İlk 3 satır seçilir.\n\n# Sonucu görüntüleme\ndf_slice_head\n\n# A tibble: 3 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     58    115\n2     59    117\n3     60    120\n\n\n\nSon N Satırı Seçme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women)\n\n# Son 3 satırı seçme\ndf_slice_tail &lt;- df %&gt;%\n  slice_tail(n = 3) # Son 3 satır seçilir.\n\n# Sonucu görüntüleme\ndf_slice_tail\n\n# A tibble: 3 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     70    154\n2     71    159\n3     72    164\n\n\n\nRastgele Satırlar Seçme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# Rastgele 3 satırı seçme\ndf_slice_sample &lt;- df %&gt;%\n  slice_sample(n = 3) # Rastgele 3 satır seçilir.\n\n# Sonucu görüntüleme\ndf_slice_sample\n\n# A tibble: 3 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     60    120\n2     61    123\n3     62    126\n\n\n\nBelirli Bir Sütuna Göre En Küçük Satırları Seçme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# height sütununa göre en küçük 2 satırı seçme\ndf_slice_min &lt;- df %&gt;%\n  slice_min(height, n = 2) # height sütunundaki en küçük 2 satır seçilir.\n\n# Sonucu görüntüleme\ndf_slice_min\n\n# A tibble: 2 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     58    115\n2     59    117\n\n\n\nBelirli Bir Sütuna Göre En Büyük Satırları Seçme\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# women veri setini tibble formatına çevirme\ndf &lt;- as_tibble(women) \n\n# weight sütununa göre en büyük 2 satırı seçme\ndf_slice_max &lt;- df %&gt;%\n  slice_max(weight, n = 2) # weight sütunundaki en büyük 2 satır seçilir.\n\n# Sonucu görüntüleme\ndf_slice_max\n\n# A tibble: 2 × 2\n  height weight\n   &lt;dbl&gt;  &lt;dbl&gt;\n1     72    164\n2     71    159\n\n\n\n5.1.3 Satırların Sıralanması: arrange()\n\narrange, dplyr paketinde kullanılan ve bir veri çerçevesindeki satırları bir veya daha fazla sütunun değerlerine göre yeniden sıralamayı sağlayan bir fonksiyondur. Varsayılan olarak, satırları artan düzende sıralar. Azalan sıralama yapmak için desc fonksiyonu kullanılır.\nstarwars Veri Seti\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\ndf &lt;- starwars[1:10, c(1, 2, 3, 11)] \n# starwars veri setinin ilk 10 satırını ve 1, 2, 3 ve 11. sütunlarını seçerek bir alt küme oluşturur ve bunu df adlı bir nesneye atar.\n\n# Veriyi görüntüleme\ndf \n\n# A tibble: 10 × 4\n   name               height  mass species\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 Luke Skywalker        172    77 Human  \n 2 C-3PO                 167    75 Droid  \n 3 R2-D2                  96    32 Droid  \n 4 Darth Vader           202   136 Human  \n 5 Leia Organa           150    49 Human  \n 6 Owen Lars             178   120 Human  \n 7 Beru Whitesun Lars    165    75 Human  \n 8 R5-D4                  97    32 Droid  \n 9 Biggs Darklighter     183    84 Human  \n10 Obi-Wan Kenobi        182    77 Human  \n\n# Bundan sonra df veri seti kullanılacaktır.\n\n\nStarwars Veri Seti\nstarwars veri seti, Star Wars evrenindeki karakterlerin fiziksel özelliklerini ve kimlik bilgilerini içeren bir veri setidir. Bu veri seti, çeşitli değişkenlerle karakterlerin boy, kilo, cinsiyet gibi fiziksel özelliklerini ve isim gibi kimlik detaylarını sunar. Seçilen veri seti (ilk 10 satır ve 1, 2, 3, 11. sütunlar), aşağıdaki değişkenleri içerir:\n\n\nname: Karakterin adı.\n\nheight: Boy ölçümlerini içerir (santimetre).\n\nmass: Kilo ölçümlerini içerir (kilogram).\n\ngender: Karakterin cinsiyet bilgisi.\n\n\n\n5.1.3.1 Tek Bir Sütuna Göre Sıralama\n\nBir Sütuna Göre Artan Sıralama\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# starwars veri setinden alt küme oluşturma\ndf &lt;- starwars[1:10, c(1, 2, 3, 11)] \n\n# 'height' sütununa göre artan (ASCENDING) sıralama\ndf_2 &lt;- df %&gt;%\n  arrange(height) # height sütununa göre satırları artan sırayla yeniden düzenler.\n\n# Sıralanmış veriyi görüntüleme\ndf_2# Sıralama sonucunda elde edilen yeni veri çerçevesi.\n\n# A tibble: 10 × 4\n   name               height  mass species\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 R2-D2                  96    32 Droid  \n 2 R5-D4                  97    32 Droid  \n 3 Leia Organa           150    49 Human  \n 4 Beru Whitesun Lars    165    75 Human  \n 5 C-3PO                 167    75 Droid  \n 6 Luke Skywalker        172    77 Human  \n 7 Owen Lars             178   120 Human  \n 8 Obi-Wan Kenobi        182    77 Human  \n 9 Biggs Darklighter     183    84 Human  \n10 Darth Vader           202   136 Human  \n\n\ndesc(): Bir sütunu azalan sırada sıralamak için kullanılır.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# starwars veri setinden alt küme oluşturma\ndf &lt;- starwars[1:10, c(1, 2, 3, 11)] \n\n# 'height' sütununa göre AZALAN sıralama\ndf_2 &lt;- df %&gt;%\n  arrange(desc(height)) \n# desc(): height sütununu azalan sıraya göre sıralamak için kullanılır.\n\n# Sıralanmış veri seti\ndf_2 \n\n# A tibble: 10 × 4\n   name               height  mass species\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 Darth Vader           202   136 Human  \n 2 Biggs Darklighter     183    84 Human  \n 3 Obi-Wan Kenobi        182    77 Human  \n 4 Owen Lars             178   120 Human  \n 5 Luke Skywalker        172    77 Human  \n 6 C-3PO                 167    75 Droid  \n 7 Beru Whitesun Lars    165    75 Human  \n 8 Leia Organa           150    49 Human  \n 9 R5-D4                  97    32 Droid  \n10 R2-D2                  96    32 Droid  \n\n\n\nBelirli Bir Sütunun Belirli Bir Karakterine Göre Sıralama\n\nsubstr(x, start, stop): Bir metinden belirli bir başlangıç ve bitiş pozisyonu arasındaki karakterleri döndürür.\nx: İşlem yapılacak metin veya karakter vektörü (örneğin, bir sütun adı).\n\n\nstart: Metnin hangi pozisyondan başlayacağını belirtir (dahil).\n\nstop: Metnin hangi pozisyonda duracağını belirtir (dahil).\n\nEğer x “Star Wars” ise:\n\n\nsubstr(x, 1, 4) → \"Star\" (İlk 4 karakter).\n\nsubstr(x, 6, 9) → \"Wars\" (6. ve 9. karakterler arası).\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# starwars veri setinden alt küme oluşturma\ndf &lt;- starwars[1:10, c(1, 2, 3, 11)] \n\n# 'name' sütununu adın ilk harfine göre sıralama\ndf_2 &lt;- df %&gt;%\n  arrange(substr(name, 1, 2)) \n# substr(): 'name' sütununun ilk iki harfine göre sıralama yapar.\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 10 × 4\n   name               height  mass species\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 Beru Whitesun Lars    165    75 Human  \n 2 Biggs Darklighter     183    84 Human  \n 3 C-3PO                 167    75 Droid  \n 4 Darth Vader           202   136 Human  \n 5 Leia Organa           150    49 Human  \n 6 Luke Skywalker        172    77 Human  \n 7 Obi-Wan Kenobi        182    77 Human  \n 8 Owen Lars             178   120 Human  \n 9 R2-D2                  96    32 Droid  \n10 R5-D4                  97    32 Droid  \n\n\n\n5.1.3.2 Birden Fazla Sütuna Göre Satırları Sıralama\nSatırlar birden fazla sütuna göre de sıralanabilir. Bu durumda sıralama sırasıyla gerçekleşir: önce birinci sütun, ardından ikinci sütun ve devam eder. Aşağıdaki örnek, satırların height ve mass değişkenlerine göre sıralanmasını göstermektedir.\n\nBirden Fazla Sütuna Göre Sıralama\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# starwars veri setinden alt küme oluşturma\ndf &lt;- starwars[1:10, c(1, 2, 3, 11)] \n\n# 'height' ve ardından 'mass' sütununa göre sıralama\ndf_2 &lt;- df %&gt;%\n  arrange(height, mass) \n# Önce height sütununa, ardından mass sütununa göre artan sıralama yapar.\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 10 × 4\n   name               height  mass species\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 R2-D2                  96    32 Droid  \n 2 R5-D4                  97    32 Droid  \n 3 Leia Organa           150    49 Human  \n 4 Beru Whitesun Lars    165    75 Human  \n 5 C-3PO                 167    75 Droid  \n 6 Luke Skywalker        172    77 Human  \n 7 Owen Lars             178   120 Human  \n 8 Obi-Wan Kenobi        182    77 Human  \n 9 Biggs Darklighter     183    84 Human  \n10 Darth Vader           202   136 Human  \n\n\n\nBirden Fazla Sütuna Göre Artan Sıralama\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# starwars veri setinden alt küme oluşturma\ndf &lt;- starwars[1:10, c(1, 2, 3, 11)] \n\n# 'mass' ve ardından 'height' sütununa göre sıralama\ndf_2 &lt;- df %&gt;%\n  arrange(mass, height)\n# Önce mass sütununa, ardından height sütununa göre artan sıralama yapar.\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 10 × 4\n   name               height  mass species\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1 R2-D2                  96    32 Droid  \n 2 R5-D4                  97    32 Droid  \n 3 Leia Organa           150    49 Human  \n 4 Beru Whitesun Lars    165    75 Human  \n 5 C-3PO                 167    75 Droid  \n 6 Luke Skywalker        172    77 Human  \n 7 Obi-Wan Kenobi        182    77 Human  \n 8 Biggs Darklighter     183    84 Human  \n 9 Owen Lars             178   120 Human  \n10 Darth Vader           202   136 Human  \n\n\n\n5.1.4 Sütun Adlarını Yeniden Adlandırma: rename()\n\nR’de dplyr paketinin rename() fonksiyonu, bir veri çerçevesindeki sütun isimlerini değiştirmek için kullanılır. Bu fonksiyon, belirli sütunlara yeni isimler atamanıza olanak tanır.\nAyrıca, rename_with() fonksiyonu, sütunları bir fonksiyon kullanarak toplu halde yeniden adlandırmanıza olanak sağlar.\ndplyr paketindeki band_instruments veri setini kullanacağız. Bu veri seti, name ve plays adlı iki sütunu içermektedir.\n\nİlk sütunu “First Name” olarak yeniden adlandırmak istediğinizi düşünüyorsanız, aşağıdaki komutu çalıştırabilirsiniz:\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# 'name' sütununu 'First Name' olarak yeniden adlandırma\ndf_2 &lt;- band_instruments %&gt;%\n  rename(\"First Name\" = name)\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n  `First Name` plays \n  &lt;chr&gt;        &lt;chr&gt; \n1 John         guitar\n2 Paul         bass  \n3 Keith        guitar\n\n\n\nSütun Adını İndeks ile Yeniden Adlandırma\n\nSütunları indeks numarasına göre de yeniden adlandırabilirsiniz. Aşağıdaki örnek, veri setinin ikinci sütununun nasıl yeniden adlandırılacağını göstermektedir.\n\nlibrary(tidyverse)\n\n# İkinci sütunu 'Second column' olarak yeniden adlandırma\ndf_2 &lt;- band_instruments %&gt;%\n  rename(\"Second column\" = 2)\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n  name  `Second column`\n  &lt;chr&gt; &lt;chr&gt;          \n1 John  guitar         \n2 Paul  bass           \n3 Keith guitar         \n\n\n\nBirden Fazla Sütun Adını Yeniden Adlandırma\nBirden fazla sütunu aynı anda yeniden adlandırmak mümkündür. Bunun için, fonksiyona new_name = old_name ifadeleri eklenir ve bu ifadeler virgülle ayrılır. Aşağıdaki örnek, name sütununu Member, plays sütununu ise Instrument olarak yeniden adlandırmaktadır.\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# 'name' sütununu 'Member', 'plays' sütununu 'Instrument' olarak adlandırma\ndf_2 &lt;- band_instruments %&gt;%\n  rename(\"Member\" = name,\n         \"Instrument\" = plays)\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n  Member Instrument\n  &lt;chr&gt;  &lt;chr&gt;     \n1 John   guitar    \n2 Paul   bass      \n3 Keith  guitar",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Veri Manipülasyonu</span>"
    ]
  },
  {
    "objectID": "veri_manipulasyonu.html#veri-dönüştürme",
    "href": "veri_manipulasyonu.html#veri-dönüştürme",
    "title": "\n5  Veri Manipülasyonu\n",
    "section": "\n5.2 Veri Dönüştürme",
    "text": "5.2 Veri Dönüştürme\n\n5.2.1 Yeni Değişkenler Oluşturma ve Düzenleme: mutate()\n\nmutate(), R’de dplyr paketinde kullanılan bir fonksiyondur ve bir veri çerçevesinde yeni sütunlar oluşturmak veya mevcut sütunları değiştirmek için kullanılır. Veri çerçevesinin orijinal yapısını korur ve sonuçları yeni sütunlar olarak saklar.\n\n5.2.1.1 mutate() Fonksiyonu Sözdizimi\n\n\n.data Veri çerçevesi\n\n\n... Yeni sütunlar (örneğin, yeni_sütun = işlem)\n\n\n.by = NULL, Gruplama değişkenleri (isteğe bağlı)\n\n\n.keep = c(\"all\", \"used\", \"unused\", \"none\"), Hangi sütunların tutulacağı\n\n\n.before = NULL, Yeni sütunları belirli bir sütundan önce yerleştirme\n\n\n.after = NULL Yeni sütunları belirli bir sütundan sonra yerleştirme\n\n\n5.2.1.2 Yeni Sütun Oluşturma\nBir veri çerçevesine yeni bir sütun eklemek için, yeni sütunun adını (örneğin, Var3) ve yeni sütunun değerlerini hesaplamak için bir ifadeyi belirtmeniz yeterlidir. Aşağıdaki örnekte, yeni sütunun değeri, diğer iki sütunun toplamı (Var1 + Var2) olarak hesaplanmıştır.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütun: 'Var3', 'Var1' ve 'Var2'nin toplamı\ndf_2 &lt;- df %&gt;%\n  mutate(Var3 = Var1 + Var2) \n# Yeni sütun ekler: Var3, Var1 ve Var2 sütunlarının toplamı olarak hesaplanır.\n\n# Yeni sütun eklenmiş veri seti\ndf_2\n\n  Var1 Var2 Var3\n1   32   39   71\n2   34    1   35\n3   15   29   44\n4   12    3   15\n5   42   35   77\n\n\n\nYeni Sütun Olarak Karekök Hesaplama\n\nBir veri çerçevesine yeni bir sütun eklemek için mevcut bir sütuna bir fonksiyon uygulayabilirsiniz. Aşağıdaki örnek, bir sütunun karekökünü hesaplayarak yeni bir sütun (Sqrt_Var1) oluşturmayı göstermektedir.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütun: 'Sqrt_Var1', 'Var1' sütununun karekökü\ndf_2 &lt;- df %&gt;%\n  mutate(Sqrt_Var1 = sqrt(Var1)) \n# Yeni sütun ekler: Sqrt_Var1, Var1 sütununun karekökü olarak hesaplanır.\n\n# Veriyi görüntüleme\ndf_2 # Yeni sütun eklenmiş veri seti.\n\n  Var1 Var2 Sqrt_Var1\n1   32   39  5.656854\n2   34    1  5.830952\n3   15   29  3.872983\n4   12    3  3.464102\n5   42   35  6.480741\n\n\n\nBirden Fazla Yeni Sütun Eklemek ve Koşullu Değer Atamak\n\nmutate fonksiyonuna birden fazla ifade ekleyerek aynı anda birden fazla sütun oluşturabilirsiniz. Bunun için ifadeleri virgülle ayırmanız yeterlidir.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütunlar: 'Var3', 'Var4' ve 'Var5'\ndf_2 &lt;- df %&gt;%\n  mutate(\n    Var3 = Var1 + Var2,             # Var1 ve Var2'nin toplamı\n    Var4 = cumsum(Var1),            # Var1'in kümülatif toplamı\n    Var5 = if_else(Var1 &gt; Var2, TRUE, FALSE) \n    # Var1, Var2'den büyükse TRUE, değilse FALSE\n  )\n\n# Veriyi görüntüleme\ndf_2 # Birden fazla sütun eklenmiş veri seti.\n\n  Var1 Var2 Var3 Var4  Var5\n1   32   39   71   32 FALSE\n2   34    1   35   66  TRUE\n3   15   29   44   81 FALSE\n4   12    3   15   93  TRUE\n5   42   35   77  135  TRUE\n\n\n\n\n\n\n\n\nif_else fonksyonu\n\n\n\nif_else() fonksiyonu R programlama dilinde koşullu ifadeler oluşturmak için kullanılan bir fonksiyondur. Temelde, bir koşulun doğru olup olmamasına göre farklı değerler döndürür. Bu, daha geleneksel if ve else yapılarının vektörleştirilmiş bir karşılığıdır ve özellikle veri manipülasyonu ve vektörler üzerinde işlem yaparken çok daha verimli olabilir.\n\nif_else(condition, true_value, false_value)\n\n\n\ncondition: Mantıksal bir vektör veya ifade. Her bir eleman için TRUE veya FALSE değerini döndürmelidir.\n\ntrue_value: condition vektöründeki ilgili eleman TRUE ise döndürülecek değer. Bu bir vektör olabilir.\n\nfalse_value: condition vektöründeki ilgili eleman FALSE ise döndürülecek değer. Bu da bir vektör olabilir.\n\nNasıl Çalışır?\nif_else() fonksiyonu, condition vektöründeki her bir elemanı teker teker kontrol eder. Eğer ilgili eleman TRUE ise, true_value vektöründeki aynı konumdaki değeri döndürür. Eğer ilgili eleman FALSE ise, false_value vektöründeki aynı konumdaki değeri döndürür.\n\n\n\nBelirli Sütunlarda İşlem Yapmak ve Yeni Sütunlar Oluşturmak: across() Kullanımı\n\nacross() fonksiyonu, mutate ile birlikte kullanılarak belirli sütunlara fonksiyonlar uygulamayı sağlar. Aynı zamanda yardımcı fonksiyonlar (contains, starts_with, vb.) ile sütun seçiminde esneklik sunar.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\ndf &lt;- tibble(Var1 = c(1, 4, 9), Var2 = c(16, 25, 36), Var3 = c(49, 64, 81))\n\n# \"1\" içeren sütunlara karekök uygulama ve yeni sütunlar oluşturma\ndf_2 &lt;- df %&gt;%\n   mutate(\n      across(\n         .cols = contains(\"Var\"), # İsimlerinde \"Var\" geçen sütunları seçer\n         .fns = sqrt,           # Karekök fonksiyonunu uygular\n         .names = \"{.col}_sqrt\")) # Yeni sütun isimleri: Eski isim + \"_sqrt\"\n\n# Veriyi görüntüleme\ndf_2 # Yeni sütunlar eklenmiş veri seti.\n\n# A tibble: 3 × 6\n   Var1  Var2  Var3 Var1_sqrt Var2_sqrt Var3_sqrt\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1     1    16    49         1         4         7\n2     4    25    64         2         5         8\n3     9    36    81         3         6         9\n\n\n\n5.2.1.3 Mevcut Sütunları Güncelleme\n\nMevcut Bir Sütunun Değerlerini Güncelleme\n\nmutate() fonksiyonu, mevcut sütunları güncellemek veya üzerinde işlem yapmak için de kullanılabilir. Bunu gerçekleştirmek için, eski_sütun_adı = ifade sözdizimini kullanmanız yeterlidir.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\ndf &lt;- tibble(Var1 = c(10, 20, 30), Var2 = c(5, 10, 15))\n\n# 'Var1' sütununun değerlerini ikiye katlama\ndf_2 &lt;- df %&gt;%\n  mutate(Var1 = Var1 * 2) # Var1 sütununun yeni değerleri Var1 * 2\n\n# Veriyi görüntüleme\ndf_2\n\n# A tibble: 3 × 2\n   Var1  Var2\n  &lt;dbl&gt; &lt;dbl&gt;\n1    20     5\n2    40    10\n3    60    15\n\n\n\nBirden Fazla Yeni Sütun Eklemek ve Koşullu Değer Atamak\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(123)\ndf &lt;- tibble(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütunlar: 'Var3', 'Var4' ve 'Var5'\ndf_2 &lt;- df %&gt;%\n  mutate(\n    Var1 = Var1 + Var2,             # Var1 ve Var2'nin toplamı\n    Var2 = cumsum(Var1),            # Var1'in kümülatif toplamı\n    Var3 = if_else(Var1 &gt;= Var2, \"Yes\", \"No\") \n    # Var1, Var2'den büyükse \"Yes\", değilse \"No\"\n  )\n\n# Veriyi görüntüleme\ndf_2 # Birden fazla sütun eklenmiş veri seti.\n\n# A tibble: 5 × 3\n   Var1  Var2 Var3 \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1    81    81 Yes  \n2    58   139 No   \n3    51   190 No   \n4    17   207 No   \n5    67   274 No   \n\n\n\nBelirli Sütunlarda İşlem Yapmak\n\nacross() fonksiyonunu kullanarak belirli sütunları seçebilir ve bunlara özel bir fonksiyon uygulayabilirsiniz. Yeni sütun oluşturmadan, mevcut sütunların değerlerini doğrudan değiştirebilirsiniz.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- tibble(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# 'Var1' hariç tüm sütunlara logaritma işlemi uygulama\ndf_2 &lt;- df %&gt;%\n  mutate(across(!Var1, log)) # Var1 dışındaki tüm sütunlara log uygulanır\n\n# Veriyi görüntüleme\ndf_2 # Güncellenmiş veri seti.\n\n# A tibble: 5 × 2\n   Var1  Var2\n  &lt;int&gt; &lt;dbl&gt;\n1    32  3.66\n2    34  0   \n3    15  3.37\n4    12  1.10\n5    42  3.56\n\n\n\n5.2.1.4 Yeni Sütunların Konumu\nVarsayılan olarak, mutate fonksiyonu yeni sütunları veri çerçevesinin sonuna ekler. Ancak, .before veya .after argümanlarını kullanarak yeni sütunun başka bir sütuna göre konumunu belirleyebilirsiniz.\n\nYeni Sütunlar Eklemek ve Belirli Pozisyonlara Yerleştirmek\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütunlar ekleniyor\ndf_2 &lt;- df %&gt;%\n  mutate(Var3 = Var1 / Var2, .before = Var2) %&gt;%  \n  # Yeni sütun: Var3, Var2'den önce ekleniyor\n  mutate(Var4 = Var1 * Var2, .before = Var1) %&gt;%  \n  # Yeni sütun: Var4, ilk sütundan önce ekleniyor\n  mutate(Var5 = (Var1 * Var2) / 2, .after = Var4) \n  # Yeni sütun: Var5, Var4'ten sonra ekleniyor\n\n# Veriyi görüntüleme\ndf_2\n\n  Var4  Var5 Var1       Var3 Var2\n1 1248 624.0   32  0.8205128   39\n2   34  17.0   34 34.0000000    1\n3  435 217.5   15  0.5172414   29\n4   36  18.0   12  4.0000000    3\n5 1470 735.0   42  1.2000000   35\n\n\n\n5.2.1.5 Sütunları saklama veya çıkarma\nYeni sütunlar bir veri çerçevesine eklendiğinde, varsayılan olarak diğer tüm sütunlar korunur. Ancak .keep argümanı sayesinde bu davranış değiştirilebilir. .keep varsayılan olarak \"all\" değerine sahiptir, ancak aşağıdaki şekilde ayarlanabilir:\n\n\"all\": Tüm sütunları korur (varsayılan).\n\"used\": Sadece mutate içinde kullanılan sütunları korur.\n\"unused\": mutate içinde kullanılmayan sütunları korur.\n\"none\": Eski tüm sütunları siler, sadece yeni sütunlar kalır.\nKullanılan Sütunları Saklamak .keep = \"used\"\n\nAşağıdaki örnek, sadece kullanılan sütunları saklamak için .keep = \"used\" ayarının nasıl kullanılacağını göstermektedir:\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütun ekleme ve sadece kullanılan sütunu ('Var1') ve \n# yeni sütunu ('Var3') koruma\ndf_2 &lt;- df %&gt;%\n  mutate(Var3 = Var1 * 2, \n         .keep = \"used\")\n\ndf_2\n\n  Var1 Var3\n1   32   64\n2   34   68\n3   15   30\n4   12   24\n5   42   84\n\n\n\nYalnızca Kullanılmayan Sütunları Saklamak .keep = \"unused\"\n\nTam tersi, yalnızca yeni sütunu ve kullanılmayan sütunları korumaktır. Bunun için .keep = \"unused\" ayarı kullanılabilir. Bu durumda, mutate içinde kullanılan sütunlar hariç tutulur.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütun ekleme ve sadece yeni sütunu ('Var3') ve kullanılmayan \n# sütunu ('Var2') koruma\ndf_2 &lt;- df %&gt;%\n  mutate(Var3 = Var1 * 2, .keep = \"unused\")\n\ndf_2\n\n  Var2 Var3\n1   39   64\n2    1   68\n3   29   30\n4    3   24\n5   35   84\n\n\n\nYalnızca Yeni Sütunu Saklamak .keep = \"none\"\n\nSon olarak, orijinal veri çerçevesindeki tüm sütunları kaldırmak için .keep = \"none\" kullanabilirsiniz.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(8)\ndf &lt;- data.frame(Var1 = sample(1:50, 5), Var2 = sample(1:50, 5))\n\n# Yeni sütun ekleme ve yalnızca yeni sütunu ('Var3') saklama\ndf_2 &lt;- df %&gt;%\n  mutate(Var3 = Var1 * 2, .keep = \"none\")\n\ndf_2\n\n  Var3\n1   64\n2   68\n3   30\n4   24\n5   84\n\n\n\n5.2.2 İstatistiksel Özetler Oluşturma: summarise()\n\nsummarise (veya summarize) fonksiyonu, verileri toplulaştırmak ve özetlemek için kullanılır. Bu fonksiyon, özellikle verileri gruplara ayırarak her grup için istatistiksel özetler veya hesaplamalar yapmak açısından oldukça faydalıdır. Belirtilen özet istatistiklerle birlikte yeni bir veri çerçevesi oluşturur ve her grup için tek bir satır döndürür.\n\n5.2.2.1 Sözdizimi\n\n# summarise(data, new_column = function(column))\n\nArgümanlar:\n\n\ndata: Özetleme yapmak istediğiniz veri çerçevesi veya gruplandırılmış veri.\n\nnew_column: Yeni oluşturulacak sütunun adı.\n\nfunction(column): Belirli bir sütuna uygulanacak fonksiyon (örneğin: sum, mean, max).\n\n5.2.2.2 Verinin İstatistiksel Özetleri\nBir veri setinden belirli değişkenlerin istatistiksel özetlerini içeren yeni bir veri çerçevesi oluşturabilirsiniz. summarise fonksiyonu ile kullanılabilecek en faydalı fonksiyonlar aşağıda açıklanmıştır:\n\n5.2.3 Verinin İstatistiksel Özetleri\nBir veri setinden belirli değişkenlerin istatistiksel özetlerini içeren yeni bir veri çerçevesi oluşturabilirsiniz. summarise fonksiyonu ile kullanılabilecek en faydalı fonksiyonlar aşağıda açıklanmıştır:\nKullanışlı Fonksiyonlar\n\n\nFonksiyon\nAçıklama\n\n\n\nmean()\nDeğerlerin ortalaması\n\n\nmedian()\nDeğerlerin medyanı\n\n\nsd(), var()\nDeğerlerin standart sapması ve varyansı\n\n\nquantile()\nDeğerlerin çeyrek dilimleri\n\n\nIQR()\nDeğerlerin interçeyrek aralığı\n\n\nmin(), max()\nMinimum ve maksimum değer\n\n\nfirst()\nİlk değer\n\n\nlast()\nSon değer\n\n\nnth()\nN. sıradaki değer\n\n\nn()\nHer gruptaki eleman sayısı\n\n\nn_distinct()\nBenzersiz değerlerin sayısı\n\n\n\n\nVeri Seti Üzerinde Özetleme İşlemi\n\nAşağıdaki örnekte, orijinal veri setindeki sayısal sütunların ortalamalarını hesaplayarak yeni bir veri çerçevesi oluşturmayı gösteriyoruz.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(9)\ndf &lt;- data.frame(group = sample(c(\"G1\", \"G2\"), 5, replace = TRUE),\n                 x = sample(1:50, 5), y = sample(1:50, 5))\n\n# Yeni sütunlar: 'mean_x' ve 'mean_y'\ndf_2 &lt;- df %&gt;%\n   summarise(mean_x = mean(x), # x sütununun ortalaması\n             mean_y = mean(y))  # y sütununun ortalaması\n\n# Veriyi görüntüleme\ndf_2 # x ve y sütunlarının ortalaması alınmış veri seti.\n\n  mean_x mean_y\n1   21.6   38.2\n\n\nSonuçta elde edilen çıktı, giriş fonksiyonu tarafından döndürülen değerler kadar satır içerecektir.\n\n5.2.3.1 Gruplara Göre Veriyi Özetleme (group_by)\n\nsummarise fonksiyonu, group_by ile birlikte kullanıldığında, her grup için istatistiksel özetler oluşturmak açısından oldukça etkili bir yöntem sunar. Bu kombinasyon, veri setini belirli bir değişkene göre gruplandırarak, her grup için özelleştirilmiş özet istatistiklerin elde edilmesini sağlar.\nAşağıdaki örnek, group değişkenine göre gruplandırılmış veri seti üzerinde, her sütunun ortalama değerini hesaplayarak özet bir veri çerçevesi oluşturmaktadır.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(9)\ndf &lt;- data.frame(group = sample(c(\"G1\", \"G2\"), 5, replace = TRUE),\n                 x = sample(1:50, 5),\n                 y = sample(1:50, 5))\n\n# Gruplara göre 'x' ve 'y' sütunlarının toplamları\ndf_2 &lt;- df %&gt;%\n   group_by(group) %&gt;%\n   summarise(mean_x = sum(x), # x sütununun toplamı\n             mean_y = sum(y))  # y sütununun toplamı\n\n# Veriyi görüntüleme\ndf_2 # Gruplara göre özetlenmiş veri seti.\n\n# A tibble: 2 × 3\n  group mean_x mean_y\n  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;\n1 G1        52     97\n2 G2        56     94\n\n\n\nÇoklu Gruplara Göre Veri Setini Özetleme\n\nAyrıca, birden fazla kategorik değişkene göre gruplama yapabilirsiniz. Bu durumda, fonksiyon her grup ve alt grup için istatistiksel özetler hesaplar. Varsayılan olarak, çıktı, birinci kategorik değişkene göre gruplandırılır ve bu durum bir mesaj ile belirtilir.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(9)\ndf &lt;- data.frame(group = sample(c(\"G1\", \"G2\"), 5, replace = TRUE),\n                 group_2 = sample(c(\"G3\", \"G4\"), 5, replace = TRUE),\n                 x = sample(1:50, 5),\n                 y = sample(1:50, 5))\n\n# Gruplara göre 'x' ve 'y' sütunlarının toplamları\ndf_2 &lt;- df %&gt;%\n   group_by(group, group_2) %&gt;% # 'group' ve 'group_2' sütunlarına göre gruplama\n   summarise(sum_x = sum(x),    # x sütununun toplamını hesaplar\n             sum_y = sum(y))    # y sütununun toplamını hesaplar\n\n# Veriyi görüntüleme\ndf_2 # Gruplara göre özetlenmiş veri seti.\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group group_2 sum_x sum_y\n  &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n1 G1    G3         74    86\n2 G1    G4         18    30\n3 G2    G3         48    22\n4 G2    G4         37    35\n\n\n\n\n.groups argümanı\n\n.groups argümanı isteğe bağlıdır ve gruplama işlemi sonrası grupların nasıl ele alınacağını kontrol etmek için kullanılır. Aşağıdaki değerlerden birini alabilir:\n\n\n\"drop_last\": Eğer birden fazla gruplama seviyesi varsa, son gruplama seviyesi kaldırılır, ancak diğerleri korunur. Örneğin, iki kategorik değişkenle gruplama yaptıysanız, birinci değişkene göre gruplama devam eder.\n\n\"drop\": Tüm gruplama seviyelerini kaldırır. Sonuç, gruplandırılmamış, düz bir veri çerçevesi olur.\n\n\"keep\": Orijinal gruplama yapısını korur. Özetleme işlemi tamamlandıktan sonra veri, hala gruplandırılmış halde kalır.\n\n\"rowwise\": Her satırı kendi başına bir grup olarak ele alır. Bu, satır bazında işlem yapmak için kullanılır ve genellikle özelleştirilmiş hesaplamalarda faydalıdır.\n\n\n\nGruplama Sonrası Gruplama Seviyelerini Kaldırma .groups\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(9)\ndf &lt;- data.frame(group = sample(c(\"G1\", \"G2\"), 5, replace = TRUE),\n                 group_2 = sample(c(\"G3\", \"G4\"), 5, replace = TRUE),\n                 x = sample(1:50, 5),\n                 y = sample(1:50, 5))\n\n# Gruplara göre 'x' ve 'y' sütunlarının toplamları, tüm gruplama seviyeleri kaldırılır\ndf_2 &lt;- df %&gt;%\n   group_by(group, group_2) %&gt;% # 'group' ve 'group_2' sütunlarına göre gruplama\n   summarise(sum_x = sum(x),    # x sütununun toplamı\n             sum_y = sum(y),    # y sütununun toplamı\n             .groups = \"drop\")  # Tüm gruplama seviyelerini kaldırır\n\n# Veriyi görüntüleme\ndf_2 # Gruplama bilgisi olmadan özetlenmiş veri seti.\n\n# A tibble: 4 × 4\n  group group_2 sum_x sum_y\n  &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n1 G1    G3         74    86\n2 G1    G4         18    30\n3 G2    G3         48    22\n4 G2    G4         37    35\n\n\n\nAynı işlem ungroup() fonksyonu ile de yapılabilir:\n\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(9)\ndf &lt;- data.frame(group = sample(c(\"G1\", \"G2\"), 5, replace = TRUE),\n                 group_2 = sample(c(\"G3\", \"G4\"), 5, replace = TRUE),\n                 x = sample(1:50, 5),\n                 y = sample(1:50, 5))\n\n# Gruplara göre 'x' ve 'y' sütunlarının toplamları, ardından gruplama kaldırılır\ndf_2 &lt;- df %&gt;%\n   group_by(group, group_2) %&gt;% # 'group' ve 'group_2' sütunlarına göre gruplama\n   summarise(sum_x = sum(x),     # x sütununun toplamını hesaplar\n             sum_y = sum(y)) %&gt;% # y sütununun toplamını hesaplar\n   ungroup()                     # Gruplama kaldırılır\n\n# Veriyi görüntüleme\ndf_2 # Gruplama bilgisi kaldırılmış özetlenmiş veri seti.\n\n# A tibble: 4 × 4\n  group group_2 sum_x sum_y\n  &lt;chr&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n1 G1    G3         74    86\n2 G1    G4         18    30\n3 G2    G3         48    22\n4 G2    G4         37    35\n\n\n\n5.2.3.2 Birden Fazla Sütunu Özetleme\nBirden fazla sütunu manuel olarak belirtmek yerine, summarise ve across kombinasyonunu kullanarak bir koşula göre sütunları seçerek özetler oluşturabilirsiniz. Sütunları seçmek için kullanılan yardımcı fonksiyonların listesine göz atabilirsiniz.\nAşağıdaki örnekte, group sütunu hariç tüm sütunların varyansı hesaplanmakta ve sonuç sütunları, orijinal sütun adlarına “var” eklenerek yeniden adlandırılmaktadır.\n\n# Gerekli paketin yüklenmesi\nlibrary(tidyverse)\n\n# Örnek veri\nset.seed(9)\ndf &lt;- data.frame(group = sample(c(\"G1\", \"G2\"), 5, replace = TRUE),\n                 x = sample(1:50, 5), \n                 y = sample(1:50, 5))\n\n# Varyans hesaplama: 'group' hariç tüm sütunların varyansı\ndf_2 &lt;- df %&gt;% \n  summarise(\n    across(!group,  # 'group' sütunu hariç diğer sütunlar\n           var,     # Varyans hesaplamak için 'var' fonksiyonu\n           .names = \"{.col}_var\")) # Sütun adlarına \"_var\" ekler\n\n# Veriyi görüntüleme\ndf_2 # 'group' dışındaki sütunların varyansını içeren veri seti.\n\n  x_var y_var\n1 254.3 149.2",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Veri Manipülasyonu</span>"
    ]
  },
  {
    "objectID": "veri_manipulasyonu.html#veri-şekillendirme",
    "href": "veri_manipulasyonu.html#veri-şekillendirme",
    "title": "\n5  Veri Manipülasyonu\n",
    "section": "\n5.3 Veri Şekillendirme",
    "text": "5.3 Veri Şekillendirme\n\n5.3.1 Veri Çerçevelerini Birleştirme: merge()\n\nR’deki merge fonksiyonu, iki veri çerçevesini ortak sütunlar veya satır isimleri aracılığıyla birleştirmeye olanak tanır. Bu fonksiyon, sol birleşim (left join), iç birleşim (inner join), sağ birleşim (right join) veya tam birleşim (full join) gibi farklı veri tabanı (SQL) birleşim türlerini gerçekleştirebilir. Bu eğitimde, R’nin temel fonksiyonlarını kullanarak veri setlerini birleştirmenin çeşitli yöntemlerini örneklerle öğrenebilirsiniz.\n\n5.3.1.1 R’deki merge() Fonksiyonu\n\nlibrary(tidyverse)\n\n# merge(x, y, ...)\n\nArgümanlar\n\n\nx, y: Birleştirilecek veri çerçeveleri veya dönüştürülebilecek diğer objeler.\n\nby: Birleştirme işlemi için kullanılacak ortak sütunların adları. Varsayılan olarak, her iki veri çerçevesinde bulunan sütun adlarının kesişimi kullanılır.\n\nby.x, by.y: Sırasıyla x ve y veri çerçevelerinden birleştirme için kullanılacak sütunların adları. Özel sütunlar belirtmek için kullanılır.\n\nall: TRUE olarak ayarlandığında hem all.x hem de all.y TRUE olur ve tam birleşim (full join) gerçekleştirilir.\n\nall.x, all.y: all.x = TRUE: x’deki tüm satırları korur, y’de eşleşmeyenler için eksik değerler (NA) eklenir (sol birleşim - left join). all.y = TRUE: y’deki tüm satırları korur, x’de eşleşmeyenler için eksik değerler (NA) eklenir (sağ birleşim - right join).\n\nsort: TRUE ise çıktı, birleştirme için kullanılan sütunlara göre sıralanır. Varsayılan değer TRUE’dur.\n\nsuffixes: Ortak sütun isimlerini ayırt etmek için kullanılan ekler. Varsayılan olarak c(\".x\", \".y\") olarak ayarlanmıştır.\n\nno.dups: TRUE ise, tekrarlanan sütun adlarını önlemek için daha fazla ekler ekler.\n\nincomparables: Eşleştirilemeyen değerlerle nasıl başa çıkılacağını belirtir. Varsayılan olarak NULL’dır.\n\nÖrnek Veri Çerçevesi Oluşturma - 1\n\n# Örnek veri çerçevesi oluşturma\ndata1 &lt;- data.frame(ID = 1:2,            # ID sütunu, 1 ve 2 değerleri\n                    X1 = c(\"a1\", \"a2\"),  # X1 sütunu, \"a1\" ve \"a2\" değerleri\n                    stringsAsFactors = FALSE) # 'stringsAsFactors' parametresi,\n# karakter sütunlarının faktör yerine karakter olarak saklanmasını sağlar.\n\n# Veri çerçevesini görüntüleme\ndata1\n\n  ID X1\n1  1 a1\n2  2 a2\n\n\nÖrnek Veri Çerçevesi Oluşturma - 2\n\n# İkinci veri çerçevesi oluşturma\ndata2 &lt;- data.frame(ID = 2:3,            # ID sütunu, 2 ve 3 değerleri\n                    X2 = c(\"b1\", \"b2\"),  # X2 sütunu, \"b1\" ve \"b2\" değerleri\n                    stringsAsFactors = FALSE) # 'stringsAsFactors' parametresi,\n# karakter sütunlarının faktör yerine karakter olarak saklanmasını sağlar.\n\n# Veri çerçevesini görüntüleme\ndata2\n\n  ID X2\n1  2 b1\n2  3 b2\n\n\n. . .\n\n\n5.3.1.2 Inner Join - İç Birleştirme İşlemi\nInner join işlemi ile veri çerçevelerini birleştirmek için, birleştirilecek veri çerçevelerinin adlarını (data1 ve data2) ve birleştirme işleminin gerçekleştirileceği ortak sütunun adını (ID sütunu) belirtmek yeterlidir. Bu işlem, iki veri çerçevesinin kesişim kümesini oluşturarak her iki çerçevede de bulunan ortak öğeleri içeren bir yapı sağlar.\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# İç birleştirme işlemi: 'inner_join' kullanımı\ninner_join(data1, data2, by = \"ID\") # 'ID' sütununa göre birleştirme\n\n  ID X1 X2\n1  2 a2 b1\n\n\n\n\n\ninner_join, dplyr paketinin bir fonksiyonudur ve iki veri çerçevesini iç birleştirme (inner join) mantığıyla birleştirir.\n\nİç birleştirme (inner join), yalnızca her iki veri çerçevesinde de ortak olan satırları birleştirir. Ortak bir sütun üzerinden eşleşmeyen satırlar sonuçta yer almaz.\n\nby = \"ID\": Birleştirme işleminin ID sütunu üzerinden yapılacağını belirtir.\nSonuç olarak, sadece ID sütununda ortak olan satırlar birleştirilir ve diğerleri dışlanır.\n\n\n\nInner join, her iki veri çerçevesinde ortak olan satırları birleştirir. Bu işlem sonucunda, her iki veri çerçevesinde de bulunan ID 2 tutulur. Ortaya çıkan sonuç veri çerçevesi, ID 2’ye ait ortak sütunları içerir; bunlar, ilk veri çerçevesinden X1 sütunundaki a2 değeri ve ikinci veri çerçevesinden X2 sütunundaki b1 değeridir. Sonuç olarak, inner join işlemi yalnızca iki veri çerçevesinin ortak öğelerini birleştirir ve diğer öğeleri dışarıda bırakır. Bu yöntem, veri çerçevelerini karşılaştırarak kesişim kümesini oluşturmaya olanak tanır.\n\n5.3.1.3 Left Join - Sol Birleştirme İşlemi\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Sol birleştirme işlemi: 'left_join' kullanımı\nleft_join(data1, data2, by = \"ID\") # 'ID' sütununa göre birleştirme\n\n  ID X1   X2\n1  1 a1 &lt;NA&gt;\n2  2 a2   b1\n\n\n\n\n\nleft_join fonksiyonu, dplyr paketinin bir fonksiyonudur ve iki veri çerçevesini sol birleştirme mantığıyla birleştirir.\n\nSol birleştirme (left join), birinci veri çerçevesindeki tüm satırları tutar ve ikinci veri çerçevesinden sadece eşleşen değerleri ekler. Eğer ikinci veri çerçevesinde bir eşleşme yoksa, eksik değerler NA olarak atanır.\n\nby = \"ID\": Birleştirme işleminin ID sütunu üzerinden yapılacağını belirtir.\n\n\n\nLeft join, sol veri çerçevesindeki tüm satırları tutar ve sağ veri çerçevesinden yalnızca eşleşen değerleri ekler. Eşleşme yoksa eksik değerler (NA) atanır. Inner join ise, yalnızca her iki veri çerçevesinde ortak olan satırları tutar ve diğer satırları dışlar.\n\n5.3.1.4 Right Join - Sağ Birleştirme İşlemi\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Sağ birleştirme işlemi: 'right_join' kullanımı\nright_join(data1, data2, by = \"ID\") # 'ID' sütununa göre sağ birleştirme\n\n  ID   X1 X2\n1  2   a2 b1\n2  3 &lt;NA&gt; b2\n\n\n\n\n\nright_join, dplyr paketinin bir fonksiyonudur ve sağ birleştirme (right join) işlemini gerçekleştirir.\n\nSağ Birleştirme (Right Join), sağ veri çerçevesindeki tüm satırları tutar ve sol veri çerçevesinden yalnızca eşleşen değerleri ekler. Eğer sol veri çerçevesinde eşleşen bir satır yoksa, bu satır için eksik değerler (NA) atanır.\n\nby = \"ID\": Birleştirmenin ID sütunu üzerinden yapılacağını belirtir.\n\n\n\nRight join, sağ veri çerçevesindeki tüm satırları korurken sol veri çerçevesinden yalnızca eşleşen değerleri ekler ve eşleşme olmayan satırlar için eksik değerler (NA) atar. Left join ile farkı, Right join’in sağ veri çerçevesini referans alması, Left join’in ise sol veri çerçevesini referans almasıdır. Inner join ile farkı ise, Right join sağ veri çerçevesindeki tüm satırları tutarken, Inner join yalnızca her iki veri çerçevesinde ortak olan satırları döndürmesidir; bu nedenle Inner join eksik değer içermezken, Right join eksik değerler barındırabilir.\n\n5.3.1.5 Full Join - Tam Birleştirme İşlemi\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Tam birleştirme işlemi: 'full_join' kullanımı\nfull_join(data1, data2, by = \"ID\") # 'ID' sütununa göre tam birleştirme\n\n  ID   X1   X2\n1  1   a1 &lt;NA&gt;\n2  2   a2   b1\n3  3 &lt;NA&gt;   b2\n\n\n\n\n\nfull_join, dplyr paketinin bir fonksiyonudur ve tam birleştirme (full join) işlemini gerçekleştirir.\n\nTüm Birleştirme (full_join), iki veri çerçevesindeki tüm satırları tutar. Her iki veri çerçevesinde de eşleşen satırlar birleştirilir; eşleşmeyen satırlar ise eksik değerler (NA) ile tamamlanır.\n\nby = \"ID\": Birleştirme işleminin ID sütunu üzerinden yapılacağını belirtir.\n\n\n\nFull join, her iki veri çerçevesindeki tüm satırları sonuç veri çerçevesine dahil eder. Ortak olan satırlar birleştirilir, eşleşmeyen satırlar ise eksik değerlerle (NA) tamamlanır. Bu yöntem, iki veri çerçevesinin birleşim kümesini oluşturur. Inner join ise yalnızca her iki veri çerçevesinde ortak olan satırları içerir ve eşleşmeyen satırları dışlar. Bu yöntem, iki veri çerçevesinin kesişim kümesini oluşturur. Full join eksik değerler barındırırken, Inner join sadece ortak değerleri içerdiği için eksik değer içermez.\n\n5.3.1.6 Semi Join - Yarı Birleştirme İşlemi\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Yarı birleştirme işlemi: 'semi_join' kullanımı\nsemi_join(data1, data2, by = \"ID\") # 'ID' sütununa göre yarı birleştirme\n\n  ID X1\n1  2 a2\n\n\n\n\n\nsemi_join, dplyr paketinin bir fonksiyonudur ve yarı birleştirme (semi join) işlemini gerçekleştirir.\n\nSemi Join, yalnızca birinci veri çerçevesindeki (data1) satırları döndürür, ancak bu satırlar ikinci veri çerçevesiyle (data2) eşleşen satırlardır.\n\nby = \"ID\": Eşleşmenin ID sütunu üzerinden yapılacağını belirtir.\nEşleşen satırlara yalnızca birinci veri çerçevesindeki sütunlar eklenir, ikinci veri çerçevesinin sütunları eklenmez.\n\n\n\nSemi join ve Inner join arasındaki temel fark, sonuç veri çerçevesinin içeriğidir. Inner join, her iki veri çerçevesinde ortak olan satırları birleştirir ve sonuç veri çerçevesine her iki veri çerçevesinin sütunlarını ekler. Semi join ise sadece birinci veri çerçevesindeki ortak satırları döndürür ve ikinci veri çerçevesinin sütunlarını sonuçta dahil etmez. Semi join, eşleşen satırları birinci veri çerçevesi perspektifinden filtrelemek için kullanılırken, Inner join, iki veri çerçevesinin kesişimini oluşturur.\n\n5.3.1.7 Anti Join - Anti Birleştirme İşlemi\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Anti birleştirme işlemi: 'anti_join' kullanımı\nanti_join(data1, data2, by = \"ID\") # 'ID' sütununa göre anti join işlemi\n\n  ID X1\n1  1 a1\n\n\n\n\n\nanti_join, dplyr paketinin bir fonksiyonudur ve ters birleştirme (anti join) işlemini gerçekleştirir.\n\nAnti Join, birinci veri çerçevesindeki (data1) ve ikinci veri çerçevesindeki (data2) satırları karşılaştırır ve yalnızca ikinci veri çerçevesiyle eşleşmeyen birinci veri çerçevesi satırlarını döndürür.\n\nby = \"ID\": Eşleşmenin ID sütunu üzerinden yapılacağını belirtir.\n\n\n\n\n5.3.2 Veri Eklemeler: bind_rows(), bind_cols()\n\n\n5.3.2.1 Satır Ekleme: bind_rows()\n\nbind_rows(), birden fazla veri çerçevesini satır bazında birleştirmek için kullanılan bir fonksiyondur. Bu fonksiyon, sütun isimlerini eşleştirerek çalışır ve eksik sütunlar varsa bu sütunlara eksik değerler (NA) atar. rbind() ile farkı, bind_rows()’un sütun sıralarına bağlı kalmadan sütun isimlerini dikkate alarak birleştirme yapabilmesidir. Ayrıca, bind_rows(), sütunları eksik olan veri çerçevelerinde hata vermek yerine eksik değerler ekleyerek birleştirmeyi tamamlar. Buna karşın, rbind(), veri çerçevelerindeki sütun isimlerinin ve sıralarının birebir aynı olmasını gerektirir; aksi halde hata verir. Bu nedenle, bind_rows(), esneklik ve kullanım kolaylığı açısından genellikle daha avantajlıdır.\n\n# Örnek veri çerçevesi 1: data1 oluşturma\ndata1 &lt;- data.frame(\n  x1 = 1:5,          # Sayılar 1'den 5'e kadar\n  x2 = letters[1:5]  # Harfler 'a' ile 'e' arasında\n)\ndata1\n\n  x1 x2\n1  1  a\n2  2  b\n3  3  c\n4  4  d\n5  5  e\n\n# Örnek veri çerçevesi 2: data2 oluşturma\ndata2 &lt;- data.frame(\n  x1 = 0,            # Sabit bir değer\n  x3 = 5:9           # Sayılar 5'ten 9'a kadar\n)\ndata2\n\n  x1 x3\n1  0  5\n2  0  6\n3  0  7\n4  0  8\n5  0  9\n\n# Örnek veri çerçevesi 3: data3 oluşturma\ndata3 &lt;- data.frame(\n  x3 = 5:9,          # Sayılar 5'ten 9'a kadar\n  x4 = letters[5:9]  # Harfler 'e' ile 'i' arasında\n)\ndata3\n\n  x3 x4\n1  5  e\n2  6  f\n3  7  g\n4  8  h\n5  9  i\n\n\n\nBu kodda, üç farklı veri çerçevesi oluşturuluyor:\n\n\ndata1: x1 ve x2 sütunlarından oluşur. x1 sayılar, x2 ise harfler içerir.\n\ndata2: x1 ve x3 sütunlarından oluşur. x1 sabit bir değer, x3 ise bir sayı aralığıdır.\n\ndata3: x3 ve x4 sütunlarından oluşur. x3 sayılar, x4 ise harfler içerir.\n\n\n\nSatır Bazında Birleştirme İşlemi\n\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Satır bazında birleştirme\nresult &lt;- bind_rows(data1, data2)\n\n# Sonucu görüntüleme\nresult\n\n   x1   x2 x3\n1   1    a NA\n2   2    b NA\n3   3    c NA\n4   4    d NA\n5   5    e NA\n6   0 &lt;NA&gt;  5\n7   0 &lt;NA&gt;  6\n8   0 &lt;NA&gt;  7\n9   0 &lt;NA&gt;  8\n10  0 &lt;NA&gt;  9\n\n\n\n\n\nbind_rows(), dplyr paketinden bir fonksiyon olup birden fazla veri çerçevesini satır bazında birleştirir.\nSütunlar eşleştiği sürece, eksik sütunlara NA atanarak işlemi tamamlar.\nBu örnekte, data1 ve data2 satır bazında birleştirilir ve sonuçta her iki veri çerçevesinin birleşimi elde edilir.\nEğer data1 ve data2’de eksik sütunlar varsa, bind_rows() eksik sütunları NA ile doldurur.\n\n\n\n5.3.2.2 Sütun ekleme: bind_cols()\n\nbind_cols(), birden fazla veri çerçevesini sütun bazında birleştirmek için kullanılan bir fonksiyondur. Bu fonksiyon, satır sayılarını dikkate alarak veri çerçevelerini yan yana birleştirir. Eğer veri çerçevelerinde farklı sayıda satır varsa, eksik satırlar için NA eklenir. cbind() ile farkı, bind_cols()’un daha esnek olmasıdır; sütunları birleştirirken veri çerçevelerinin isimlendirilmiş sütun yapılarını korur ve modern veri işleme ihtiyaçlarına daha uygun şekilde çalışır. Buna karşılık, cbind(), sütun isimlerine bakmaz ve uyumsuz satır sayılarına sahip veri çerçevelerinde hata verir. Bu nedenle, bind_cols(), sütun bazında birleştirme işlemlerinde kullanım kolaylığı ve hata toleransı açısından daha avantajlıdır.\n\nSütun Bazında Birleştirme İşlemi\n\n\n# Gerekli paketin yüklenmesi\nlibrary(dplyr)\n\n# Sütun bazında birleştirme\nresult &lt;- bind_cols(data1, data3)\n\n# Sonucu görüntüleme\nresult\n\n  x1 x2 x3 x4\n1  1  a  5  e\n2  2  b  6  f\n3  3  c  7  g\n4  4  d  8  h\n5  5  e  9  i\n\n\n\n\n\nbind_cols(), dplyr paketinden bir fonksiyon olup birden fazla veri çerçevesini sütun bazında birleştirir.\nSatır sayılarını dikkate alır; eğer veri çerçevelerindeki satır sayıları eşleşmezse, eksik satırlar için NA ekler.\nBu örnekte, data1 ve data3 sütun bazında birleştirilir ve iki veri çerçevesi yan yana eklenerek yeni bir veri çerçevesi oluşturulur.",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Veri Manipülasyonu</span>"
    ]
  },
  {
    "objectID": "veri_manipulasyonu.html#metin-string-manipülasyonu",
    "href": "veri_manipulasyonu.html#metin-string-manipülasyonu",
    "title": "\n5  Veri Manipülasyonu\n",
    "section": "\n5.4 Metin (String) Manipülasyonu",
    "text": "5.4 Metin (String) Manipülasyonu\n\n5.4.1 Temel Metin Manipülasyonu\n\n5.4.1.1 Metin Birleştirme\nstr_c(), stringr paketinde bulunan ve metinleri birleştirmek için kullanılan güçlü bir fonksiyondur. Bu fonksiyon, birden fazla metin girdisini yan yana getirerek tek bir metin oluşturur. str_c() fonksiyonu, temel birleştirme işlemlerinin yanı sıra, sep argümanı ile birleştirme sırasında kullanılacak ayırıcı karakteri belirleme, vektörleri birleştirme ve farklı veri tiplerini metin olarak birleştirme gibi birçok esnek özellik sunar.\n\nTemel Metin Birleştirme İşlemi (str_c())\n\n\n\n# Gerekli paketlerin yüklenmesi\n# install.packages(\"stringr\")\nlibrary(stringr)\n\n# Örnek metinler\ntext1 &lt;- \"Merhaba\"\ntext2 &lt;- \"Dunya\"\ntext3 &lt;- \"!\"\n\n# Temel metin birleştirme\nresult_basic &lt;- str_c(text1, text2, text3)\n\n# Sonucu görüntüleme\nresult_basic\n\n[1] \"MerhabaDunya!\"\n\n\n\n1. str_c() Fonksiyonu:\n\n\nAçıklama: str_c() fonksiyonu, stringr paketine ait bir fonksiyondur ve bir veya daha fazla metni birleştirmek için kullanılır. Bu fonksiyon, verilen metinleri ardışık olarak birleştirir.\n\nArgümanlar: text1, text2, text3: Birleştirilecek metinlerdir.\n\nSonuç: Verilen metinler, aralarındaki boşluk veya herhangi bir ek karakter olmadan doğrudan birleştirilir.\n\n2. Birleştirme İşlemi:\n\n\nAçıklama: str_c(text1, text2, text3) kodu, text1, text2, ve text3 metinlerini birleştirir. Sonuç olarak \"MerhabaDunya!\" metni elde edilir.\n\n\n\nsep Argümanı ile Metin Birleştirme\n\n\n# Gerekli paketlerin yüklenmesi\nlibrary(stringr)\n\n# Örnek metinler\ntext1 &lt;- \"Merhaba\"\ntext2 &lt;- \"Dunya\"\ntext3 &lt;- \"!\"\n\n# sep argümanı ile metin birleştirme\nresult_sep &lt;- str_c(text1, text2, text3, sep = \" \") \n# 'sep = \" \"', metinler arasına boşluk ekler.\n\n# Sonucu görüntüleme\nresult_sep\n\n[1] \"Merhaba Dunya !\"\n\n\n\nstr_c() Fonksiyonu ile Veri Çerçevesinde Metin Birleştirme\n\n\n# Örnek veri çerçevesi oluşturma\ndata &lt;- data.frame(\n  ad = c(\"Ali\", \"Ayse\", \"Veli\"),\n  soyad = c(\"Yilmaz\", \"Demir\", \"Kara\"),\n  yas = c(25, 30, 28))\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(stringr)\n\n# 'ad_soyad_yas' adında yeni bir sütun oluşturuluyor ve bu sütun,\n# 'ad', 'soyad' ve 'yas' sütunlarının birleşiminden oluşuyor\ndata$ad_soyad_yas &lt;- str_c(   # str_c() fonksiyonu bu birleştirme işlemini yapıyor.\n  data$ad,           # 'ad' sütunundaki değerler \n  data$soyad,        # 'soyad' sütunundaki değerler \n  \" (\",              # Metin içerisinde sabit bir karakter dizisi, parantez açma\n  data$yas,          # 'yas' sütunundaki değerler (örneğin: 25)\n  \" yas)\",           \n  # Metin içerisinde sabit bir karakter dizisi, parantez kapama ve 'yas' kelimesi\n  sep = \" \"          # Birleştirilen metin parçaları arasına boşluk ekleniyor.\n)\n\n# Sonuç veri çerçevesini görüntüleme\ndata\n\n    ad  soyad yas           ad_soyad_yas\n1  Ali Yilmaz  25 Ali Yilmaz  ( 25  yas)\n2 Ayse  Demir  30 Ayse Demir  ( 30  yas)\n3 Veli   Kara  28  Veli Kara  ( 28  yas)\n\n\n\n\n\n\n\n\nstr_c() vs. paste()\n\n\n\nstr_c() (stringr paketi) ve paste() (base R) Karşılaştırması\n\n# stringr::str_c() örneği\nlibrary(stringr)\nmetin1 &lt;- c(\"a\", \"b\", \"c\")\nmetin2 &lt;- c(1, 2, 3)\nsonuc_str_c &lt;- str_c(metin1, metin2, sep = \"-\")\nsonuc_str_c  # \"a-1\" \"b-2\" \"c-3\"\n\n[1] \"a-1\" \"b-2\" \"c-3\"\n\n# base::paste() örneği\nmetin1 &lt;- c(\"a\", \"b\", \"c\")\nmetin2 &lt;- c(1, 2, 3)\nsonuc_paste &lt;- paste(metin1, metin2, sep = \"-\")\nsonuc_paste  # \"a-1\" \"b-2\" \"c-3\"\n\n[1] \"a-1\" \"b-2\" \"c-3\"\n\n# NA değerler ile paste ve str_c kullanımı\nmetin3 &lt;- c(\"a\", \"b\", NA)\nmetin4 &lt;- c(1, 2, 3)\n\nstr_c(metin3, metin4, sep = \"-\")  # \"a-1\" \"b-2\" NA\n\n[1] \"a-1\" \"b-2\" NA   \n\npaste(metin3, metin4, sep = \"-\") # \"a-1\" \"b-2\" \"NA-3\"\n\n[1] \"a-1\"  \"b-2\"  \"NA-3\"\n\n# collapse argümanı ile paste kullanımı\npaste(metin1, collapse = \", \") # \"a, b, c\"\n\n[1] \"a, b, c\"\n\n# str_c()'de collapse argümanı yoktur.\n\n\n\n\n5.4.1.2 Metin Uzunluğu\nstr_length() fonksiyonu, stringr paketine ait bir fonksiyondur ve verilen metnin karakter sayısını döndürür. Bu fonksiyon, boşluklar da dahil olmak üzere tüm karakterleri sayar. Örnek metinler oluşturularak farklı uzunluklardaki ve özelliklerdeki (boşluklu, boşluksuz) metinlerin uzunlukları str_length() fonksiyonu ile hesaplanır. Ardından cat() fonksiyonu kullanılarak sonuçlar ekrana yazdırılır. str_length() fonksiyonunun bir diğer kullanım şekli de, bir veri çerçevesindeki metinlerin uzunluklarını hesaplayıp, yeni bir sütuna kaydetmektir. Bu işlem sırasında stringAsFactors = FALSE argümanı kullanılarak metinlerin faktör değil, string olarak kalması sağlanır.\n\nstr_length() Fonksiyonu ile Metin Uzunluğu Hesaplama\n\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(stringr)\n\n# str_length() fonksiyonu, stringr paketine ait bir fonksiyondur ve verilen metnin\n# karakter sayısını döndürür. Bu fonksiyon, boşluklar da dahil olmak üzere tüm\n# karakterleri sayar.\n\n# Örnek metinler\ntext1 &lt;- \"Hello World\"\ntext2 &lt;- \"  Space  \"\ntext3 &lt;- \"MerhabaDunya!\"\n\n# Metinlerin uzunlukları str_length() fonksiyonu ile hesaplanır.\nlength1 &lt;- str_length(text1)\nlength2 &lt;- str_length(text2)\nlength3 &lt;- str_length(text3)\n\n# cat() fonksiyonu ile sonuçlar ekrana yazdırılır.\ncat(\"Text 1:'\",text1, \"\\n\", \"'- Length:\", length1, \"\\n\")\n\nText 1:' Hello World \n '- Length: 11 \n\ncat(\"Text 2: '\", text2, \"' - Length: \", length2)\n\nText 2: '   Space   ' - Length:  9\n\ncat(\"Text 3: '\", text3, \"' - Length: \", length3, \"\\n\")\n\nText 3: ' MerhabaDunya! ' - Length:  13 \n\n\n\n\n\n\n\n\ncat() fonksyonu ve işlevleri\n\n\n\ncat() Fonksiyonu\n\n\nTemel İşlevi: cat() fonksiyonu, R’da metinleri ve diğer değerleri (sayılar, mantıksal değerler vb.) ekrana yazdırmak için kullanılan bir temel fonksiyondur.\n\nÇıktı Biçimi: cat(), print() fonksiyonuna göre daha basit bir çıktı üretir. Genellikle, çıktıya ek bilgiler (satır numaraları, değişken isimleri vb.) eklemez, sadece verilen metni ve değerleri yan yana yazdırır.\n\nBirleştirme: cat() fonksiyonu, birden fazla metin veya değeri birleştirmek için kullanılabilir. Bu, farklı türdeki bilgileri aynı satırda görüntülemek için oldukça kullanışlıdır.\n\nAyırıcı Karakter: cat() fonksiyonu varsayılan olarak metinleri bir boşlukla ayırır, ancak bu davranış sep argümanı ile değiştirilemez. sep argümanı print() fonksiyonunda vardır.\n\nYeni Satır Karakteri: cat() fonksiyonunda yeni bir satıra geçmek için \\n kaçış dizisi (escape sequence) kullanılır. Bu sayede çıktı daha düzenli hale getirilebilir.\n\nGenel Kullanım: cat(), özellikle döngüler içinde veya koşullu çıktıların oluşturulmasında kullanışlıdır. Gelişmiş çıktılar veya değişkenlere ait bilgilerin görüntülenmesi için print() veya message() fonksiyonları daha uygun olabilir.\n\nÖzet:\ncat() fonksiyonu, R’da metin ve değerleri basit bir şekilde ekrana yazdırmak için kullanılan bir araçtır. Özellikle birden fazla metni birleştirmek ve formatlı çıktılar oluşturmak için kullanışlıdır. print() fonksiyonuna göre daha yalın bir çıktı verir ve sep argümanı kullanılamaz, ancak \\n kaçış dizisi ile yeni satır eklenebilir.\n\n\n\nstr_length() Fonksiyonu ile Veri Çerçevesinde Yeni Sütun Eklemek\n\n\n# Gerekli paketlerin yüklenmesi\nlibrary(stringr)\n\n# str_length() fonksiyonunun bir diğer kullanım şekli de, bir veri çerçevesindeki\n# metinlerin uzunluklarını hesaplayıp, yeni bir sütuna kaydetmektir.\n\n# Örnek bir veri çerçevesi oluşturulur\ndata_fruits &lt;- data.frame(\n  text = c(\"apple\", \"banana\", \"cherry\", \"date\"),\n  stringsAsFactors = FALSE # Metinlerin faktör değil string olarak kalmasını sağlar\n)\n\n# str_length() fonksiyonu kullanılarak metinlerin uzunlukları hesaplanır ve \n# yeni bir sütuna eklenir\ndata_fruits$text_length &lt;- str_length(data_fruits$text)\n\n# Sonucu görüntüleme\ndata_fruits\n\n    text text_length\n1  apple           5\n2 banana           6\n3 cherry           6\n4   date           4\n\n\n\n\n\n\n\n\n$ İşareti ile Yeni Sütun/Değişken Eklemek\n\n\n\nR dilinde, veri çerçevelerine yeni sütun eklemek için $ işareti sıkça kullanılır. Bu, veri çerçevesine doğrudan yeni bir sütun eklemeye olanak tanır.\nVeri Çerçevesinde Yeni Değişken Ekleme:\nVeri çerçevesine yeni bir sütun (veya değişken) eklemek için şu adımları izlersiniz:\n\n\n$ işareti kullanarak yeni sütunun adını belirtirsiniz.\nSağdaki kısımda, eklemek istediğiniz değişkenin hesaplamasını veya değerini belirtirsiniz.\n\n\n# data$new_column &lt;- 5  # Tüm satırlar için 5 değeri eklenir.\n\n\nBu işlem, data veri çerçevesine new_column adında yeni bir sütun ekler ve tüm satırlara 5 değeri atar.\n\nVeri Çerçevesine Hesaplanan Değer Ekleme:\nBir sütun, başka sütunlardaki değerlerin hesaplanması ile de eklenebilir. Örneğin, metin uzunlukları, sayılar, vb. hesaplanarak yeni bir sütun oluşturulabilir.\n\n# data$new_column &lt;- data$var1 + data$var2  # var1 ve var2 sütunlarının toplamı\n\n\nBu örnekte, data$new_column sütunu, data$var1 ve data$var2 sütunlarının toplamını içerir.\n\nÖzet:\n\n\n$ işareti, veri çerçevesine yeni bir sütun eklerken kullanılır. Yeni sütunun adı belirlenir ve sağdaki kısımda bu sütuna atanacak değerler veya hesaplamalar belirtilir.\n\nYeni sütun eklemek için: data$new_column &lt;- value şeklinde kullanılır. Bu, veri çerçevesine new_column adında bir sütun ekler ve value’yu bu sütuna atar.\nBu yöntem, veri çerçevesinde hızlı bir şekilde yeni değişkenler oluşturmanızı sağlar ve veri manipülasyonu için oldukça kullanışlıdır.\n\n\n\n\n5.4.1.3 Metin Dönüştürme\n\nBüyük/Küçük Harf Dönüşümleri: str_to_lower() ve str_to_upper()\n\nBu fonksiyonlar, karakter dizilerindeki harfleri tamamen küçük veya büyük harfe dönüştürmek için kullanılır. Bu işlem, metin normalizasyonu ve karşılaştırma gibi işlemlerde oldukça faydalıdır.\n\nstr_to_lower(): Metni tamamen küçük harfe dönüştürür.\nstr_to_upper(): Metni tamamen büyük harfe dönüştürür.\n\n\n# Gerekli paketlerin yüklenmesi\nlibrary(stringr)\n\n# Küçük harfe dönüştürme\ntext &lt;- \"Merhaba Dunya!\"\nlower_text &lt;- str_to_lower(text)\nprint(lower_text) # Çıktı: \"merhaba dunya!\"\n\n[1] \"merhaba dunya!\"\n\n# Büyük harfe dönüştürme\nupper_text &lt;- str_to_upper(text)\nprint(upper_text) # Çıktı: \"MERHABA DÜNYA!\"\n\n[1] \"MERHABA DUNYA!\"\n\n\n\nAlt Dizeleri Çıkarma: str_sub()\n\nBu fonksiyon, bir karakter dizisinden belirli bir başlangıç ve bitiş pozisyonuna göre alt dizeler çıkarmak veya mevcut bir alt diziyi değiştirmek için kullanılır.\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(stringr)\n\n# Örnek bir telefon numarası tanımlanır\nphone_number &lt;- \"+90 123 456 7890\" \n\n# str_sub() fonksiyonu kullanılarak telefon numarasının alan kodu alınır\narea_code &lt;- str_sub(phone_number, 1, 3) # 1.'den 3. karaktere kadar olan kısmı alır.\n\n# Sonucu ekrana yazdırma\nprint(area_code) # Çıktı: \"+90\"\n\n[1] \"+90\"\n\n\n\nBaş ve Sondaki Boşlukları Temizleme: str_trim()\n\nBu fonksiyon, bir metnin başındaki ve sonundaki boşlukları temizlemek için kullanılır. side argümanıyla, sadece baştan, sondan veya her iki taraftan boşlukları temizleme seçeneği sunar.\n\nstr_trim(string): Baş ve sondaki boşlukları temizler.\nstr_trim(string, side = \"left\"): Sadece baştaki boşlukları temizler.\nstr_trim(string, side = \"right\"): Sadece sondaki boşlukları temizler.\n\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(stringr)\n\n# Kullanıcı girdisi (boşluklu)\nuser_input &lt;- \"   Kullanici Adi   \"  \n\n# str_trim() fonksiyonu kullanılarak baştaki ve sondaki boşluklar temizlenir\ncleaned_input &lt;- str_trim(user_input)  # Boşlukları temizler\n\n# Sonucu ekrana yazdırma\nprint(cleaned_input) # Çıktı: \"Kullanici Adi\"\n\n[1] \"Kullanici Adi\"\n\n\n\n5.4.2 Desen Eşleştirme ve Değiştirme\nstr_detect() fonksiyonu, bir karakter vektöründe belirli bir desenin varlığını kontrol etmek için kullanılır. Bu fonksiyon, bir mantıksal vektör (TRUE/FALSE) döndürür.\n\nlibrary(stringr)\n\n#str_detect(string, #Aranacak metin ya da metin vektörü.\n           #pattern) #Aranacak desen (düz metin ya da regex).\n\nstr_detect() Fonksiyonu ile Desen Arama\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(stringr)\n\n# Örnek metinler\ntext_vector &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\", \"apricot\")\n\n# Desen arama örnekleri\n\n# \"a\" içeren kelimeler\nhas_a &lt;- str_detect(text_vector, \"a\")\nhas_a\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n# \"ap\" ile başlayan kelimeler\nhas_ap &lt;- str_detect(text_vector, \"^ap\")\nhas_ap\n\n[1]  TRUE FALSE FALSE FALSE  TRUE\n\n# \"e\" ile biten kelimeler\nhas_e &lt;- str_detect(text_vector, \"e$\")\nhas_e\n\n[1]  TRUE FALSE FALSE  TRUE FALSE\n\n# Rakam içeren kelimeler (bu örnekte yok)\nhas_num &lt;- str_detect(text_vector, \"\\\\d\")\nhas_num\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\n\n\nYukarıdaki kodda, text_vector adında bir metin vektörü tanımlanır. Ardından, str_detect() fonksiyonu kullanılarak bu vektördeki metinlerde belirli desenler aranır. Örneğin, “a” harfini içeren kelimeler, “ap” ile başlayan kelimeler, “e” ile biten kelimeler ve rakam içeren kelimeler kontrol edilir. Sonuçlar, TRUE veya FALSE değerlerinden oluşan mantıksal bir vektör olarak döndürülür.\n\n\n5.4.2.1 Desen Değiştirme: str_replace() ve str_replace_all()\n\nstr_replace() ve str_replace_all() fonksiyonları, metin içindeki belirli desenleri değiştirmek için kullanılır. str_replace() fonksiyonu, desenin ilk eşleşmesini değiştirirken, str_replace_all() fonksiyonu desenin tüm eşleşmelerini değiştirir.\n\n# Gerekli kütüphanenin yüklenmesi\nlibrary(stringr)\n\n# Örnek metin\ntext2 &lt;- \"red apple, green apple, red banana\"\n\n# İlk eşleşmeyi değiştirme\nreplaced_text1 &lt;- str_replace(text2, \"apple\", \"orange\")\nreplaced_text1\n\n[1] \"red orange, green apple, red banana\"\n\n# Tüm eşleşmeleri değiştirme\nreplaced_text2 &lt;- str_replace_all(text2, \"apple\", \"orange\")\nreplaced_text2\n\n[1] \"red orange, green orange, red banana\"\n\n\n\n5.4.3 Regex Temelleri (Düzenli İfadeler - Regular Expressions)\nTemel Regex Karakterleri\n\n\n\n\n\n\n\nKarakter\nAnlamı\nÖrnek\n\n\n\n.\nHerhangi bir karakter\n\na.b → “acb”, “a2b”\n\n\n*\nÖnceki karakter 0 veya daha fazla kez\n\nab* → “a”, “ab”, “abb”\n\n\n+\nÖnceki karakter 1 veya daha fazla kez\n\nab+ → “ab”, “abb”\n\n\n?\nÖnceki karakter 0 veya 1 kez\n\nab? → “a”, “ab”\n\n\n[]\nKarakter kümesi\n\n[aeiou] → “a”, “e”, “o”\n\n\n^\nBaşlangıç\n\n^abc → “abcdef”\n\n\n$\nBitiş\n\nxyz$ → “123xyz”\n\n\n\\d\nRakam (digit)\n\n\\d+ → “123”, “45”\n\n\n\\w\nKelime karakteri\n\n\\w+ → “abc”, “123”, “word1”\n\n\n\\s\nBoşluk karakteri\n\n\\s+ → ” “,” ”\n\n\n\nRegex ile str_detect(), str_replace(), ve str_replace_all() Kullanımı\n\n# Örnek metinler\nmetin &lt;- c(\"abc123\", \"def456\", \"ghi\")\n# - \"abc123\": Hem harf hem rakam içerir.\n# - \"def456\": Hem harf hem rakam içerir.\n# - \"ghi\": Harf içerir.\n\n# Desen arama işlemi\nsonuc &lt;- str_detect(metin, \"\\\\d+\")\n# - \"\\\\d+\": Bir veya daha fazla rakamı arayan düzenli ifade (regex).\n# - Dönen sonuç: Her bir öğe için TRUE/FALSE (mantıksal vektör).\n\nprint(sonuc)\n\n[1]  TRUE  TRUE FALSE\n\n# Açıklama: Her bir öğe en az bir rakam içerdiği için tüm sonuçlar TRUE döner.\n\nÖrnek Kullanım:\n\n# Gerekli paketlerin yüklenmesi\n# install.packages(\"kableExtra\")\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(stringr)\n\n# Örnek tibble oluşturma\ndata_regex &lt;- tibble(\n  ID = 1:5,\n  Customer_Info = c(\n    \" John Doe, john.doe@example.com \",\n    \" Jane Smith, JANE.SMITH@example.com \",\n    \" Bob Brown, BOB.BROWN@example.com \",\n    \" Alice Johnson, alice.johnson@example.com \",\n    \" Carol White, carol.white@example.com \"\n  )\n)\n\n# Veri manipülasyonu\nprocessed_data_regex &lt;- data_regex %&gt;%\n  # 1. str_trim(): Baş ve sondaki boşlukları temizleme\n  mutate(Customer_Info = str_trim(Customer_Info)) %&gt;%\n  \n  # 2. str_detect(): E-posta adreslerinin doğru formatta olup olmadığını kontrol etme\n  mutate(Valid_Email = str_detect(Customer_Info, \"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}\")) %&gt;%\n  \n  # 3. str_sub(): İsim ve e-posta adreslerini ayıklama\n  mutate(\n    Name = str_sub(Customer_Info, 1, str_locate(Customer_Info, \",\")[, 1] - 1), \n    # Virgülden önceki kısmı isim olarak al\n    Email = str_sub(Customer_Info, str_locate(Customer_Info, \",\")[, 1] + 2)    \n    # Virgülden sonraki kısmı e-posta olarak al\n  ) %&gt;%\n    \n    # 4. str_to_lower() ve str_to_upper(): İsimleri büyük harf, e-posta adreslerini\n    # küçük harf yapma\n  mutate(\n    Name = str_to_upper(Name),\n    Email = str_to_lower(Email)\n  ) %&gt;%\n  \n  # 5. str_length(): İsmin uzunluğunu hesaplama\n  mutate(Name_Length = str_length(Name)) %&gt;%\n  \n  # 6. str_replace(): E-postalardaki \"example.com\" kısmını \"domain.com\" ile değiştirme\n  mutate(Email = str_replace(Email, \"example.com\", \"domain.com\")) %&gt;%\n  \n  # 7. str_c(): İsim ve yeni e-posta adresini birleştirerek tam müşteri bilgisi oluşturma\n  mutate(Updated_Info = str_c(Name, \" &lt;\", Email, \"&gt;\"))\n\n# Sonuçları göster\nkableExtra::kable(processed_data_regex)\n\n\n\nID\nCustomer_Info\nValid_Email\nName\nEmail\nName_Length\nUpdated_Info\n\n\n\n1\nJohn Doe, john.doe@example.com\nTRUE\nJOHN DOE\njohn.doe@domain.com\n8\nJOHN DOE john.doe@domain.com\n\n\n\n2\nJane Smith, JANE.SMITH@example.com\nTRUE\nJANE SMITH\njane.smith@domain.com\n10\nJANE SMITH jane.smith@domain.com\n\n\n\n3\nBob Brown, BOB.BROWN@example.com\nTRUE\nBOB BROWN\nbob.brown@domain.com\n9\nBOB BROWN bob.brown@domain.com\n\n\n\n4\nAlice Johnson, alice.johnson@example.com\nTRUE\nALICE JOHNSON\nalice.johnson@domain.com\n13\nALICE JOHNSON alice.johnson@domain.com\n\n\n\n5\nCarol White, carol.white@example.com\nTRUE\nCAROL WHITE\ncarol.white@domain.com\n11\nCAROL WHITE carol.white@domain.com\n\n\n\n\n\n\n\n5.4.4 Janitor Paketi ile Veri Temizleme\n\n# Gerekli paketlerin yüklenmesi\nlibrary(janitor)\n\n# Örnek veri çerçevesi\ndata_janitor &lt;- data.frame(\n  \"First Name\" = c(\"Ali\", \"Ayse\", \"Mehmet\"),\n  \"LastNAME\" = c(\"Kara\", \"Demir\", \"Yilmaz\"),\n  \"DateOFBirth\" = c(\"1990-01-01\", \"1985-05-12\", \"2000-07-22\"),\n  stringsAsFactors = FALSE\n)\n\n# Orijinal veri çerçevesi\nprint(data_janitor)\n\n  First.Name LastNAME DateOFBirth\n1        Ali     Kara  1990-01-01\n2       Ayse    Demir  1985-05-12\n3     Mehmet   Yilmaz  2000-07-22\n\n# clean_names() fonksiyonu ile sütun isimlerini temizleme\ncleaned_data_janitor &lt;- clean_names(data_janitor)\n\n# Temizlenmiş veri çerçevesi\nprint(cleaned_data_janitor)\n\n  first_name last_name date_of_birth\n1        Ali      Kara    1990-01-01\n2       Ayse     Demir    1985-05-12\n3     Mehmet    Yilmaz    2000-07-22",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Veri Manipülasyonu</span>"
    ]
  },
  {
    "objectID": "veri_manipulasyonu.html#fonksiyonlarla-veri-manipülasyonu",
    "href": "veri_manipulasyonu.html#fonksiyonlarla-veri-manipülasyonu",
    "title": "\n5  Veri Manipülasyonu\n",
    "section": "\n5.5 Fonksiyonlarla Veri Manipülasyonu",
    "text": "5.5 Fonksiyonlarla Veri Manipülasyonu\n\n5.5.1 Fonksiyon Uygulamaları:\n\n\napply(), sapply(), lapply() gibi fonksiyonlar ile veri üzerinde işlemler gerçekleştirme.\n\n5.5.2 Gruplama İşlemleri:\n\n\ntapply() fonksiyonu ile gruplar üzerinde hesaplamalar yapma.\n\n5.5.3 Kesim ve Sınıflandırma:\n\n\ncut() fonksiyonu ile sayısal veriyi sınıflara ayırma.\n\nReferanslar\nhttps://www.tidyverse.org/\nhttps://dplyr.tidyverse.org/\nhttps://tibble.tidyverse.org/\nhttps://stringr.tidyverse.org/\nhttps://r4ds.hadley.nz/\nhttps://mine-cetinkaya-rundel.github.io/r4ds-solutions/\nhttps://www.geeksforgeeks.org/merge-function-in-r/\nhttps://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti\nhttps://statisticsglobe.com/r-bind_rows-bind_cols-functions-dplyr-package\nhttps://r-coder.com/r-data-manipulation/\nhttps://r-primers.andrewheiss.com/\nhttps://app.datacamp.com/learn/courses/data-manipulation-with-dplyr",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Veri Manipülasyonu</span>"
    ]
  },
  {
    "objectID": "veri_temizleme.html",
    "href": "veri_temizleme.html",
    "title": "\n6  Veri Temizleme\n",
    "section": "",
    "text": "6.1 Eksik Verilerle Çalışma\nBüyük veri, hacim, hız, çeşitlilik, doğruluk ve değer gibi özellikleriyle öne çıkar. Bu karmaşık veri dünyasında anlamlı bilgiler çıkarma ve analiz süreçlerini yönetme görevi veri bilimine düşmektedir. Ancak, büyük veri analizi sürecinde en sık karşılaşılan zorluklardan biri eksik verilerdir. Eksik veriler, genellikle yanıt eksiklikleri veya veri kaybı gibi nedenlerle ortaya çıkar ve bu durum, analiz sonuçlarının doğruluğunu ve güvenilirliğini tehlikeye atar. Eksik veri problemi, istatistiksel gücün azalması, parametre tahminlerinde yanlılık, örneklemlerin temsil gücünün zayıflaması ve analiz süreçlerinin karmaşıklaşması gibi sorunlara yol açabilir. Bu nedenle, eksik verilerle doğru bir şekilde başa çıkmak, sağlam ve güvenilir analiz sonuçları elde etmek için kritik öneme sahiptir.\nhttps://www.rpubs.com/justjooz/miss_data\nEksik veri yönetimi, veri analizi sürecinin temel yapı taşlarından biri olarak değerlendirilmelidir. Bu bağlamda, eksik verilerin tespiti ve görselleştirilmesi için naniar paketi kullanılabilir; özellikle vis_miss() fonksiyonu, eksik veri desenlerini analiz etmek için etkili bir araçtır. Eksik verileri doldurma yöntemleri arasında, özellikle çok değişkenli veri setleri için uygun olan mice paketi dikkat çeker. Bu paket, birden fazla doldurma yöntemi sunarak, veri setinin istatistiksel gücünü ve temsiliyetini artırır. Ayrıca, eksik veri profillerini detaylı bir şekilde analiz etmek ve raporlamak için dlookr paketi gibi araçlardan yararlanmak mümkündür. Eksik veri yönetiminde kullanılan bu yaklaşımlar, veri analistlerinin daha doğru öngörüler yapmasını sağlayarak, stratejik karar alma süreçlerine destek olur. Böylece, eksik veri probleminin üstesinden gelmek için yöntem seçimi ve uygulaması, veri analizinde güvenilirlik ve doğruluk açısından vazgeçilmez bir süreçtir.\nVeri Seti airquality\n# Gerekli kütüphanelerin yüklenmesi\nlibrary(dplyr)\n# datasets paketini yükleme (otomatik olarak yüklü olmalı)\nlibrary(datasets)\n\n# airquality veri setinin görüntülenmesi\nhead(airquality, 10)\n\n   Ozone Solar.R Wind Temp Month Day\n1     41     190  7.4   67     5   1\n2     36     118  8.0   72     5   2\n3     12     149 12.6   74     5   3\n4     18     313 11.5   62     5   4\n5     NA      NA 14.3   56     5   5\n6     28      NA 14.9   66     5   6\n7     23     299  8.6   65     5   7\n8     19      99 13.8   59     5   8\n9      8      19 20.1   61     5   9\n10    NA     194  8.6   69     5  10",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Veri Temizleme</span>"
    ]
  },
  {
    "objectID": "veri_temizleme.html#eksik-verilerle-çalışma",
    "href": "veri_temizleme.html#eksik-verilerle-çalışma",
    "title": "\n6  Veri Temizleme\n",
    "section": "",
    "text": "Airquality Veri Seti\nairquality veri seti, 1973 yılında New York’ta ölçülen hava kalitesi değerlerini içeren bir veri setidir. Bu veri seti, hava kalitesini etkileyen çeşitli değişkenleri içerir ve çevresel analizler için kullanılır. Veri seti, aşağıdaki değişkenlerden oluşur:\n\n\nOzone: Ozon seviyelerini ifade eder (ppb - parts per billion).\n\nSolar.R: Solar radyasyon değerlerini içerir (langley).\n\nWind: Rüzgar hızını içerir (mph - miles per hour).\n\nTemp: Günlük maksimum sıcaklık ölçümlerini içerir (Fahrenheit).\n\nMonth: Ölçümün yapıldığı ayı temsil eder (1-12 arasında).\n\nDay: Ölçümün yapıldığı gün bilgisini içerir (1-31 arasında).\n\n\n\n6.1.1 Ad-hoc Yöntemler - Liste Bazlı Silme (Listwise Deletion)\nEksik verilerle başa çıkmak için veri bilimciler tarafından en sık kullanılan yöntemlerden biri, eksik değerlere sahip durumları tamamen çıkarmak ve yalnızca kalan veri setini analiz etmektir. Bu yönteme liste bazlı silme veya tam durum analizi (complete-case analysis) denir. R programında na.omit() fonksiyonu, veri setinde bir veya daha fazla eksik değeri olan tüm durumları kaldırır.\n\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\n\nVeri setinde bazı NA değerlerini şimdiden gözlemleyebiliyoruz.\nSonraki adımda, NA değerleri içeren durumları veri setinden kaldırıyoruz.\n\nna.omit() ile Eksik Verileri Çıkarma\n\n\n# Eksik verileri çıkarma\nairquality_omit &lt;- na.omit(airquality)\n\n# İlk birkaç satırı görüntüleme\nhead(airquality_omit)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n7    23     299  8.6   65     5   7\n8    19      99 13.8   59     5   8\n\n\n\nİlk çıktıda airquality, eksik değerler (NA) hala veri setinde bulunurken, airquality_omit veri setinde eksik değerler içeren satırlar tamamen çıkarılmıştır. Bu, satır sayısının azalmasına yol açar.\n\n\n\n\n\n\n\nListe bazlı silme\n\n\n\nListe bazlı silme (Listwise deletion) yöntemi, eksik veriler içeren satırları tamamen kaldırdığı için genellikle birkaç nedenden dolayı tercih edilmez:\n\n\nVeri Kaybı: Eksik değerlere sahip satırların tamamen silinmesi, veri setinin boyutunu küçültür ve bu da analiz için kullanılabilir bilgi miktarını azaltır. Bu durum, özellikle eksik verilerin oranı yüksekse, analiz sonuçlarını ciddi şekilde etkileyebilir.\n\nÖrnekleme Yanlılığı: Eksik veriler rastgele (MCAR - Missing Completely at Random) değilse, bu yöntemin kullanımı örneklemde yanlılığa neden olabilir. Sonuç olarak, elde edilen analiz sonuçları tüm veri setini veya popülasyonu doğru bir şekilde temsil etmeyebilir.\n\nİstatistiksel Güç Kaybı: Veri setinin boyutunun küçülmesi, istatistiksel gücü azaltır. Bu da yapılan analizlerin daha az anlamlı sonuçlar üretmesine yol açabilir.\n\nKarmaşık Eksiklik Yapıları: Eksik veriler farklı desenler izleyebilir ve listwise deletion, bu desenleri dikkate almadan tüm eksik satırları kaldırır. Bu, özellikle eksik verilerin analizin anahtar değişkenlerinde olduğu durumlarda önemli bilgilerin kaybolmasına neden olabilir.\n\nBu nedenlerle, eksik verilerle başa çıkmak için çoklu doldurma (multiple imputation) veya eksik değerlerin modelleme yöntemleriyle ele alınması gibi daha gelişmiş yöntemler genellikle listwise deletion’a tercih edilir.\n\n\n\n6.1.2 Eksik Verilerin Grafik Olarak Tespiti\n\nEksik Verileri Görselleştirme (naniar Paketinin Kullanımı)\n\n\n# naniar kütüphanesini yükleme (eğer yüklü değilse)\n# install.packages(\"naniar\")\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Eksik verileri görselleştirme\nvis_miss(airquality)\n\n\n\n\n\n\n\n\nGrafik, vis_miss() fonksiyonu ile oluşturulmuş ve airquality veri setindeki eksik verilerin genel yapısını göstermektedir.\n\n\nSiyah alanlar eksik verileri (Missing) temsil ederken, gri alanlar mevcut verileri (Present) temsil eder.\nOzon değişkeninde %24, Solar.R değişkeninde %5 oranında eksik veri bulunmaktadır. Diğer değişkenler (Wind, Temp, Month, Day) ise eksiksizdir.\n\n\n\n6.1.2.1 Eksik Değerlerin Eşzamanlı Görülmesi\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Eksik verilerin UpSet grafiği ile gösterimi\ngg_miss_upset(airquality)\n\n\n\n\n\n\n\n\ngg_miss_upset(airquality) fonksiyonu, naniar paketine ait bir fonksiyondur ve eksik değerlerin birlikteliğini (co-occurrence) görselleştirmek için UpSetR paketini kullanarak bir grafik oluşturur. Bu grafik, hangi değişkenlerin birlikte eksik olduğunu ve bu kombinasyonların ne sıklıkta görüldüğünü gösterir.\n\n\nÇubuk grafikler (dikey): Her bir çubuk, belirli bir eksik değer kombinasyonunu temsil eder. Çubuğun yüksekliği, bu kombinasyonun veri setinde kaç kez tekrarlandığını gösterir.\n\nNoktalar ve çizgiler (yatay): Her bir değişken için bir nokta bulunur. Eğer bir çubukta o değişkenle ilgili nokta doluysa (yani çizgiyle bağlıysa), o kombinasyonda o değişkende eksik değer olduğu anlamına gelir. Örneğin, sadece “Ozone” değişkenine bağlı bir çubuk, sadece “Ozone” değerinin eksik olduğu satırları temsil eder. Hem “Ozone” hem de “Solar.R” değişkenlerine bağlı bir çubuk ise, her iki değişkende de aynı anda eksik değer olan satırları temsil eder.\n\n\n\n6.1.2.2 Faktör Düzeyine Göre Veri Eksikliğini Görselleştirme\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Eksik verileri faktör düzeyine göre görselleştirme\ngg_miss_fct(x = airquality, fct = Month)\n\n\n\n\n\n\n\n\ngg_miss_fct(x = airquality, fct = Month) fonksiyonu, naniar paketine ait bir fonksiyondur ve airquality veri setindeki eksik verilerin Month değişkenine göre dağılımını görselleştirir. Month burada bir faktör (kategorik değişken) olarak kabul edilir ve her bir ay (5, 6, 7, 8, 9) için ayrı bir çubuk gösterilir.\nGrafikte şunlar görülebilir:\n\n\nX ekseni (Month): Ayları temsil eder (5 = Mayıs, 6 = Haziran, …, 9 = Eylül).\n\nY ekseni (Missing Percentage): Eksik veri yüzdesini temsil eder.\n\nÇubuklar: Her bir ay için bir çubuk bulunur. Çubuğun yüksekliği, o ayda ne kadar eksik veri olduğunu (tüm değişkenler için toplamda) gösterir.\n\nBu grafik, eksik verilerin aylara göre nasıl değiştiğini anlamak için çok faydalıdır. Örneğin, belirli aylarda daha fazla eksik veri olup olmadığını veya eksik verilerin aylara göre bir örüntü izleyip izlemediğini görebilirsiniz. Bu bilgi, veri toplama sürecindeki olası sorunları veya mevsimsel etkileri anlamanıza yardımcı olabilir. Örneğin, eğer belirli bir ayda ölçüm cihazlarında bir arıza olduysa, o ayda daha fazla eksik veri görülebilir.\n\n\nEksik Verileri Faktör Düzeyine Göre Nokta Grafiği ile Görselleştirme\n\n\n# Gerekli paketlerin yüklenmesi\nlibrary(ggplot2)\nlibrary(naniar)\n\n# Eksik veri noktalarını görselleştirme\nggplot(airquality, aes(x = Ozone, y = Solar.R)) +\n  geom_miss_point()  # Eksik verileri noktalar olarak görselleştirir\n\n\n\n\n\n\n\n\n6.1.2.3 dlookr Paketi ile Eksik Veriler\n\n# dlookr kütüphanesini yükleme (gerekli fonksiyon için)\n# install.packages(\"dlookr\")\nlibrary(dlookr)\n\n# Eksik verilerin Pareto grafiği ile gösterimi\nplot_na_pareto(airquality, col = \"blue\")\n\n\n\n\n\n\n\n\nplot_na_pareto(airquality) fonksiyonu, dlookr paketine ait bir fonksiyondur ve airquality veri setindeki eksik değerleri bir Pareto grafiği ile görselleştirir.\n\n\nX ekseni: Değişkenleri temsil eder. Değişkenler, eksik değer sayılarına göre en çoktan en aza doğru sıralanmıştır.\n\nSol Y ekseni: Eksik değer sayısını temsil eder. Her bir değişken için bir çubuk bulunur ve çubuğun yüksekliği o değişkendeki eksik değer sayısını gösterir.\n\nSağ Y ekseni: Kümülatif eksiklik yüzdesini temsil eder. Çizgi grafiği, değişkenler eklendikçe toplam eksiklik oranının nasıl arttığını gösterir.\n\nPareto grafiği, hangi değişkenlerde en çok eksik değer olduğunu ve bu değişkenlerin toplam eksikliğe ne kadar katkıda bulunduğunu hızlıca anlamak için kullanışlıdır. Genellikle, birkaç değişkenin toplam eksikliğin büyük bir kısmını oluşturduğu görülür (“80/20 kuralı” olarak da bilinir). Bu grafik, eksik verilerle başa çıkarken önceliklerin belirlenmesine yardımcı olabilir. Örneğin, en çok eksik değere sahip değişkenlere odaklanmak, genel eksiklik sorununu çözmek için daha etkili bir yaklaşım olabilir. airquality örneğinde Ozone değişkeninin diğerlerine göre çok daha fazla eksik veriye sahip olduğu kolayca görülebilir.\n\nEksik Verilerin Hiyerarşik Kümeleme Grafiği ile Gösterimi dlookr\n\n# dlookr kütüphanesini yükleme\nlibrary(dlookr)\n\n# Eksik verilerin hiyerarşik kümeleme grafiği ile gösterimi\nplot_na_hclust(airquality, main = \"Distribution of missing value\")\n\n\n\n\n\n\n\n\n\n\nplot_na_hclust(airquality, main = \"Distribution of missing value\") fonksiyonu, dlookr paketine ait bir fonksiyondur ve airquality veri setindeki eksik değer örüntülerini hiyerarşik kümeleme (hierarchical clustering) kullanarak görselleştirir.\n\nmain = \"Distribution of missing value\" argümanı, grafiğe bir başlık ekler.\n\nBu grafik, eksik değerlerin veri setinde rastgele mi dağıldığını yoksa belirli örüntüler izleyip izlemediğini anlamak için çok faydalıdır. Örneğin, belirli satır gruplarının benzer eksik değer örüntülerine sahip olduğunu görmek, veri toplama sürecinde veya verilerin doğasında bir sorun olduğunu gösterebilir. Bu bilgi, eksik verilerle nasıl başa çıkılacağına (örneğin, hangi doldurma yönteminin kullanılacağına) karar verirken önemli bir rol oynayabilir.\n\nEksik Verilerin Kesişim Grafiği ile Gösterimi dlookr\n\n# dlookr kütüphanesini yükleme\nlibrary(dlookr)\n\n# Eksik verilerin kesişim grafiği ile gösterimi\nplot_na_intersect(airquality)\n\n\n\n\n\n\n\n\nplot_na_intersect(airquality) fonksiyonu, dlookr paketine ait bir fonksiyondur ve airquality veri setindeki eksik değerlerin kesişimlerini (yani hangi değişkenlerin aynı satırlarda birlikte eksik olduğunu) görselleştirir.\n\n\n6.1.3 Eksik Değerlerin Toplam Sayıları ve Oranları\nn_miss fonksiyonu, verilerdeki tüm NA (yani eksik) değerlerinin toplam sayısını döndürür.\n\n6.1.3.1 NA olan değerlerin sayısı için:\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Eksik değer sayısını hesaplama\nn_miss(airquality)\n\n[1] 44\n\n\n\nn_miss(airquality) fonksiyonu, naniar paketine ait bir fonksiyondur ve airquality veri setindeki toplam eksik değer (NA) sayısını hesaplar. Çıktı olarak [1] 44 değeri döner. Bu, airquality veri setinde toplam 44 adet eksik değer olduğunu gösterir.\n\n\n6.1.3.2 NA olmayan (complete) değerlerin sayısı için:\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Tamamlanmış değer sayısını hesaplama\nn_complete(airquality)\n\n[1] 874\n\n\n\nn_complete(airquality) fonksiyonu, naniar paketine ait bir fonksiyondur ve airquality veri setindeki tamamlanmış (yani eksik olmayan) toplam değer sayısını hesaplar. Çıktı olarak [1] 874 değeri döner. Bu, airquality veri setinde toplam 874 adet tamamlanmış değer olduğunu gösterir.\n\n\n6.1.3.3 NA olan değerlerin oranı için:\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Eksik değer oranını hesaplama\nprop_miss(airquality)\n\n[1] 0.04793028\n\n\n\nprop_miss(airquality) fonksiyonunun çıktısı olan [1] 0.04792626, airquality veri setindeki verilerin yaklaşık %4.79’unun eksik olduğunu gösterir. Bu oran, eksik değer sayısının toplam veri noktası sayısına bölünmesiyle bulunur.\n\n\n6.1.3.4 NA olmayan (complete) değerlerin oranı için:\n\n# naniar kütüphanesini yükleme\nlibrary(naniar)\n\n# Tamamlanmış değer oranını hesaplama\nprop_complete(airquality)\n\n[1] 0.9520697\n\n\n\nprop_complete(airquality) fonksiyonu, naniar paketine ait bir fonksiyondur ve airquality veri setindeki tamamlanmış (yani eksik olmayan) değerlerin oranını hesaplar. Çıktı olarak [1] 0.9520737 değeri döner. Bu, airquality veri setindeki değerlerin yaklaşık %95.2’sinin tamamlanmış olduğunu gösterir.\n\n\n6.1.3.5 Eksik veriler için pareto tablosu dlookr\n\n\n# dlookr kütüphanesini yükleme (gerekli fonksiyon için)\n# install.packages(\"dlookr\")\nlibrary(dlookr)\n\n# Eksik verilerin Pareto grafiği ile gösterimi\nplot_na_pareto(airquality, \n               only_na = TRUE, \n               # sadece eksik değer içeren değişkenlerin gösterilmesini sağlar.\n               plot = FALSE) \n\n# A tibble: 2 × 5\n  variable frequencies  ratio grade cumulative\n  &lt;fct&gt;          &lt;int&gt;  &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;\n1 Ozone             37 0.242  Bad         84.1\n2 Solar.R            7 0.0458 Good       100  \n\n               # grafik yerine sadece tablo çıktısının gösterilmesini sağlar.\n\n\n6.1.4 Web Raporu Oluşturma\n\n# dlookr kütüphanesini yükleme \nlibrary(dlookr)  \n\n# Web raporu oluşturma \n# diagnose_web_report(airquality, subtitle = \"airquality\")\n\n\ndiagnose_web_report(airquality, subtitle = \"airquality\") fonksiyonu, dlookr paketine ait bir fonksiyondur ve airquality veri seti için kapsamlı bir veri teşhis raporu oluşturur. Bu rapor bir HTML dosyası olarak kaydedilir ve bir web tarayıcısında görüntülenebilir.\n\n\n6.1.5 DLOOKR Paketi ile Eksik Değerleri Doldurma\ndlookr paketi ve imputate_na()\ndlookr paketi, veri teşhisi (data diagnosis) ve veri keşfi (data exploration) için tasarlanmış bir R paketidir. Bu paket, veri kalitesini değerlendirmek, veri setini özetlemek, değişkenler arasındaki ilişkileri incelemek ve eksik verilerle başa çıkmak için çeşitli kullanışlı fonksiyonlar içerir. imputate_na() fonksiyonu da bu paketin eksik veri yönetimi araçlarından biridir.\nimputate_na() fonksiyonunun temel amacı, bir veri setindeki eksik değerleri (NA) çeşitli yöntemlerle doldurmaktır. Bu fonksiyon, hem sayısal (numeric) hem de kategorik (categorical) değişkenlerdeki eksik değerleri ele alabilir ve farklı doldurma yöntemleri sunar.\n\n\nSayısal Değişkenler için Doldurma Yöntemleri:\n\n\n\"mean\": Eksik değerleri değişkenin ortalamasıyla doldurur.\n\n\"median\": Eksik değerleri değişkenin medyanıyla (ortanca) doldurur.\n\n\"mode\": Eksik değerleri değişkenin moduyla (en sık tekrar eden değer) doldurur.\n\n\"knn\": K-en yakın komşu algoritmasını kullanarak eksik değerleri doldurur. Bu yöntem, eksik değerin bulunduğu satıra en yakın olan K tane gözlemi bulur ve bu gözlemlerin değerlerini kullanarak eksik değeri tahmin eder. Bu yöntem için bir referans değişken belirtmek gereklidir.\n\n\"rpart\": Özyinelemeli Bölümleme ve Regresyon Ağaçları (Recursive Partitioning and Regression Trees) yöntemini kullanarak eksik değerleri doldurur. Bu yöntem, bir karar ağacı modeli oluşturarak eksik değerleri tahmin eder. Bu yöntem için bir referans değişken belirtmek gereklidir.\n\n\"mice\": Zincirleme Denklemlerle Çoklu Atama (Multivariate Imputation by Chained Equations) yöntemini kullanarak eksik değerleri doldurur. Bu yöntem, her eksik değişken için bir model oluşturur ve diğer değişkenleri kullanarak eksik değerleri tahmin eder. Bu yöntem için bir referans değişken belirtmek ve bir rastgele sayı başlangıç değeri (random seed) ayarlamak gereklidir.\n\n\n\nKategorik Değişkenler için Doldurma Yöntemleri:\n\n\n\"mode\": Eksik değerleri değişkenin moduyla (en sık tekrar eden kategori) doldurur.\n\n\"rpart\": Özyinelemeli Bölümleme ve Regresyon Ağaçları yöntemini kullanarak eksik değerleri doldurur. Bu yöntem için bir referans değişken belirtmek gereklidir.\n\n\"mice\": Zincirleme Denklemlerle Çoklu Atama yöntemini kullanarak eksik değerleri doldurur. Bu yöntem için bir referans değişken belirtmek ve bir rastgele sayı başlangıç değeri (random seed) ayarlamak gereklidir.\n\n\n\nimputate_na() fonksiyonu, veri ön işleme adımlarında eksik verileri ele almak için kullanışlı bir araçtır. Doldurma yöntemini seçerken, verinizin yapısını ve analizin amacını göz önünde bulundurmanız önemlidir. Örneğin, ortalama ile doldurma, aykırı değerlerden etkilenebilirken, medyan ile doldurma bu etkiyi azaltır. knn, rpart ve mice gibi daha gelişmiş yöntemler ise, değişkenler arasındaki ilişkileri dikkate alarak daha doğru tahminler yapabilir.\n\n6.1.5.1 Eksik değer içeren sütunu görüntüleme\n\ndata(\"airquality\")\n\n# airquality veri setinin Ozone sütununu görüntüleme\nairquality$Ozone\n\n  [1]  41  36  12  18  NA  28  23  19   8  NA   7  16  11  14  18  14  34   6\n [19]  30  11   1  11   4  32  NA  NA  NA  23  45 115  37  NA  NA  NA  NA  NA\n [37]  NA  29  NA  71  39  NA  NA  23  NA  NA  21  37  20  12  13  NA  NA  NA\n [55]  NA  NA  NA  NA  NA  NA  NA 135  49  32  NA  64  40  77  97  97  85  NA\n [73]  10  27  NA   7  48  35  61  79  63  16  NA  NA  80 108  20  52  82  50\n [91]  64  59  39   9  16  78  35  66 122  89 110  NA  NA  44  28  65  NA  22\n[109]  59  23  31  44  21   9  NA  45 168  73  NA  76 118  84  85  96  78  73\n[127]  91  47  32  20  23  21  24  44  21  28   9  13  46  18  13  24  16  13\n[145]  23  36   7  14  30  NA  14  18  20\n\n\n\nairquality$Ozone kodu, airquality adlı veri çerçevesinin Ozone adlı sütununu seçer ve bu sütundaki tüm değerleri bir vektör olarak döndürür.\nÇıktıda görüldüğü gibi, Ozone sütunu sayısal değerler ve NA (Not Available - Mevcut Değil) değerleri içermektedir. NA değerleri, o gün için ozon ölçümünün yapılamadığını veya kaydedilmediğini gösterir.\n\n\n\n\n\n\nVektör Çıktılarında Köşeli Parantez\n\n\n\nÇıktının başında ve sonunda [1], [28], [55] gibi ifadeler bulunur. Bunlar, çıktının hangi indeksinden itibaren yeni bir satıra geçildiğini gösterir. Örneğin, [28] ifadesi, o satırda 28. elemandan itibaren değerlerin listelendiğini belirtir. Bu, çıktının daha okunabilir olmasını sağlar, özellikle de çok uzun vektörler görüntülendiğinde.\n\n\n\n\n6.1.5.2 Eksik değerleri ortalama (mean) ile doldurma\n\n# dlookr kütüphanesini yükleme \nlibrary(dlookr)\n\n# Ozone değişkenini Temp i referans alarak ortalama ile doldurma\naq_imp_ozone_mean &lt;- imputate_na(airquality, Ozone, Temp, method = \"mean\")\n\n# SADECE Ozone sütununu görüntüleme\naq_imp_ozone_mean\n\n  [1]  41.00000  36.00000  12.00000  18.00000  42.12931  28.00000  23.00000\n  [8]  19.00000   8.00000  42.12931   7.00000  16.00000  11.00000  14.00000\n [15]  18.00000  14.00000  34.00000   6.00000  30.00000  11.00000   1.00000\n [22]  11.00000   4.00000  32.00000  42.12931  42.12931  42.12931  23.00000\n [29]  45.00000 115.00000  37.00000  42.12931  42.12931  42.12931  42.12931\n [36]  42.12931  42.12931  29.00000  42.12931  71.00000  39.00000  42.12931\n [43]  42.12931  23.00000  42.12931  42.12931  21.00000  37.00000  20.00000\n [50]  12.00000  13.00000  42.12931  42.12931  42.12931  42.12931  42.12931\n [57]  42.12931  42.12931  42.12931  42.12931  42.12931 135.00000  49.00000\n [64]  32.00000  42.12931  64.00000  40.00000  77.00000  97.00000  97.00000\n [71]  85.00000  42.12931  10.00000  27.00000  42.12931   7.00000  48.00000\n [78]  35.00000  61.00000  79.00000  63.00000  16.00000  42.12931  42.12931\n [85]  80.00000 108.00000  20.00000  52.00000  82.00000  50.00000  64.00000\n [92]  59.00000  39.00000   9.00000  16.00000  78.00000  35.00000  66.00000\n [99] 122.00000  89.00000 110.00000  42.12931  42.12931  44.00000  28.00000\n[106]  65.00000  42.12931  22.00000  59.00000  23.00000  31.00000  44.00000\n[113]  21.00000   9.00000  42.12931  45.00000 168.00000  73.00000  42.12931\n[120]  76.00000 118.00000  84.00000  85.00000  96.00000  78.00000  73.00000\n[127]  91.00000  47.00000  32.00000  20.00000  23.00000  21.00000  24.00000\n[134]  44.00000  21.00000  28.00000   9.00000  13.00000  46.00000  18.00000\n[141]  13.00000  24.00000  16.00000  13.00000  23.00000  36.00000   7.00000\n[148]  14.00000  30.00000  42.12931  14.00000  18.00000  20.00000\nattr(,\"var_type\")\n[1] \"numerical\"\nattr(,\"method\")\n[1] \"mean\"\nattr(,\"na_pos\")\n [1]   5  10  25  26  27  32  33  34  35  36  37  39  42  43  45  46  52  53  54\n[20]  55  56  57  58  59  60  61  65  72  75  83  84 102 103 107 115 119 150\nattr(,\"type\")\n[1] \"missing values\"\nattr(,\"message\")\n[1] \"complete imputation\"\nattr(,\"success\")\n[1] TRUE\nattr(,\"class\")\n[1] \"imputation\" \"numeric\"   \n\n\n\n\n\ndata: İşlem yapılacak veri seti. Burada airquality veri seti kullanılmıştır.\n\ntarget: Eksik değerlerin doldurulacağı sütun. Burada Ozone sütunu belirtilmiştir.\n\nref: Referans alınacak sütun. Burada Temp sütunu kullanılmıştır.\n\nmethod: Doldurma yöntemi. \"mean\" ile ortalama kullanılarak doldurma yapılır.\n\nÇalışma Prensibi: Eksik değerler Temp sütununun ortalamasına göre doldurulmuş ve yeni bir veri seti (aq_imp_ozone) oluşturulmuştur.\n\n\n6.1.5.3 Ortalama (mean) ile doldurma öncesi ve sonrası yoğunluk dağılımları\n\nplot(aq_imp_ozone_mean)\n\n\n\n\n\n\n\n\nEksik değerlerin ortalama ile doldurulması, veri setinin genel dağılımında hafif değişikliklere yol açmıştır. Eksik değerlerin doldurulması, yoğunluk eğrisini daha düzgün hale getirmiştir, ancak bu işlem, verilerin doğal dağılımını biraz değiştirebilir. Özellikle veri çok eksikse, ortalama ile doldurma yöntemi dağılımın şeklini etkileyebilir. Eğer veri setinin doğal varyasyonunu korumak çok önemliyse, alternatif doldurma yöntemleri (örneğin, knn veya regresyon tabanlı yöntemler) düşünülebilir.\n\n\n6.1.5.4 Medyan (median) ile doldurma öncesi ve sonrası yoğunluk dağılımları\n\nlibrary(dlookr)\n\n# Ozone ve Temp değişkenlerini medyan ile doldurma\naq_imp_ozone_median &lt;- imputate_na(airquality, Ozone, Temp, method = \"median\")\n\n# plot() fonksiyonu ile çizim (indekse karşı değer grafiği)\nplot(aq_imp_ozone_median)\n\n\n\n\n\n\n\n\nGrafikte, x ekseni vektördeki elemanların sırasını (indeks), y ekseni ise medyan ile doldurulmuş Ozone değerlerini gösterir. Ortalama ile doldurmaya benzer şekilde, grafikte noktaların rastgele yukarı aşağı hareket ettiğini görürsünüz. Ancak, medyan ile doldurmada, ortalama ile doldurmaya kıyasla grafikte daha az yatay çizgi veya düz bölge görürsünüz. Bunun nedeni, medyanın ortalamadan farklı değerlere sahip olabilmesi ve aynı değerin daha az tekrar etmesidir.\n\n\n\n\n\n\n\nOrtalama vs. Medyan ile Eksik Değer Doldurma\n\n\n\nOrtalama ile doldurma, dağılımın ortasında bir yığılmaya neden olurken, medyan ile doldurma bu yığılmayı daha az belirgin hale getirir. Çünkü medyan, aykırı değerlerden ortalamaya göre daha az etkilenir. Bu nedenle, verilerinizde aykırı değerler varsa, medyan ile doldurma ortalama ile doldurmaya göre daha iyi bir seçenek olabilir.\n\n\n\n6.1.5.5 knn ile doldurma öncesi ve sonrası yoğunluk dağılımları\n\nlibrary(dlookr)\n\n# Ozone değişkenini knn ile doldurma (Temp'i referans değişken olarak kullanır)\naq_imp_ozone_knn &lt;- imputate_na(airquality, Ozone, Temp, method = \"knn\")\n\n# plot() fonksiyonu ile çizim (indekse karşı değer grafiği)\nplot(aq_imp_ozone_knn)\n\n\n\n\n\n\n\n\nYukarıdaki kod, Ozone değişkenindeki eksik değerleri knn (k-Nearest Neighbors - k-En Yakın Komşu) yöntemiyle dolduruyor ve ardından bu doldurulmuş değerleri plot() fonksiyonu ile çiziliyor.\n\n\nReferans Değişkenin Önemi: knn ile doldurma yaparken, seçilen referans değişkenin (burada Temp) eksik değerlere sahip olmaması veya çok az eksik değere sahip olması önemlidir. Aksi takdirde, modelin doğruluğu düşebilir.\n\nBenzer Gözlemler: knn, eksik değere sahip olan gözleme en benzer k tane gözlemi bulur ve bu gözlemlerin değerlerini kullanarak eksik değeri tahmin eder. Bu nedenle, verideki yerel örüntüleri yakalamada etkilidir.\n\nk Değeri: k parametresi (komşu sayısı) önemlidir. Çok küçük bir k değeri, aşırı uyuma (overfitting) neden olabilirken, çok büyük bir k değeri, yerel örüntüleri kaçırmaya neden olabilir. imputate_na() fonksiyonunda k değeri varsayılan olarak 5’tir, ancak gerekirse değiştirilebilir.\n\nDağılımın Değişimi: knn ile doldurma, ortalama veya medyan ile doldurmaya göre dağılımı daha az etkiler. Çünkü bu yöntem, eksik değerleri tek bir sabit değerle doldurmak yerine, benzer gözlemlerin değerlerine göre farklı değerlerle doldurur.\n\n\n\n6.1.5.6 rpart ile doldurma öncesi ve sonrası yoğunluk dağılımları\n\nlibrary(dlookr)\n\n# Ozone değişkenini rpart ile doldurma (Temp'i referans değişken olarak kullanır)\naq_imp_ozone_rpart &lt;- imputate_na(airquality, Ozone, Temp, method = \"rpart\")\n\n# plot() fonksiyonu ile çizim (indekse karşı değer grafiği)\nplot(aq_imp_ozone_rpart)\n\n\n\n\n\n\n\n\nYukarıdaki kod ile Ozone değişkenindeki eksik değerleri rpart (Recursive Partitioning and Regression Trees - Özyinelemeli Bölümleme ve Regresyon Ağaçları) yöntemiyle dolduruyor ve ardından bu doldurulmuş değerleri plot() fonksiyonu ile çiziyor.\n\n\nreferans Değişkenin Önemi: rpart ile doldurma yaparken, seçilen referans değişkenin (burada Temp) eksik değerlere sahip olmaması veya çok az eksik değere sahip olması önemlidir. Aksi takdirde, modelin doğruluğu düşebilir.\n\nDoğrusal Olmayan İlişkiler: rpart, değişkenler arasındaki doğrusal olmayan ilişkileri de yakalayabildiği için, ortalama veya medyan ile doldurmaya göre daha doğru sonuçlar verebilir. Ancak, aşırı uyum (overfitting) riskini de beraberinde getirebilir.\n\nDağılımın Değişimi: rpart ile doldurma, ortalama veya medyan ile doldurmaya göre dağılımı daha az etkiler. Çünkü bu yöntem, eksik değerleri tek bir sabit değerle doldurmak yerine, referans değişkene göre farklı değerlerle doldurur.\n\n\n\n6.1.5.7 mice ile doldurma öncesi ve sonrası yoğunluk dağılımları\n\nlibrary(dlookr)\nlibrary(mice)\n\n# Ozone değişkenini mice ile doldurma (Temp'i ve diğer değişkenleri kullanır)\naq_imp_ozone_mice &lt;- imputate_na(airquality, Ozone, Temp, \n                                 method = \"mice\", \n                                 seed = 111, \n                                 print =FALSE)\n\n# plot() fonksiyonu ile çizim (indekse karşı değer grafiği)\nplot(aq_imp_ozone_mice)\n\n\n\n\n\n\n\n\nYukarıdaki kod ile Ozone değişkenindeki eksik değerleri mice (Multivariate Imputation by Chained Equations - Zincirleme Denklemlerle Çoklu Atama) yöntemiyle dolduruyor ve ardından bu doldurulmuş değerleri plot() fonksiyonu ile çiziyor.\n\n\nÇoklu Atama: mice, eksik değerler için birden fazla olası değer ürettiği için, eksik verilerin belirsizliğini daha iyi yansıtır. Bu, daha doğru ve güvenilir sonuçlar elde etmenizi sağlar.\n\nDeğişkenler Arası İlişkiler: mice, değişkenler arasındaki ilişkileri dikkate aldığı için, diğer yöntemlere göre daha iyi tahminler yapabilir.\n\nDağılımın Korunması: mice, verinin orijinal dağılımını daha iyi korur. Ortalama veya medyan ile doldurma, dağılımda bozulmalara neden olabilirken, mice bu etkiyi en aza indirir.\n\n\n\n6.1.5.8 Doldurulmuş veriyi orijinal veriye entegre etme - Aşama 1\n\n# Gerekli kütüphanelerin yüklenmesi\nlibrary(dlookr)\nlibrary(tidyverse)\nlibrary(mice)\n\n# Orijinal veri setini kopyalama\nairquality_imp &lt;- airquality\n\n# Doldurulmuş Ozone verisini orijinal veri setine atama\nairquality_imp$Ozone &lt;- aq_imp_ozone_mice\n\n# Doldurulmuş veri setini görüntüleme\nhead(airquality_imp, 10)\n\n   Ozone Solar.R Wind Temp Month Day\n1   41.0     190  7.4   67     5   1\n2   36.0     118  8.0   72     5   2\n3   12.0     149 12.6   74     5   3\n4   18.0     313 11.5   62     5   4\n5   21.0      NA 14.3   56     5   5\n6   28.0      NA 14.9   66     5   6\n7   23.0     299  8.6   65     5   7\n8   19.0      99 13.8   59     5   8\n9    8.0      19 20.1   61     5   9\n10  40.2     194  8.6   69     5  10\n\n\n\n6.1.5.9 Doldurulmuş veriyi orijinal veriye entegre etme - Aşama 2\n\n# Gerekli kütüphanelerin yüklenmesi\nlibrary(dlookr)\nlibrary(mice)\nlibrary(tidyverse)\n\n# Ozone değişkenini ortalama ile doldurma\naq_imp_solar_mice &lt;- imputate_na(airquality_imp, Solar.R, Temp, \n                                 method = \"mice\", \n                                 seed = 111,\n                                 print = FALSE)\n# \"print =\" argümanı eğer TRUE olarak ayarlanırsa, mice işlemin geçmişini konsolda\n# yazdıracaktır. Sessiz bir hesaplama için print=FALSE kullanın.\n\n# Doldurulmuş Ozone verisini orijinal veri setine atama\nairquality_imp$Solar.R &lt;- aq_imp_solar_mice\n\n# Doldurulmuş veri setini görüntüleme\nhead(airquality_imp, 10)\n\n   Ozone Solar.R Wind Temp Month Day\n1   41.0   190.0  7.4   67     5   1\n2   36.0   118.0  8.0   72     5   2\n3   12.0   149.0 12.6   74     5   3\n4   18.0   313.0 11.5   62     5   4\n5   21.0   266.2 14.3   56     5   5\n6   28.0   218.0 14.9   66     5   6\n7   23.0   299.0  8.6   65     5   7\n8   19.0    99.0 13.8   59     5   8\n9    8.0    19.0 20.1   61     5   9\n10  40.2   194.0  8.6   69     5  10\n\n\nOrijinal veri seti ile karşılaştırma\n\nhead(airquality, 10)\n\n   Ozone Solar.R Wind Temp Month Day\n1     41     190  7.4   67     5   1\n2     36     118  8.0   72     5   2\n3     12     149 12.6   74     5   3\n4     18     313 11.5   62     5   4\n5     NA      NA 14.3   56     5   5\n6     28      NA 14.9   66     5   6\n7     23     299  8.6   65     5   7\n8     19      99 13.8   59     5   8\n9      8      19 20.1   61     5   9\n10    NA     194  8.6   69     5  10\n\n\n\n6.1.6 MICE Paketi ile Eksik Değerleri Doldurma\nMICE paketi, eksik veri problemini çözmek için kullanılan bir araçtır ve eksik verileri çoklu imputasyon yöntemini kullanarak işleme alır. Süreç, eksik veri içeren bir veri setiyle başlar. Bu veri genellikle bir data frame formatındadır ve eksik verilerin, diğer değişkenlerle olan ilişkilerine dayanarak doldurulması hedeflenir.\nMICE paketi, eksik veri problemini çözmek için şu adımları takip eder:\n\n\nEksik verileri birden fazla doldurur (mice()).\nİlk adımda, mice() fonksiyonu kullanılarak eksik veriler birden fazla iterasyonla doldurulur. Her iterasyonda eksik olan değişkenler, diğer değişkenlerle olan ilişkileri kullanılarak tahmin edilir. Bu işlem sonucunda, doldurulmuş veri setlerini içeren bir “mids” nesnesi oluşturulur.\n\n\nDoldurulan veri setleri üzerinde analizler yapar (with()).\nDaha sonra, with() fonksiyonu aracılığıyla doldurulan veri setleri üzerinde istatistiksel analizler gerçekleştirilir. Örneğin, her doldurulmuş veri seti için regresyon analizi gibi istatistiksel işlemler yapılabilir ve bu analizlerin sonuçları “mira” nesnesi olarak saklanır.\n\n\nAnaliz sonuçlarını havuzlar ve birleştirir (pool()).\nSon aşamada, pool() fonksiyonu kullanılarak her bir doldurulmuş veri seti üzerinde yapılan analizlerin sonuçları birleştirilir. Bu birleştirme işlemi, eksik veri kaynaklı belirsizliği hesaba katarak daha güvenilir ve tutarlı sonuçlar elde etmeyi sağlar. Bu süreç sonucunda, analizlerin nihai sonuçları “mipo” nesnesi olarak elde edilir.\n\n\nMICE paketi, eksik veri problemini istatistiksel olarak en iyi şekilde ele alarak analizlerin güvenilirliğini artırmayı hedefler ve eksik veriden kaynaklanan yanlılığı azaltır.\n\nFigür: https://www.jstatsoft.org/article/view/v045i03\nVeri Seti nhanes\n\n# Gerekli kütüphanelerin yüklenmesi\n# install.packages(\"mice\")\n# install.packages(\"tidyverse\")\n# install.packages(\"NHANES\")\n\nlibrary(mice)\nlibrary(tidyverse)\nlibrary(NHANES)\n\nnhanes3 &lt;- NHANES %&gt;% \n   select(Weight, Height, TotChol, PhysActive)\n\n# NHANES veri setinin görüntülenmesi (örnek olarak ilk 10 satır)\nhead(nhanes3, 10)\n\n# A tibble: 10 × 4\n   Weight Height TotChol PhysActive\n    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;     \n 1   87.4   165.    3.49 No        \n 2   87.4   165.    3.49 No        \n 3   87.4   165.    3.49 No        \n 4   17     105.   NA    &lt;NA&gt;      \n 5   86.7   168.    6.7  No        \n 6   29.8   133.    4.86 &lt;NA&gt;      \n 7   35.2   131.    4.09 &lt;NA&gt;      \n 8   75.7   167.    5.82 Yes       \n 9   75.7   167.    5.82 Yes       \n10   75.7   167.    5.82 Yes       \n\n\n\nnhanes Veri Seti\nNHANES (Ulusal Sağlık ve Beslenme İnceleme Anketi), ABD’de yetişkinlerin ve çocukların sağlık ve beslenme durumunu ölçen bir CDC araştırmasıdır. Anketler ve fiziksel muayeneler içerir. 76 farklı değişkeni bulunmaktadır. Araştırmamızda özellikle aşağıda yer alan\nÇalışmamızda aşağıda yer alan değişkenlere odaklanılacaktır:\n\n\nWeight (Kilo): Obezite ve aşırı kiloyu değerlendirmek için ölçülür.\n\nHeight (Boy): VKİ (Vücut Kitle İndeksi) hesaplamak için kullanılır.\n\nTotChol (Toplam Kolesterol): Kalp hastalığı riskini gösterir.\n\nPhysActive (Fiziksel Aktivite): Genel sağlık için önemlidir.\n\nBu veriler, halk sağlığı sorunlarını anlamak ve sağlık politikalarını değerlendirmek için kullanılır.\n\nnhanes Veri Setinde Eksik Değerler Özet Tablosu\n\nlibrary(naniar)\n\n# miss_var_summary() fonksiyonunu uygulama\nmiss_var_summary(nhanes3)\n\n# A tibble: 4 × 3\n  variable   n_miss pct_miss\n  &lt;chr&gt;       &lt;int&gt;    &lt;num&gt;\n1 PhysActive   1674    16.7 \n2 TotChol      1526    15.3 \n3 Height        353     3.53\n4 Weight         78     0.78\n\n\n\n\n\nPhysActive 167 16.7: PhysActive değişkeninde 167 eksik veri vardır ve bu, toplam verinin %16.7’sine karşılık gelir.\n\nTotChol 152 15.3: TotChol değişkeninde 152 eksik veri vardır ve bu, toplam verinin %15.3’üne karşılık gelir.\n\nHeight 35 3.53: Height değişkeninde 35 eksik veri vardır ve bu, toplam verinin %3.53’üne karşılık gelir.\n\nWeight 7 0.78: Weight değişkeninde 7 eksik veri vardır ve bu, toplam verinin %0.78’ine karşılık gelir.\n\n\n\n6.1.6.1 MICE (Çoklu İmputasyon) ile Eksik Veri Doldurma\n\nlibrary(mice)\n\n# nhanes veri setinde eksik değerleri doldurma (20 imputasyon seti oluşturma)\nnhanes_multiimp &lt;- mice(nhanes3, m = 20, print = FALSE)\n\n\nBu kod, mice paketi kullanılarak nhanes veri setindeki eksik değerlerin doldurulması için çoklu imputasyon işlemi gerçekleştirir. Burada, m = 20 parametresiyle eksik değerlerin 20 farklı tahmini yapılır ve her biri bir imputasyon veri seti olarak oluşturulur.\n\n\nnhanes: İçerisinde eksik değerler bulunan örnek bir veri seti.\n\nm = 20: Çoklu imputasyon işlemiyle 20 farklı doldurulmuş veri seti oluşturulacağını belirtir.\n\nYukarıdaki kod, mice paketini kullanarak nhanes veri setindeki eksik değerleri çoklu atama yöntemiyle doldurur. Bu yöntem, eksik verilerin belirsizliğini hesaba katarak daha doğru ve güvenilir analizler yapmanıza olanak tanır. Kodun doğru çalışması için data(nhanes) satırının eklenmesi önemlidir. Ayrıca, seed eklenmesi, sonuçların tekrarlanabilirliğini sağlar. Kod, nhanes_multiimp adında bir mids nesnesi oluşturur.\n\n\n\n\n\n\n\nÇoklu Atama ve mice’ın Avantajları\n\n\n\n\n\nÇoklu Atama: mice, eksik değerler için tek bir değer yerine birden fazla olası değer ürettiği için, eksik verilerin belirsizliğini daha iyi yansıtır. Bu, standart tek atama yöntemlerine (ortalama, medyan vb.) göre daha doğru ve güvenilir sonuçlar elde etmenizi sağlar. Tek bir değer atamak yerine, olası değerlerin bir dağılımını kullanarak, eksik veriden kaynaklanan belirsizliği modelinize dahil edersiniz.\n\nDeğişkenler Arası İlişkiler: mice, atama işlemi sırasında değişkenler arasındaki ilişkileri dikkate alır. Bu, eksik verilerin daha gerçekçi ve tutarlı bir şekilde tahmin edilmesini sağlar. Örneğin, yaş ve VKİ arasındaki ilişkiyi göz önünde bulundurarak, eksik VKİ değerlerini daha doğru bir şekilde tahmin edebilir.\n\nDağılımın Korunması: mice, verinin orijinal dağılımını daha iyi korur. Ortalama veya medyan ile doldurma gibi basit yöntemler, veri dağılımında bozulmalara neden olabilirken, mice bu etkiyi en aza indirir. Bu, analizlerinizin daha güvenilir ve anlamlı olmasını sağlar.\n\n\n\n\n6.1.6.2 MICE ile Veri Setleri Üzerinde Lineer Regresyon Modeli Kurma\n\nlibrary(mice)\n\n# Her bir atanmış veri setine lineer regresyon modeli uygula\nlm_multiimp &lt;- with(nhanes_multiimp, lm(Weight ~ Height + TotChol + PhysActive))\n\n\nBu kod, daha önce oluşturulan nhanes_multiimp adlı mids (multiple imputation data set) nesnesini kullanarak, her bir tamamlanmış veri setine bir lineer regresyon modeli uygular.\n\nwith(nhanes_multiimp, ...): Bu fonksiyon, nhanes_multiimp nesnesindeki her bir tamamlanmış veri seti üzerinde belirtilen ifadeyi uygular. Yani, 20 farklı tamamlanmış veri setin varsa, bu ifade 20 kez çalıştırılır ve her biri için ayrı bir lineer regresyon modeli oluşturulur.\nlm(Weight ~ Height + TotChol + PhysActive): Bu, lineer regresyon modelini tanımlar. Weight (Kilo) bağımlı değişken, Height (Boy), TotChol (Toplam Kolesterol) ve PhysActive (Fiziksel Aktivite) ise bağımsız değişkenlerdir. Yani, kilonun boy, toplam kolesterol ve fiziksel aktivite ile nasıl ilişkili olduğunu inceliyoruz.\n\n\n\n\n\n\n\nFaktör Dönüşümü\n\n\n\nPhysActive’in Faktöre Dönüştürülmesi: Eğer PhysActive değişkeni sayısal olarak kodlanmış bir kategorik değişken ise (örneğin, 1=Aktif, 2=Pasif ya da yes, no gibi), lineer regresyon modelinde doğru şekilde yorumlanabilmesi için bu değişkeni factor() fonksiyonu ile faktöre dönüştürmek çok önemlidir. Kodu bu duruma göre güncelledim. Eğer PhysActive zaten bir faktör ise bu satıra gerek yoktur.\n\n\n\n\n6.1.6.3 MICE ile Regresyon Sonuçlarını Havuzlama\n\nlibrary(mice)\n\n# Çoklu imputasyon veri setleri üzerindeki regresyon sonuçlarını havuzlama\nlm_pooled &lt;- pool(lm_multiimp)\n\n# Havuzlanmış sonuçları özetleme\nsummary(lm_pooled)\n\n           term    estimate  std.error  statistic         df      p.value\n1   (Intercept) -93.2761794 1.88249998 -49.549100   85.53417 9.001161e-65\n2        Height   0.9997873 0.01088186  91.876490   92.25780 1.680034e-92\n3       TotChol   1.5587611 0.17765159   8.774259 2354.76828 3.236133e-18\n4 PhysActiveYes  -5.9132808 0.38186334 -15.485332 1660.16326 1.265237e-50\n\n\n\nBu kod, lm_multiimp nesnesindeki çoklu imputasyon veri setleri üzerinde oluşturulan lineer regresyon modellerinin sonuçlarını birleştirir (pool). Havuzlama işlemi, eksik veriler nedeniyle ortaya çıkan belirsizliği hesaba katar ve tüm imputasyon veri setlerinden elde edilen sonuçları birleştirerek daha doğru ve güvenilir tahminler sunar.\nBu model, bağımlı değişken olan Weight (Ağırlık) üzerinde Height (Boy Uzunluğu), TotChol (Toplam Kolesterol) ve PhysActive (Fiziksel Aktivite Durumu) değişkenlerinin etkilerini anlamlı bir şekilde açıklamaktadır. Tüm değişkenlerin p-değerleri oldukça küçüktür ve bu değişkenlerin modelde anlamlı bir etkisi olduğunu göstermektedir. Modeldeki katsayılar, bağımlı değişken üzerinde her bir bağımsız değişkenin etkisini istatistiksel olarak güçlü bir şekilde temsil etmektedir.\n\n\n6.1.6.4 MICE ile Tamamlanmış Veri Seti\n\nlibrary(mice)\n\n# İlk doldurulmuş veri setini elde etme\nnhanes3_completed &lt;- complete(nhanes_multiimp)\n\n# Doldurulmuş veri setini görüntüleme\nhead(nhanes3_completed)\n\n  Weight Height TotChol PhysActive\n1   87.4  164.7    3.49         No\n2   87.4  164.7    3.49         No\n3   87.4  164.7    3.49         No\n4   17.0  105.4    3.80         No\n5   86.7  168.4    6.70         No\n6   29.8  133.1    4.86        Yes\n\n\n\n6.1.6.5 Ham Veri ile Son Veriyi Karşılaştırma\n\nsummary(nhanes3_completed)\n\n     Weight           Height         TotChol       PhysActive\n Min.   :  2.80   Min.   : 83.6   Min.   : 1.530   No :4710  \n 1st Qu.: 56.10   1st Qu.:155.7   1st Qu.: 4.030   Yes:5290  \n Median : 72.70   Median :165.5   Median : 4.680             \n Mean   : 70.99   Mean   :159.9   Mean   : 4.813             \n 3rd Qu.: 88.90   3rd Qu.:174.3   3rd Qu.: 5.480             \n Max.   :230.70   Max.   :200.4   Max.   :13.650             \n\n\n\nsummary(nhanes3)\n\n     Weight           Height         TotChol       PhysActive \n Min.   :  2.80   Min.   : 83.6   Min.   : 1.530   No  :3677  \n 1st Qu.: 56.10   1st Qu.:156.8   1st Qu.: 4.110   Yes :4649  \n Median : 72.70   Median :166.0   Median : 4.780   NA's:1674  \n Mean   : 70.98   Mean   :161.9   Mean   : 4.879              \n 3rd Qu.: 88.90   3rd Qu.:174.5   3rd Qu.: 5.530              \n Max.   :230.70   Max.   :200.4   Max.   :13.650              \n NA's   :78       NA's   :353     NA's   :1526",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Veri Temizleme</span>"
    ]
  },
  {
    "objectID": "veri_temizleme.html#aykırı-değerler-ile-çalışma",
    "href": "veri_temizleme.html#aykırı-değerler-ile-çalışma",
    "title": "\n6  Veri Temizleme\n",
    "section": "\n6.2 Aykırı Değerler ile Çalışma",
    "text": "6.2 Aykırı Değerler ile Çalışma\n\n6.2.1 Aykırı Değerlerin Tespiti\n\nKutu grafikleri (ggplot2::geom_boxplot()).\nZ-skore veya IQR yöntemleri (scale(), boxplot.stats()).\n\n6.2.2 Aykırı Değerlerin Çıkarılması veya Düzenlenmesi\n\nVeri dönüşümleri ile etkilerini azaltma (ör. log(), sqrt()).\nKategorik aykırılıkların analizi (dplyr::filter()).",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Veri Temizleme</span>"
    ]
  },
  {
    "objectID": "veri_temizleme.html#veri-dönüşümleri-ve-standardizasyon",
    "href": "veri_temizleme.html#veri-dönüşümleri-ve-standardizasyon",
    "title": "\n6  Veri Temizleme\n",
    "section": "\n6.3 Veri Dönüşümleri ve Standardizasyon",
    "text": "6.3 Veri Dönüşümleri ve Standardizasyon\n\n6.3.1 Matematiksel Dönüşümler\n\nLogaritmik (log()), karekök (sqrt()) dönüşümleri\n\n6.3.2 Standardizasyon ve Normalizasyon\n-   Z-skore standardizasyonu (`scale()`).\n\n-   Min-max normalizasyon (`scales::rescale()`, `caret::preProcess()`).",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Veri Temizleme</span>"
    ]
  },
  {
    "objectID": "veri_temizleme.html#veri-doğrulama-ve-temizleme-işlemleri",
    "href": "veri_temizleme.html#veri-doğrulama-ve-temizleme-işlemleri",
    "title": "\n6  Veri Temizleme\n",
    "section": "\n6.4 Veri Doğrulama ve Temizleme İşlemleri",
    "text": "6.4 Veri Doğrulama ve Temizleme İşlemleri\n\n6.4.1 Veri Türlerinin Düzenlenmesi\n\n6.4.1.1 Kategorik Değişkenler\n\nKategorilere dönüştürme (as.factor(), forcats::fct_reorder()).\nSeyrek kategorilerin birleştirilmesi (forcats::fct_lump()).\n\n6.4.1.2 Tarih ve Saat Verileri\n\nTarih dönüşümleri (lubridate::ymd(), dmy()).\n\n6.4.1.3 Veri Çoğaltmalarının Kaldırılması\n\nBenzersiz veri seçimi (dplyr::distinct()).\n\nReferanslar\nhttps://naniar.njtierney.com/\nhttps://www.rdocumentation.org/packages/mice/versions/3.17.0/topics/mice\nhttps://choonghyunryu.github.io/dlookr/ https://rpubs.com/chibueze99/MissingR\nhttps://stefvanbuuren.name/fimd/\nhttps://rmisstastic.netlify.app/tutorials/josse_bookdown_dataanalysismissingr_2020\nhttps://rpubs.com/rpatel40/handling_missing_data_in_R\nhttps://www.youtube.com/watch?v=Akb401i32Oc&ab_channel=yuzaRDataScience",
    "crumbs": [
      "Veri Dönüşümleri",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Veri Temizleme</span>"
    ]
  },
  {
    "objectID": "temel_istatistik.html",
    "href": "temel_istatistik.html",
    "title": "Temel İstatistik",
    "section": "",
    "text": "Çalışmanın Temel İstatistik bölümü, istatistiksel analizlerin yapı taşlarını oluşturan temel kavram ve yöntemlere odaklanmaktadır. İlk olarak, veri tipleri ele alınmış ve sayısal (nicel) verilerin sürekli ve kesikli, kategorik (nitel) verilerin ise nominal ve ordinal olarak sınıflandırılması yapılmıştır. Bu sınıflandırma, farklı veri türlerinin analiz süreçlerinde nasıl ele alınması gerektiğini açıklamaktadır. Ayrıca, merkezi eğilim ölçüleri (ortalama, medyan, mod) ve yayılım ölçüleri (aralık, varyans, standart sapma) gibi istatistiksel araçlar ayrıntılı bir şekilde incelenmiş ve bunların veri setlerini özetlemedeki rolleri vurgulanmıştır. Merkezi limit teoremi, dağılım türleri ve olasılık dağılımları (örneğin, binom, Poisson, normal dağılım) gibi istatistikte önemli kavramlara da bölümde yer verilmiş, bu kavramların temel prensipleri uygulamalı örneklerle desteklenmiştir.\nBölümün devamında, istatistiksel analizlerde sıklıkla kullanılan güven aralıkları ve hipotez testleri ayrıntılı bir şekilde ele alınmaktadır. Güven aralıklarının nasıl hesaplandığı ve bu aralıkların sonuçların yorumlanmasındaki önemi açıklanmıştır. Hipotez testleri kapsamında, sıfır hipotezi ve alternatif hipotez kavramları, p-değeri ve anlamlılık seviyelerinin istatistiksel çıkarımlar üzerindeki etkisi ele alınmıştır. Ayrıca, farklı hipotez testi türleri ve bu testlerin hangi durumlarda kullanılması gerektiği açıklanmıştır.",
    "crumbs": [
      "Temel İstatistik"
    ]
  },
  {
    "objectID": "veri_donusum.html",
    "href": "veri_donusum.html",
    "title": "Veri Dönüşümleri",
    "section": "",
    "text": "Veri dönüşümleri, ham verinin analiz ve modelleme için uygun hale getirilmesi sürecinde temel bir adımdır. Bu başlık altında, veri manipülasyonu ve dönüşüm tekniklerine ilişkin kapsamlı bir içerik sunulmaktadır. Kitabın bu kısmında, sütun seçimi, satır filtreleme, sıralama ve sütun adlarının yeniden adlandırılması gibi temel veri manipülasyonu işlemlerinden başlayarak, yeni değişken oluşturma, istatistiksel özetler hazırlama ve veri birleştirme gibi daha karmaşık süreçlere kadar geniş bir yelpazede yöntemler ele alınmıştır. Bu yöntemlerin, R programlama dili kullanılarak pratik uygulamalarla nasıl gerçekleştirilebileceği adım adım açıklanmıştır.\nVeri manipülasyonu işlemlerinin ardından, veri şekillendirme ve metin manipülasyonu gibi daha spesifik konular ele alınmaktadır. Veri çerçevelerinin birleştirilmesi, veri ekleme işlemleri ve metinsel bilgilerin düzenlenmesi, modern veri analizi süreçlerinde sıkça karşılaşılan problemler için çözüm önerileri sunmaktadır. Özellikle, düzenli ifadeler (regex) ve janitor paketi gibi araçlar kullanılarak veri temizleme ve düzenleme süreçleri sade bir şekilde anlatılmıştır. Bu teknikler, büyük ve karmaşık veri setlerinin daha anlaşılır ve işlenebilir bir formata dönüştürülmesini sağlamaktadır.\nÇalışmanın bu kısmı ayrıca eksik verilerle çalışmaya yönelik detaylı yöntemler içermektedir. Eksik verilerin tespiti, görselleştirilmesi ve doldurulması gibi süreçler, analizlerin doğruluğunu artırmak ve tutarlı sonuçlar elde etmek için kritik bir öneme sahiptir. Bu bağlamda, DLOOKR ve MICE gibi R paketlerinin kullanımı uygulamalı örneklerle gösterilmiştir. Veri dönüşümüne yönelik bu kapsamlı yaklaşım, veri analizi süreçlerinde verilerin etkin bir şekilde işlenmesine ve analizlerden maksimum verim alınmasına olanak tanımaktadır.",
    "crumbs": [
      "Veri Dönüşümleri"
    ]
  }
]